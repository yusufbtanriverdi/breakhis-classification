{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet is a convolutional neural network (CNN).\n",
    "It was one of the first CNNs to demonstrate the effectiveness of deep learning for image classification tasks.\n",
    "\n",
    "AlexNet is composed of 8 layers: 5 convolutional layers, 2 fully connected layers, and 1 softmax layer. It uses the Rectified Linear Unit (ReLU) activation function, local response normalization, and dropout regularization to prevent overfitting.\n",
    "\n",
    "Firstly, it operated with 3-channel images that were (224x224x3) in size. It used max pooling along with ReLU activations when subsampling. The kernels used for convolutions were either 11x11, 5x5, or 3x3 while kernels used for max pooling were 3x3 in size. It classified images into 1000 classes. It also utilized multiple GPUs.\n",
    "\n",
    "Source: https://blog.paperspace.com/alexnet-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn # For the dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, number_classes=10):\n",
    "\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.number_classes = number_classes\n",
    "        self.convolution_block1 = nn.Sequential(       # First convolution layer\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),  # 2D convolution layer, 3 channel image, applies 96 filters of size 11x11 with a stride of 4 and no padding\n",
    "            nn.BatchNorm2d(96),                                     # Normalizing batch layer for the first convolution layer\n",
    "            nn.ReLU(),                                              # ReLU is a non-linear activation function\n",
    "            nn.MaxPool2d(kernel_size=2, stride = 2),                # reducing the spatial dimensions of the output tensor by half.\n",
    "        )\n",
    "        self.convolution_block2 = nn.Sequential(                    # Second convolution layer, to learn more complex and abstract features from the image.\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2), # input tensor is the output from the first convolutional layer\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.convolution_block3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.convolution_block4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.convolution_block5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        # Fully connected layers,  to convert the high-dimensional output from the convolutional layers to a probability distribution over the possible classes.\n",
    "        # used to prevent overfitting by randomly dropping out units during training\n",
    "        # RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x256 and 9216x4096)\n",
    "        self.fully_connected = nn.Sequential(                       \n",
    "            nn.Dropout(0.3),                                        \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU())\n",
    "        self.fully_connected1 = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU())\n",
    "        self.fully_connected2= nn.Sequential(                     \n",
    "            nn.Linear(64, number_classes))                        #Softmax function,  produces a probability distribution over the possible classes, allowing the network to make a prediction.         \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.convolution_block1(x)\n",
    "        out = self.convolution_block2(out)\n",
    "        out = self.convolution_block3(out)\n",
    "        out = self.convolution_block4(out)\n",
    "        out = self.convolution_block5(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fully_connected(out)\n",
    "        out = self.fully_connected1(out)\n",
    "        logits = self.fully_connected2(out)\n",
    "\n",
    "        return logits      # class probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (convolution_block1): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (convolution_block2): Sequential(\n",
      "    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (convolution_block3): Sequential(\n",
      "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (convolution_block4): Sequential(\n",
      "    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (convolution_block5): Sequential(\n",
      "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fully_connected): Sequential(\n",
      "    (0): Dropout(p=0.3, inplace=False)\n",
      "    (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fully_connected1): Sequential(\n",
      "    (0): Dropout(p=0.3, inplace=False)\n",
      "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fully_connected2): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "OrderedDict([('convolution_block1.0.weight', tensor([[[[ 2.9364e-02,  5.2262e-02, -1.2160e-03,  ..., -1.3885e-02,\n",
      "            3.7758e-02,  2.5687e-02],\n",
      "          [-2.1983e-02, -4.1630e-02, -8.2599e-03,  ..., -1.9359e-02,\n",
      "            8.7882e-03,  4.9678e-02],\n",
      "          [-4.7092e-02, -4.5837e-02, -5.3335e-03,  ..., -1.8393e-02,\n",
      "            3.3465e-02, -5.2197e-03],\n",
      "          ...,\n",
      "          [-3.2022e-02, -1.3358e-02,  4.6504e-03,  ..., -1.2457e-05,\n",
      "            1.2759e-02, -4.0199e-02],\n",
      "          [-2.1532e-02, -2.9893e-02,  1.5919e-03,  ...,  3.7928e-02,\n",
      "            1.9083e-02,  4.0444e-02],\n",
      "          [-5.1856e-02,  2.6047e-02,  1.5950e-02,  ..., -4.9579e-03,\n",
      "            5.0762e-02, -2.0970e-02]],\n",
      "\n",
      "         [[ 8.7628e-03,  3.6588e-02,  3.4655e-02,  ...,  3.5377e-02,\n",
      "           -1.7968e-02, -5.0400e-03],\n",
      "          [-5.1152e-03,  3.4608e-02, -1.9309e-02,  ..., -3.5171e-02,\n",
      "            1.0396e-02,  1.2513e-03],\n",
      "          [ 1.7795e-02, -2.9143e-03,  5.6444e-03,  ..., -4.1217e-02,\n",
      "            3.1869e-02,  3.8040e-02],\n",
      "          ...,\n",
      "          [-3.5378e-02, -2.6217e-03,  4.9121e-02,  ...,  4.2463e-02,\n",
      "            4.5580e-02, -2.9951e-02],\n",
      "          [ 1.9340e-02, -4.9863e-02, -3.9089e-02,  ...,  2.3901e-02,\n",
      "            2.3983e-02, -3.2759e-02],\n",
      "          [-1.7177e-02,  3.0255e-02,  2.4493e-03,  ..., -1.6106e-02,\n",
      "           -3.9023e-03,  2.8268e-02]],\n",
      "\n",
      "         [[-3.9386e-02,  1.3183e-02, -2.3409e-03,  ...,  3.3697e-02,\n",
      "            4.4816e-02, -2.4628e-02],\n",
      "          [-4.7673e-03, -4.3930e-02, -4.0936e-02,  ...,  4.2236e-02,\n",
      "           -5.0571e-02, -2.6016e-02],\n",
      "          [-4.7765e-02,  2.8272e-02, -4.2810e-02,  ..., -2.1055e-03,\n",
      "           -4.9556e-02, -2.6571e-02],\n",
      "          ...,\n",
      "          [ 7.5400e-03,  1.5923e-02,  2.2183e-02,  ...,  3.2660e-02,\n",
      "           -9.5308e-03, -3.5229e-02],\n",
      "          [ 4.1395e-02,  1.8096e-02,  2.2205e-03,  ...,  1.3563e-03,\n",
      "           -8.5185e-03, -3.2553e-02],\n",
      "          [-3.5137e-02,  3.8557e-02, -1.5589e-02,  ...,  3.5417e-02,\n",
      "            3.0349e-02,  2.4647e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6121e-03,  1.0802e-02,  6.7798e-03,  ...,  3.5228e-02,\n",
      "            4.8624e-02, -3.5910e-02],\n",
      "          [ 3.1902e-02, -1.6478e-02, -5.0511e-02,  ...,  4.6499e-02,\n",
      "           -1.9519e-02, -4.6986e-02],\n",
      "          [ 3.2024e-02, -5.1838e-02, -6.8354e-03,  ...,  1.8499e-02,\n",
      "            3.6933e-02,  3.2474e-02],\n",
      "          ...,\n",
      "          [ 1.2259e-02, -5.1075e-02,  3.4401e-02,  ...,  4.6388e-04,\n",
      "           -4.2991e-02, -4.8831e-02],\n",
      "          [-1.1738e-02,  3.3574e-04,  2.2503e-02,  ...,  4.4318e-02,\n",
      "            4.5163e-03, -3.1640e-03],\n",
      "          [ 5.1225e-02, -8.5686e-03, -2.1360e-03,  ...,  1.9288e-02,\n",
      "            3.4231e-03,  3.3648e-02]],\n",
      "\n",
      "         [[-3.2169e-04, -2.0687e-02, -5.8990e-03,  ..., -2.1102e-02,\n",
      "            3.2457e-02,  2.5961e-02],\n",
      "          [ 3.7318e-02, -2.4741e-02, -1.5509e-02,  ...,  3.8694e-02,\n",
      "           -4.0030e-02, -9.4505e-03],\n",
      "          [ 4.5071e-02, -2.3166e-02, -4.2427e-02,  ..., -4.9002e-02,\n",
      "            1.8839e-02,  4.1071e-02],\n",
      "          ...,\n",
      "          [-4.2930e-03, -4.5721e-02, -1.3875e-02,  ..., -1.0267e-03,\n",
      "            1.5324e-02,  4.3596e-02],\n",
      "          [-2.7297e-02, -9.0016e-03, -5.1719e-03,  ...,  3.7738e-02,\n",
      "           -2.5635e-02, -1.3305e-02],\n",
      "          [ 3.4740e-03, -2.7287e-02,  2.7612e-02,  ..., -3.3383e-02,\n",
      "            1.6093e-02,  3.4119e-02]],\n",
      "\n",
      "         [[ 1.9967e-02,  2.8733e-03,  1.3069e-02,  ...,  4.5623e-02,\n",
      "           -1.9121e-02, -4.5148e-02],\n",
      "          [ 1.7126e-03, -2.5273e-02,  2.6901e-02,  ..., -4.7927e-02,\n",
      "            4.8310e-02, -4.0909e-02],\n",
      "          [-4.3307e-02,  4.6068e-03,  2.5339e-02,  ..., -9.5734e-04,\n",
      "            3.5668e-02, -1.2183e-02],\n",
      "          ...,\n",
      "          [-4.3025e-02, -1.4998e-02, -4.3367e-02,  ...,  5.0074e-02,\n",
      "           -3.8519e-02,  4.3415e-02],\n",
      "          [-5.8731e-03,  1.9986e-02,  2.5103e-02,  ...,  4.0278e-02,\n",
      "           -6.6237e-04, -2.9484e-03],\n",
      "          [-2.3951e-03,  1.5714e-03, -2.3549e-02,  ..., -2.5461e-02,\n",
      "            3.3753e-02,  7.2173e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6732e-02, -2.0975e-02, -5.2112e-02,  ...,  2.8708e-02,\n",
      "           -3.2724e-02,  3.0426e-02],\n",
      "          [ 7.2127e-03, -2.2407e-02,  2.5977e-02,  ..., -3.4245e-02,\n",
      "           -4.5501e-05, -1.9087e-02],\n",
      "          [-3.0441e-02,  4.0312e-02, -1.1574e-02,  ...,  3.4625e-02,\n",
      "            4.9186e-02, -3.7431e-02],\n",
      "          ...,\n",
      "          [ 1.4208e-02, -3.3834e-02,  2.7963e-02,  ...,  1.9157e-02,\n",
      "            3.2257e-02,  3.0828e-03],\n",
      "          [ 3.7110e-02,  3.6298e-02, -4.3138e-02,  ..., -2.5745e-02,\n",
      "           -4.3532e-02, -4.8654e-02],\n",
      "          [ 2.8671e-03, -2.0213e-02,  4.3028e-02,  ...,  2.0380e-03,\n",
      "            6.9105e-03, -5.3275e-03]],\n",
      "\n",
      "         [[ 4.1348e-02,  3.1460e-02,  2.3528e-02,  ...,  8.5865e-03,\n",
      "            1.6666e-02, -1.0589e-02],\n",
      "          [-2.7385e-02,  4.4108e-02, -2.2831e-02,  ...,  3.3105e-02,\n",
      "            4.6882e-02,  4.1989e-02],\n",
      "          [-7.8456e-03, -1.3262e-02, -5.0305e-02,  ..., -1.6880e-02,\n",
      "            4.1053e-02, -1.4123e-03],\n",
      "          ...,\n",
      "          [-3.1865e-02, -3.2664e-02,  4.0227e-02,  ...,  3.8943e-02,\n",
      "            2.5759e-02,  4.5264e-02],\n",
      "          [-4.5858e-02,  2.7819e-02,  1.9089e-02,  ..., -3.0898e-02,\n",
      "           -9.4812e-03,  6.3280e-03],\n",
      "          [ 1.7681e-02,  2.5660e-02,  3.2404e-02,  ..., -3.7751e-02,\n",
      "           -1.3716e-02,  3.5826e-02]],\n",
      "\n",
      "         [[ 4.3600e-02,  1.6369e-02, -3.0445e-02,  ..., -3.7326e-02,\n",
      "           -4.0831e-02, -9.4984e-03],\n",
      "          [-1.7236e-02,  2.3277e-02, -8.2891e-03,  ...,  4.5711e-03,\n",
      "            1.2946e-02,  1.8859e-02],\n",
      "          [ 1.8500e-03,  5.0272e-03, -5.0566e-02,  ..., -5.1942e-02,\n",
      "            4.2184e-02,  3.5546e-02],\n",
      "          ...,\n",
      "          [ 3.1535e-03,  2.8553e-02, -3.0869e-02,  ...,  2.8263e-03,\n",
      "           -3.2913e-02, -2.1055e-02],\n",
      "          [-1.2052e-02, -2.8080e-02, -3.1966e-02,  ...,  2.6639e-02,\n",
      "            1.2449e-02, -9.3036e-03],\n",
      "          [ 1.8860e-02,  4.8819e-02,  8.0067e-03,  ...,  4.0299e-02,\n",
      "            4.3048e-02, -1.5698e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.8150e-02, -4.8222e-02, -5.0760e-02,  ..., -1.3057e-02,\n",
      "           -1.8506e-02,  7.1284e-03],\n",
      "          [ 2.4668e-02,  1.6812e-02, -5.5405e-03,  ..., -4.9437e-02,\n",
      "           -4.4762e-02,  1.4383e-02],\n",
      "          [-1.9830e-02, -1.1820e-02, -1.6248e-03,  ...,  6.1994e-03,\n",
      "           -1.1925e-02, -4.8271e-02],\n",
      "          ...,\n",
      "          [ 2.7934e-02, -2.2206e-02,  2.0347e-02,  ..., -3.1290e-02,\n",
      "            2.0300e-02, -4.7374e-02],\n",
      "          [ 3.1210e-02, -5.2361e-02, -5.4278e-03,  ..., -3.4075e-02,\n",
      "            3.6733e-02, -2.5692e-02],\n",
      "          [ 4.8232e-02, -9.9579e-03, -5.2273e-02,  ...,  2.6020e-02,\n",
      "           -1.7090e-03, -4.9294e-02]],\n",
      "\n",
      "         [[-1.7208e-02, -2.3201e-02,  5.0784e-02,  ..., -1.3115e-02,\n",
      "           -3.1552e-02,  1.4433e-02],\n",
      "          [-2.5574e-02, -3.1532e-02,  2.3335e-02,  ...,  3.7510e-03,\n",
      "           -4.5404e-02, -2.0260e-02],\n",
      "          [-1.2930e-02, -2.5357e-02, -1.5410e-02,  ..., -4.6563e-02,\n",
      "            1.7578e-02, -1.8058e-02],\n",
      "          ...,\n",
      "          [ 2.4083e-02, -3.9235e-02, -2.8697e-02,  ..., -6.0309e-03,\n",
      "           -1.1252e-02, -2.3188e-02],\n",
      "          [ 2.1053e-02, -3.3793e-03, -3.2828e-02,  ..., -1.2019e-02,\n",
      "           -4.6755e-02, -4.3452e-02],\n",
      "          [ 3.9004e-02, -1.9424e-03,  2.7064e-02,  ..., -3.7035e-02,\n",
      "           -5.0547e-02, -3.3572e-02]],\n",
      "\n",
      "         [[-5.1363e-02, -2.0056e-02,  4.3694e-02,  ...,  2.6144e-02,\n",
      "           -1.6548e-02, -2.7593e-02],\n",
      "          [-3.1433e-02,  1.5768e-02, -3.8373e-02,  ...,  3.5207e-02,\n",
      "           -3.5336e-02,  4.9771e-02],\n",
      "          [-3.9616e-03, -2.0886e-02,  1.7647e-02,  ..., -2.9729e-02,\n",
      "            1.6691e-02, -7.1941e-03],\n",
      "          ...,\n",
      "          [-1.7017e-02, -2.3570e-02, -4.5737e-02,  ...,  2.1416e-02,\n",
      "            2.4675e-02, -1.1671e-02],\n",
      "          [-5.0096e-02,  4.9683e-02,  2.8351e-02,  ..., -3.5158e-02,\n",
      "            1.6401e-02, -2.0738e-02],\n",
      "          [-4.9928e-02, -1.6531e-03, -2.9834e-02,  ..., -3.3404e-03,\n",
      "            2.1511e-02, -1.6600e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7801e-03,  3.8836e-02,  2.6397e-02,  ..., -4.9020e-02,\n",
      "            4.7624e-02,  2.3975e-02],\n",
      "          [-4.8347e-03,  2.7443e-02, -3.9416e-02,  ..., -3.8727e-02,\n",
      "           -3.9637e-02,  3.1091e-02],\n",
      "          [ 1.0587e-02, -1.5138e-02, -3.4825e-02,  ...,  2.0364e-02,\n",
      "            2.3103e-03, -3.1623e-02],\n",
      "          ...,\n",
      "          [-4.3949e-02, -1.4560e-02,  5.0227e-02,  ..., -3.9283e-02,\n",
      "           -3.0506e-04,  3.8973e-02],\n",
      "          [-3.9746e-02,  4.5634e-02, -3.9233e-02,  ...,  2.1798e-02,\n",
      "            4.6095e-02,  3.0536e-02],\n",
      "          [ 5.0139e-02,  4.8979e-02,  3.4438e-02,  ..., -4.1059e-02,\n",
      "           -2.4978e-02, -3.2371e-02]],\n",
      "\n",
      "         [[ 3.0364e-02, -9.7634e-03, -2.6206e-02,  ...,  4.7409e-03,\n",
      "            2.8378e-02, -2.2199e-02],\n",
      "          [ 2.6426e-02,  4.8792e-02, -1.4087e-02,  ..., -3.9308e-02,\n",
      "            1.2647e-03, -1.9060e-02],\n",
      "          [ 3.5399e-02, -3.2298e-02,  2.2562e-02,  ...,  2.6657e-02,\n",
      "            2.6178e-02, -1.0840e-02],\n",
      "          ...,\n",
      "          [-4.9449e-02, -4.3880e-02, -2.3674e-02,  ..., -4.7226e-02,\n",
      "            2.8660e-02, -4.4465e-02],\n",
      "          [ 2.4965e-02, -3.4046e-02, -9.6585e-03,  ..., -2.7149e-02,\n",
      "           -6.9433e-03, -1.8955e-02],\n",
      "          [-4.4577e-02, -5.1352e-02, -2.0438e-02,  ...,  2.3594e-02,\n",
      "           -4.0516e-02,  1.2230e-02]],\n",
      "\n",
      "         [[-2.9387e-02,  2.0360e-02, -3.0545e-02,  ...,  4.8348e-02,\n",
      "           -4.7662e-02,  4.0908e-02],\n",
      "          [ 1.7631e-02, -9.4271e-03,  2.5046e-02,  ...,  5.0423e-02,\n",
      "           -1.8103e-02, -3.5914e-02],\n",
      "          [-2.3208e-02, -6.5636e-03,  1.5071e-02,  ..., -1.7656e-02,\n",
      "           -1.8409e-02,  4.7193e-02],\n",
      "          ...,\n",
      "          [-8.7788e-04, -2.4292e-02, -1.4792e-02,  ...,  2.3024e-02,\n",
      "           -4.3337e-02,  1.3614e-02],\n",
      "          [-2.4746e-02, -3.5960e-02, -4.8792e-04,  ..., -3.2768e-02,\n",
      "           -5.0321e-02, -4.5105e-02],\n",
      "          [-1.7502e-02, -1.4735e-03,  2.8516e-02,  ..., -3.1797e-02,\n",
      "            5.1025e-02, -2.7203e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5581e-02, -1.9288e-02,  3.2008e-02,  ...,  9.6629e-03,\n",
      "           -4.4615e-02, -3.9074e-02],\n",
      "          [-3.2496e-02,  1.1563e-02, -5.8657e-03,  ...,  2.2128e-02,\n",
      "           -2.6986e-02,  1.0687e-02],\n",
      "          [-3.9469e-02,  2.5038e-02,  9.8506e-03,  ..., -3.4935e-02,\n",
      "           -1.3838e-02,  1.2595e-02],\n",
      "          ...,\n",
      "          [-8.5388e-03,  1.5265e-02,  2.5339e-02,  ...,  5.7669e-03,\n",
      "            4.4943e-02, -2.8256e-02],\n",
      "          [-3.7056e-02, -3.3886e-02,  1.5691e-02,  ..., -2.8517e-02,\n",
      "           -9.0318e-03, -2.4488e-02],\n",
      "          [-2.1740e-02, -1.2277e-02,  2.9555e-02,  ...,  3.5918e-02,\n",
      "            3.8331e-02,  3.6974e-02]],\n",
      "\n",
      "         [[-3.6092e-02,  3.6674e-02,  3.1413e-02,  ..., -2.7481e-02,\n",
      "           -4.4902e-02, -3.5932e-02],\n",
      "          [-1.9238e-02, -3.1458e-02, -4.0409e-02,  ..., -4.0062e-02,\n",
      "            1.2219e-03, -2.6246e-02],\n",
      "          [-4.9813e-02, -1.1230e-02,  3.8692e-02,  ...,  1.0228e-02,\n",
      "           -5.1442e-02, -2.8123e-02],\n",
      "          ...,\n",
      "          [ 3.5980e-02,  3.7589e-02,  3.1550e-02,  ...,  1.4498e-02,\n",
      "           -3.8374e-02,  4.3045e-02],\n",
      "          [-1.7238e-02, -4.3260e-02, -1.4935e-02,  ...,  3.4734e-02,\n",
      "           -3.5417e-03, -2.8583e-02],\n",
      "          [-4.7685e-02, -3.7181e-02,  1.3418e-02,  ..., -4.2982e-02,\n",
      "           -3.9557e-02,  9.3067e-03]],\n",
      "\n",
      "         [[-3.9374e-02, -2.6748e-03,  1.6446e-02,  ...,  9.2629e-03,\n",
      "            4.4399e-02, -4.5498e-03],\n",
      "          [-5.0945e-02, -4.2141e-03,  3.1195e-02,  ..., -6.6836e-03,\n",
      "            1.4295e-02,  1.5307e-03],\n",
      "          [ 1.5205e-02,  2.1091e-02, -1.3646e-02,  ...,  3.6010e-02,\n",
      "           -6.1899e-03, -3.9307e-02],\n",
      "          ...,\n",
      "          [ 1.2988e-02, -3.5025e-02, -1.2414e-02,  ..., -3.9982e-03,\n",
      "            2.2344e-02,  2.0681e-02],\n",
      "          [-1.4726e-02,  4.4114e-02,  1.4665e-02,  ..., -1.8884e-02,\n",
      "           -3.3251e-02, -1.4596e-02],\n",
      "          [ 1.1559e-02,  4.1993e-02,  9.2847e-03,  ...,  1.2950e-02,\n",
      "            2.1476e-02, -4.3904e-02]]]])), ('convolution_block1.0.bias', tensor([-0.0482,  0.0155,  0.0333, -0.0157,  0.0027,  0.0093, -0.0518, -0.0238,\n",
      "         0.0146,  0.0288,  0.0301,  0.0350, -0.0069, -0.0157,  0.0394, -0.0520,\n",
      "         0.0488,  0.0375,  0.0506,  0.0369, -0.0079, -0.0498,  0.0070, -0.0199,\n",
      "        -0.0402,  0.0195, -0.0414,  0.0090, -0.0213,  0.0111,  0.0515,  0.0126,\n",
      "        -0.0018,  0.0380,  0.0339, -0.0508, -0.0300, -0.0355, -0.0346, -0.0448,\n",
      "         0.0099,  0.0040, -0.0381,  0.0202, -0.0216, -0.0006,  0.0323,  0.0012,\n",
      "        -0.0498, -0.0446,  0.0250,  0.0036, -0.0140, -0.0455,  0.0028, -0.0448,\n",
      "        -0.0375,  0.0151,  0.0459, -0.0174,  0.0239,  0.0490,  0.0413, -0.0250,\n",
      "        -0.0104, -0.0400, -0.0140,  0.0223,  0.0112, -0.0075,  0.0470, -0.0095,\n",
      "         0.0157, -0.0375,  0.0115, -0.0410, -0.0042, -0.0218, -0.0355, -0.0122,\n",
      "        -0.0297, -0.0523, -0.0012,  0.0506, -0.0487,  0.0413,  0.0507,  0.0364,\n",
      "         0.0412,  0.0030, -0.0130, -0.0177,  0.0164,  0.0062, -0.0302,  0.0028])), ('convolution_block1.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])), ('convolution_block1.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block1.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block1.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])), ('convolution_block1.1.num_batches_tracked', tensor(0)), ('convolution_block2.0.weight', tensor([[[[ 1.4540e-02,  5.7580e-03, -1.5054e-02, -1.1305e-02, -1.0066e-02],\n",
      "          [-9.3385e-03, -1.4950e-02,  4.3024e-03,  7.2641e-03, -2.0627e-03],\n",
      "          [ 8.1786e-03, -8.6423e-03,  8.2927e-03,  1.7543e-02, -4.9832e-03],\n",
      "          [-1.4243e-02,  1.7380e-02,  1.1964e-02, -1.8176e-02, -9.7693e-03],\n",
      "          [ 6.2391e-03,  1.2011e-02,  1.0988e-02,  1.7896e-02, -4.2506e-03]],\n",
      "\n",
      "         [[-4.6584e-03,  1.2243e-02,  2.0164e-02,  1.5675e-02, -9.6300e-03],\n",
      "          [ 3.5640e-03, -7.6296e-03, -1.4100e-02,  8.8534e-03,  1.7485e-02],\n",
      "          [-1.7401e-02,  1.2867e-02,  1.3132e-02, -5.7202e-03,  9.8947e-03],\n",
      "          [-1.2539e-02, -5.3903e-03,  1.2775e-02, -1.6376e-02,  1.4948e-02],\n",
      "          [-1.8665e-02, -6.1044e-03, -8.0400e-03, -1.6525e-02, -9.1710e-03]],\n",
      "\n",
      "         [[-6.0901e-03,  6.4594e-03,  1.6983e-02,  1.5851e-02, -3.2983e-04],\n",
      "          [-5.1563e-03, -9.7932e-04,  2.0236e-02, -1.0053e-02,  2.1024e-03],\n",
      "          [-1.3042e-02,  1.0453e-02, -2.9277e-03,  8.1164e-03, -7.7838e-03],\n",
      "          [-2.9815e-03,  4.1090e-03, -2.0236e-02, -1.2077e-02,  1.3871e-02],\n",
      "          [ 1.4321e-02, -1.3550e-03, -1.8024e-03,  1.6219e-02,  1.7184e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0304e-02,  1.7765e-02,  1.5959e-02, -1.9934e-02, -2.6059e-03],\n",
      "          [-2.0190e-02, -1.0572e-02, -1.1873e-02,  1.3740e-02,  8.9070e-03],\n",
      "          [-1.8966e-02,  4.1813e-03,  9.2746e-04,  1.6985e-02,  7.9704e-03],\n",
      "          [ 1.5554e-03,  4.7805e-03,  9.4790e-03, -7.7384e-03,  5.5547e-03],\n",
      "          [ 4.2260e-03,  5.2243e-03,  1.7592e-02, -1.9741e-02,  3.8667e-03]],\n",
      "\n",
      "         [[-4.3939e-03, -2.8477e-04,  4.9478e-03, -6.4495e-03, -7.3779e-03],\n",
      "          [-8.6093e-03, -4.4663e-03,  9.5607e-03, -1.2985e-02, -1.7380e-03],\n",
      "          [-1.8404e-02,  1.8183e-02,  1.7029e-03,  1.4255e-02,  1.1507e-02],\n",
      "          [ 5.8325e-03,  2.0398e-02, -1.7799e-02, -1.0814e-02, -7.2861e-03],\n",
      "          [ 1.1883e-02,  5.2044e-03, -2.0688e-03,  2.9179e-04,  2.8460e-03]],\n",
      "\n",
      "         [[-7.4345e-03,  1.5722e-02, -1.4809e-02, -1.5760e-02, -9.2336e-04],\n",
      "          [-6.9417e-03,  8.9580e-03, -1.6071e-02,  6.6472e-03,  1.5447e-02],\n",
      "          [-1.3066e-02, -1.0838e-02, -1.9222e-02, -1.8144e-02, -5.1492e-03],\n",
      "          [-1.1436e-02,  1.7737e-02, -4.5408e-03, -9.6200e-03, -3.9639e-03],\n",
      "          [-8.0056e-03, -1.3866e-02,  1.2874e-02, -5.3283e-03,  9.6331e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.3820e-03,  6.3729e-05,  5.0295e-03, -1.0484e-02,  1.8272e-02],\n",
      "          [ 1.8995e-02,  1.3500e-02, -4.3875e-03, -2.0191e-02, -1.9997e-02],\n",
      "          [ 1.4341e-02, -5.5692e-03,  8.4524e-03,  1.5454e-03, -2.2586e-03],\n",
      "          [-9.5639e-03,  1.8140e-02,  1.4403e-02,  8.2583e-03, -8.3288e-03],\n",
      "          [ 1.8563e-02,  1.6598e-02,  2.7749e-03,  7.8644e-03, -1.5146e-03]],\n",
      "\n",
      "         [[ 5.4137e-03,  1.2031e-03,  9.0897e-03,  1.7772e-02,  3.3738e-03],\n",
      "          [-7.3832e-03,  6.0243e-03, -1.7967e-02,  1.2149e-02, -6.5628e-03],\n",
      "          [ 1.3993e-02, -1.2918e-02, -1.9204e-02,  1.8847e-02,  1.2917e-02],\n",
      "          [-9.7500e-03, -1.9642e-02,  5.5144e-03, -6.4524e-03, -1.7834e-02],\n",
      "          [ 6.6353e-03,  6.3570e-03, -1.9502e-02, -2.8074e-03, -1.8488e-02]],\n",
      "\n",
      "         [[-1.1384e-02, -1.9853e-02,  6.1193e-03, -1.2923e-02,  1.2682e-02],\n",
      "          [ 1.4718e-02,  1.5155e-02, -1.9321e-02,  1.9772e-02, -5.1712e-04],\n",
      "          [-1.3656e-02,  4.0256e-04, -8.4401e-03, -1.0558e-02, -1.6702e-02],\n",
      "          [-1.1075e-03, -1.5782e-03, -1.4563e-02,  1.7106e-02,  5.0982e-03],\n",
      "          [ 3.9397e-04, -1.8483e-02, -1.8788e-02, -2.9296e-03,  6.2743e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.0232e-03,  1.4246e-02,  5.4555e-03,  1.8481e-02, -1.3583e-02],\n",
      "          [-1.0530e-02, -1.8918e-03, -8.5633e-04, -1.5118e-02, -1.3107e-02],\n",
      "          [-6.9281e-03, -1.1459e-02,  2.1852e-03,  8.3527e-03,  1.6199e-02],\n",
      "          [ 9.3064e-03, -7.9441e-03, -1.2892e-02, -7.7699e-03, -2.8772e-03],\n",
      "          [-7.6828e-03, -4.1325e-03,  5.7109e-03,  5.6404e-03,  1.3411e-02]],\n",
      "\n",
      "         [[-1.4796e-02, -1.3482e-02, -1.7836e-02,  9.3610e-03,  3.3188e-03],\n",
      "          [-1.8319e-02,  3.4416e-03,  1.2546e-02,  9.5866e-03, -1.7643e-02],\n",
      "          [ 1.1498e-02, -1.1551e-02, -5.2792e-03,  1.6418e-02,  1.5628e-02],\n",
      "          [ 1.3330e-02,  1.6862e-02, -1.5564e-02,  1.2169e-02,  4.3265e-04],\n",
      "          [-8.4438e-03,  9.2084e-03, -1.5972e-02,  1.9870e-02,  3.2108e-03]],\n",
      "\n",
      "         [[-1.1932e-02,  1.4544e-02,  9.7049e-03,  9.0259e-03,  1.3209e-02],\n",
      "          [-1.6941e-02, -1.4714e-02,  3.8086e-03, -3.2519e-03,  1.8683e-03],\n",
      "          [ 5.3088e-03, -1.1626e-02, -1.3089e-02,  1.2107e-02,  1.2865e-02],\n",
      "          [-1.0775e-02, -1.5793e-02,  7.2149e-03, -1.7197e-02, -1.4287e-02],\n",
      "          [ 9.4786e-03, -2.0405e-02, -1.5598e-03,  1.3778e-02, -1.5327e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4098e-02, -1.1862e-02, -6.9363e-03, -1.2562e-02, -1.9627e-02],\n",
      "          [-4.0647e-03,  8.8241e-03, -9.3666e-03,  1.1135e-02, -6.6213e-03],\n",
      "          [ 1.8229e-02, -1.6382e-02, -1.5200e-02, -1.8816e-02, -5.8207e-03],\n",
      "          [ 1.3835e-03,  1.0876e-02,  2.3907e-03, -1.8735e-04,  2.6853e-04],\n",
      "          [ 2.5917e-03,  1.7081e-03,  1.1658e-03,  1.8339e-02, -7.6587e-03]],\n",
      "\n",
      "         [[ 3.8933e-03, -5.6401e-03,  5.7147e-03,  6.2069e-03,  3.1609e-06],\n",
      "          [ 1.0296e-02,  7.0092e-03, -1.8720e-03, -2.2391e-04,  4.9506e-03],\n",
      "          [ 1.3312e-03, -1.2415e-02,  5.9995e-03,  1.3193e-02, -1.0633e-02],\n",
      "          [-4.6606e-03,  1.2852e-02, -1.9752e-02,  4.6740e-03,  4.5442e-03],\n",
      "          [ 8.8183e-03, -2.4065e-03,  1.6523e-03, -2.0038e-03, -2.2925e-04]],\n",
      "\n",
      "         [[-1.9470e-04, -1.8441e-02,  5.4129e-03,  9.1630e-03, -1.6958e-02],\n",
      "          [ 1.9102e-02, -2.0211e-02, -2.1896e-04, -4.2517e-03,  2.8884e-03],\n",
      "          [ 4.5050e-03,  2.7985e-04, -9.0236e-05, -8.5104e-03, -9.8651e-03],\n",
      "          [-1.2653e-02, -1.2769e-02, -1.7662e-02, -4.8207e-03,  2.0211e-02],\n",
      "          [-3.3785e-03, -1.0416e-02, -8.5185e-03,  1.9123e-02, -1.4236e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9014e-02, -1.5601e-02, -1.0941e-02,  1.9279e-02, -1.9704e-03],\n",
      "          [-1.3594e-02, -1.4340e-03, -1.9431e-02,  2.0066e-02, -8.1565e-05],\n",
      "          [ 5.8891e-03, -1.8497e-02, -6.1351e-03,  1.3742e-02,  3.3632e-03],\n",
      "          [-3.7643e-03,  3.8271e-03,  9.0601e-03,  7.2472e-03,  1.6257e-02],\n",
      "          [ 1.1281e-02, -1.2380e-02, -1.6065e-02,  8.6362e-03, -1.8220e-02]],\n",
      "\n",
      "         [[-1.1693e-02, -1.3134e-02,  1.2417e-02, -1.0957e-02, -2.9062e-03],\n",
      "          [-9.6811e-03, -1.5413e-02, -3.0580e-03, -1.1051e-02, -1.3584e-02],\n",
      "          [-1.8907e-02,  1.4392e-02, -1.8741e-02, -1.2902e-02, -1.4580e-02],\n",
      "          [-1.9241e-03, -1.5123e-02,  1.3791e-03, -1.6254e-02,  7.7172e-03],\n",
      "          [ 8.3851e-03,  4.1813e-03, -1.6973e-02,  4.5810e-03, -1.6248e-02]],\n",
      "\n",
      "         [[-7.5235e-03, -8.4180e-03, -1.5000e-02, -1.0730e-02, -3.8487e-03],\n",
      "          [ 1.0985e-03,  8.1104e-03,  2.1471e-03,  6.8737e-03, -1.5004e-02],\n",
      "          [-1.4095e-02,  1.9832e-02, -9.8769e-04,  1.2593e-02,  2.0282e-02],\n",
      "          [-6.9917e-03, -1.7936e-02,  1.1966e-03,  4.6804e-03, -1.0778e-02],\n",
      "          [-5.2205e-03, -8.7462e-03, -1.5189e-03,  1.2941e-02,  1.9077e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.5614e-04, -5.7825e-03,  1.1287e-02, -3.4176e-03, -7.5336e-03],\n",
      "          [-1.3121e-02, -1.7728e-02,  9.5326e-04, -1.4870e-02, -5.2292e-03],\n",
      "          [ 2.0336e-02,  6.4257e-03, -1.9831e-02, -4.0177e-03, -1.0812e-02],\n",
      "          [ 5.7337e-03, -1.1760e-02,  1.1731e-02,  7.0379e-03, -6.2461e-03],\n",
      "          [-1.5579e-02, -4.2709e-03,  1.8137e-02,  9.3112e-03, -4.4384e-03]],\n",
      "\n",
      "         [[-1.9940e-02,  1.1399e-02, -5.8944e-04,  2.1604e-03, -1.0724e-02],\n",
      "          [-5.4727e-03,  8.3629e-03,  7.2813e-03,  5.0437e-03,  1.3043e-02],\n",
      "          [-5.2938e-03, -1.9539e-02, -2.6261e-03,  1.7332e-02, -5.0833e-03],\n",
      "          [ 2.3513e-03,  1.6673e-02,  1.4417e-02, -1.3163e-03, -7.5790e-03],\n",
      "          [-1.8101e-02,  6.1524e-03,  1.9771e-02,  6.0979e-03,  1.1444e-02]],\n",
      "\n",
      "         [[-1.7183e-03,  1.6161e-02, -9.0270e-03,  1.5474e-02, -1.2421e-02],\n",
      "          [ 8.8660e-03,  2.3455e-03, -4.8173e-03,  1.0869e-02,  1.8557e-02],\n",
      "          [ 2.8077e-03,  6.3958e-03, -1.6157e-02, -1.5363e-02, -1.8055e-02],\n",
      "          [-1.4584e-02,  9.7428e-03,  3.5786e-03,  1.9408e-02, -1.7914e-02],\n",
      "          [ 1.3692e-02, -1.7248e-02,  1.9875e-03,  9.0335e-03, -1.3522e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3243e-02,  2.2500e-03,  2.5975e-03,  1.3855e-04,  1.4146e-02],\n",
      "          [ 1.8534e-03, -1.3833e-02, -1.3687e-02, -9.0760e-03, -2.7707e-03],\n",
      "          [-4.5561e-03, -1.6067e-02, -1.1386e-02,  1.0555e-02, -1.3610e-02],\n",
      "          [ 4.8790e-03,  2.0624e-03, -1.3364e-02, -8.8007e-03, -5.3403e-03],\n",
      "          [ 1.8311e-02, -1.4310e-04, -4.4648e-04,  2.3077e-03, -7.5497e-03]],\n",
      "\n",
      "         [[ 1.0602e-02, -1.2051e-02,  4.0676e-04, -1.2594e-02, -1.9643e-03],\n",
      "          [-1.6630e-02,  1.1273e-02, -1.5773e-02, -1.8320e-02,  1.2176e-02],\n",
      "          [-1.9361e-02,  1.3484e-02,  8.0145e-03, -1.2412e-02,  9.7550e-03],\n",
      "          [-1.2940e-02,  4.7821e-03, -1.5488e-02, -3.0931e-03,  5.3609e-03],\n",
      "          [-1.5014e-02,  1.3707e-02,  4.0677e-03,  9.8732e-03, -3.6281e-03]],\n",
      "\n",
      "         [[ 1.4021e-02,  1.3884e-02, -1.8532e-02,  2.4767e-03, -6.5562e-03],\n",
      "          [-3.5790e-03,  8.3145e-03,  1.0076e-02, -2.9298e-03, -9.8914e-03],\n",
      "          [-1.6325e-02,  9.2455e-03,  1.8916e-02,  1.9984e-02, -1.0836e-02],\n",
      "          [-1.7310e-02, -5.1789e-04,  1.7142e-02, -1.4775e-02, -3.5820e-03],\n",
      "          [ 5.7278e-05,  1.8540e-02, -1.2019e-02, -1.1227e-02, -8.8408e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.8455e-02,  4.0893e-03,  1.0005e-02, -2.8058e-03,  1.7213e-02],\n",
      "          [-1.5537e-02, -2.0240e-02, -1.5592e-03, -1.2878e-02, -1.9959e-02],\n",
      "          [-2.0156e-02, -1.7914e-03, -8.3991e-03,  8.9505e-03, -7.2309e-03],\n",
      "          [ 4.4204e-03, -2.9507e-03, -1.2921e-02,  9.5566e-03,  6.3854e-03],\n",
      "          [ 1.1656e-02, -1.2817e-02,  1.5577e-02, -2.3771e-03,  1.5916e-02]],\n",
      "\n",
      "         [[-9.5924e-03, -1.3060e-02,  1.0771e-02, -1.1814e-02,  1.9756e-02],\n",
      "          [-1.7655e-02, -6.1739e-03,  6.9805e-03, -5.9905e-03, -3.2179e-04],\n",
      "          [-1.7857e-02, -3.8642e-03, -6.3046e-03,  1.1246e-02,  6.2045e-03],\n",
      "          [ 2.0287e-02,  1.8260e-02, -5.0880e-03,  8.0639e-04, -6.6797e-03],\n",
      "          [ 5.6948e-03,  1.7112e-02,  1.0642e-02, -5.9207e-04, -1.2414e-02]],\n",
      "\n",
      "         [[ 9.0475e-03,  1.3132e-03, -1.6121e-02,  1.7067e-02,  1.1120e-02],\n",
      "          [ 1.0254e-02,  1.6245e-02,  3.9987e-03, -7.0346e-03,  1.0526e-02],\n",
      "          [-2.8326e-03, -1.4877e-02, -1.8521e-02,  6.9326e-03,  2.0094e-02],\n",
      "          [-1.7393e-02, -1.2983e-04, -1.1938e-02, -5.1720e-03, -2.1824e-03],\n",
      "          [ 1.5783e-02, -8.7929e-04,  1.6613e-02,  1.2621e-02, -1.4694e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9470e-03,  1.4990e-02,  1.3233e-02,  9.6381e-03, -1.1764e-02],\n",
      "          [-1.7380e-02, -1.4833e-02, -1.2866e-03, -1.2082e-02,  2.6113e-03],\n",
      "          [ 1.6006e-03, -5.3420e-03,  1.8096e-02,  4.6640e-03, -1.6041e-02],\n",
      "          [-6.1797e-03,  1.6522e-02,  1.0869e-02, -8.9792e-03, -4.5416e-03],\n",
      "          [ 7.0539e-04,  1.4911e-02,  1.0285e-03, -3.3117e-03, -3.9843e-03]],\n",
      "\n",
      "         [[ 9.3908e-03,  2.1153e-04, -1.0361e-03,  4.4552e-03,  1.3244e-02],\n",
      "          [ 1.7998e-02, -7.9349e-03, -1.2126e-02,  1.0468e-02, -8.0003e-03],\n",
      "          [-4.6849e-04,  6.8440e-04,  5.6138e-03,  5.9995e-03,  1.9283e-03],\n",
      "          [ 1.4556e-02, -4.7837e-03,  1.5626e-02,  4.2762e-03,  1.0819e-02],\n",
      "          [-9.9765e-03, -1.7817e-03, -1.0328e-02,  4.1248e-03,  1.0676e-02]],\n",
      "\n",
      "         [[-1.1781e-02, -1.4150e-02,  1.2340e-02, -5.4264e-03,  3.3733e-03],\n",
      "          [ 1.4527e-02, -7.2613e-04, -1.3921e-02, -9.5752e-03,  1.0298e-02],\n",
      "          [-2.0280e-02,  1.5922e-02, -1.4080e-02,  4.5486e-03,  3.9166e-03],\n",
      "          [-6.0504e-03,  3.2605e-04, -7.2937e-03,  7.0427e-03, -9.5810e-03],\n",
      "          [ 1.6790e-02,  1.2960e-03, -3.4942e-03, -1.1719e-02,  1.0829e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.6265e-03, -6.1619e-03,  1.4259e-02, -1.9037e-02, -9.2126e-03],\n",
      "          [ 1.8714e-02,  1.8226e-02,  4.9853e-03, -1.2993e-02, -2.0658e-04],\n",
      "          [-1.5540e-02, -1.7774e-02, -1.1475e-02,  1.6141e-02,  6.4395e-03],\n",
      "          [ 2.8441e-03,  1.6632e-02,  1.2227e-02, -1.9729e-02,  1.8071e-02],\n",
      "          [-5.5922e-04, -1.8795e-02,  1.5888e-03, -1.2745e-02,  7.6924e-03]],\n",
      "\n",
      "         [[-8.8641e-03, -1.7503e-02,  1.6970e-02,  8.3868e-03, -8.3269e-03],\n",
      "          [ 5.3384e-03, -2.7223e-03, -1.8528e-02, -1.9457e-02,  1.9215e-02],\n",
      "          [ 1.8680e-02, -6.7166e-03,  8.3503e-03, -5.0241e-03, -1.4321e-02],\n",
      "          [-2.6719e-03,  9.5495e-03,  1.2774e-02, -1.4335e-02, -1.2420e-02],\n",
      "          [-2.5051e-03,  1.0139e-02,  1.5279e-02, -1.3497e-02, -1.0161e-02]],\n",
      "\n",
      "         [[-1.7088e-02,  1.2637e-02, -9.1128e-04,  7.0891e-03,  1.8048e-02],\n",
      "          [-1.1324e-03, -4.3482e-04, -1.3156e-02,  1.8451e-02, -1.7428e-02],\n",
      "          [ 8.3409e-03, -5.1453e-03,  4.7396e-03,  1.9915e-02,  1.3111e-02],\n",
      "          [ 5.9535e-03,  1.7919e-02,  1.6503e-02, -1.0559e-02,  8.4037e-03],\n",
      "          [ 1.0832e-02,  1.9815e-02, -1.7447e-02, -1.1751e-02,  6.2106e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8093e-02,  1.5632e-02,  2.0394e-02, -1.0757e-02,  1.3144e-02],\n",
      "          [-1.7401e-02,  1.6069e-02, -5.1539e-03,  8.1457e-03,  1.0335e-02],\n",
      "          [-1.6185e-02, -4.1900e-03, -1.9152e-02, -1.2125e-02, -1.6483e-03],\n",
      "          [ 1.0434e-02,  1.5549e-02, -1.9887e-02, -5.3594e-03,  1.8506e-02],\n",
      "          [ 1.9494e-02,  3.3557e-03, -4.8613e-03,  4.1867e-03, -1.6852e-02]],\n",
      "\n",
      "         [[ 2.6639e-04, -1.4298e-02,  1.5304e-02,  1.4668e-02, -9.6383e-04],\n",
      "          [ 7.6160e-03,  1.9670e-02, -9.6055e-03,  2.0141e-02,  1.1778e-02],\n",
      "          [ 1.0674e-02,  4.4299e-03,  5.4964e-03, -1.9194e-02, -6.0240e-03],\n",
      "          [-8.3595e-03, -9.3959e-04, -2.0129e-02, -6.7012e-03, -5.0974e-03],\n",
      "          [ 5.7178e-03,  2.0228e-02, -1.1413e-02,  1.4021e-02, -1.7682e-02]],\n",
      "\n",
      "         [[ 1.3660e-02,  1.4321e-02, -6.6621e-03, -5.8036e-03, -7.7331e-03],\n",
      "          [ 1.6956e-02,  4.8739e-03, -5.7962e-03,  1.8820e-02,  7.5635e-03],\n",
      "          [ 1.0423e-02,  1.8529e-02,  1.5071e-03, -1.7824e-02, -1.6710e-02],\n",
      "          [-4.6295e-04,  3.6254e-03,  6.7600e-03,  5.2743e-03, -4.0154e-04],\n",
      "          [ 1.7162e-02, -1.3659e-02,  1.8423e-02,  9.7566e-03,  3.8020e-03]]]])), ('convolution_block2.0.bias', tensor([-0.0043,  0.0004,  0.0130, -0.0183, -0.0148,  0.0155, -0.0012,  0.0202,\n",
      "        -0.0147, -0.0090, -0.0080,  0.0045,  0.0035, -0.0184, -0.0016,  0.0085,\n",
      "        -0.0169, -0.0180,  0.0174, -0.0043, -0.0186, -0.0092, -0.0023, -0.0177,\n",
      "        -0.0009,  0.0178,  0.0038, -0.0105, -0.0020,  0.0123,  0.0003,  0.0033,\n",
      "        -0.0059,  0.0101, -0.0114,  0.0114, -0.0018, -0.0106,  0.0143,  0.0102,\n",
      "         0.0174, -0.0070, -0.0198, -0.0095, -0.0163,  0.0028,  0.0119, -0.0112,\n",
      "        -0.0148,  0.0127, -0.0032,  0.0101,  0.0064,  0.0118,  0.0199, -0.0056,\n",
      "         0.0103,  0.0161,  0.0187, -0.0196, -0.0110, -0.0164,  0.0188,  0.0117,\n",
      "        -0.0154,  0.0137,  0.0155,  0.0062, -0.0175, -0.0158,  0.0004, -0.0091,\n",
      "         0.0117,  0.0160, -0.0148, -0.0029, -0.0195,  0.0152, -0.0055, -0.0200,\n",
      "         0.0141, -0.0115,  0.0177,  0.0100,  0.0131, -0.0049,  0.0074,  0.0074,\n",
      "         0.0113,  0.0090, -0.0133, -0.0199, -0.0127, -0.0181, -0.0084,  0.0168,\n",
      "        -0.0088,  0.0129, -0.0130, -0.0046, -0.0097,  0.0198,  0.0071,  0.0063,\n",
      "         0.0003,  0.0064, -0.0098, -0.0061,  0.0082, -0.0115,  0.0080,  0.0167,\n",
      "         0.0073,  0.0069,  0.0178, -0.0053,  0.0016, -0.0089, -0.0164,  0.0204,\n",
      "        -0.0004,  0.0017, -0.0047,  0.0191,  0.0154, -0.0075,  0.0170,  0.0044,\n",
      "         0.0043,  0.0039, -0.0015,  0.0166, -0.0087, -0.0025,  0.0193,  0.0077,\n",
      "         0.0068, -0.0167, -0.0057,  0.0067, -0.0016,  0.0126,  0.0179,  0.0057,\n",
      "        -0.0053, -0.0069, -0.0069,  0.0063,  0.0042,  0.0091, -0.0031,  0.0166,\n",
      "         0.0121,  0.0027,  0.0007, -0.0103, -0.0165,  0.0156, -0.0171, -0.0127,\n",
      "        -0.0097,  0.0186,  0.0178,  0.0139,  0.0016,  0.0166, -0.0073, -0.0033,\n",
      "        -0.0152,  0.0062,  0.0156, -0.0155, -0.0017, -0.0199, -0.0048,  0.0045,\n",
      "        -0.0140, -0.0044,  0.0091, -0.0079,  0.0073,  0.0199,  0.0044, -0.0100,\n",
      "         0.0039,  0.0185, -0.0113,  0.0002, -0.0083,  0.0005,  0.0006,  0.0040,\n",
      "         0.0109, -0.0111,  0.0074,  0.0154,  0.0153,  0.0195, -0.0170, -0.0099,\n",
      "         0.0081, -0.0061, -0.0200,  0.0093, -0.0188,  0.0058, -0.0061, -0.0035,\n",
      "         0.0099,  0.0030,  0.0133, -0.0137,  0.0204,  0.0189, -0.0089,  0.0076,\n",
      "         0.0079, -0.0142,  0.0001, -0.0029,  0.0010, -0.0042, -0.0125,  0.0195,\n",
      "        -0.0020, -0.0171, -0.0097,  0.0179, -0.0171, -0.0145, -0.0155, -0.0099,\n",
      "        -0.0011, -0.0062,  0.0149,  0.0080,  0.0099,  0.0003, -0.0119,  0.0078,\n",
      "        -0.0165, -0.0118,  0.0075, -0.0113, -0.0049, -0.0174,  0.0033,  0.0188,\n",
      "        -0.0188, -0.0155,  0.0158, -0.0178, -0.0180,  0.0127, -0.0191,  0.0148])), ('convolution_block2.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])), ('convolution_block2.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block2.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block2.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])), ('convolution_block2.1.num_batches_tracked', tensor(0)), ('convolution_block3.0.weight', tensor([[[[-0.0103,  0.0145,  0.0071],\n",
      "          [-0.0081, -0.0042, -0.0193],\n",
      "          [ 0.0042, -0.0071, -0.0086]],\n",
      "\n",
      "         [[ 0.0173, -0.0180, -0.0153],\n",
      "          [ 0.0199, -0.0019, -0.0134],\n",
      "          [ 0.0083,  0.0136, -0.0091]],\n",
      "\n",
      "         [[ 0.0003,  0.0090, -0.0052],\n",
      "          [ 0.0095, -0.0145, -0.0117],\n",
      "          [-0.0124, -0.0101, -0.0046]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0145,  0.0036, -0.0199],\n",
      "          [-0.0079, -0.0112, -0.0137],\n",
      "          [ 0.0118,  0.0050,  0.0028]],\n",
      "\n",
      "         [[-0.0078, -0.0104, -0.0183],\n",
      "          [ 0.0151,  0.0060, -0.0066],\n",
      "          [-0.0145,  0.0127,  0.0205]],\n",
      "\n",
      "         [[-0.0198, -0.0167,  0.0033],\n",
      "          [-0.0160,  0.0175, -0.0111],\n",
      "          [-0.0169, -0.0145,  0.0044]]],\n",
      "\n",
      "\n",
      "        [[[-0.0167, -0.0052, -0.0117],\n",
      "          [-0.0198, -0.0058, -0.0180],\n",
      "          [ 0.0168,  0.0092,  0.0070]],\n",
      "\n",
      "         [[ 0.0035,  0.0085, -0.0109],\n",
      "          [-0.0090, -0.0074, -0.0170],\n",
      "          [-0.0171, -0.0130,  0.0079]],\n",
      "\n",
      "         [[ 0.0007, -0.0144,  0.0116],\n",
      "          [-0.0168, -0.0176, -0.0058],\n",
      "          [-0.0203, -0.0012, -0.0120]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0038,  0.0003, -0.0029],\n",
      "          [-0.0026,  0.0098,  0.0117],\n",
      "          [ 0.0019, -0.0079, -0.0097]],\n",
      "\n",
      "         [[ 0.0053,  0.0204, -0.0027],\n",
      "          [ 0.0015, -0.0055,  0.0043],\n",
      "          [-0.0030, -0.0086,  0.0034]],\n",
      "\n",
      "         [[ 0.0130, -0.0134, -0.0123],\n",
      "          [ 0.0177, -0.0138, -0.0203],\n",
      "          [-0.0189,  0.0174,  0.0146]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0056, -0.0192, -0.0064],\n",
      "          [ 0.0021,  0.0029, -0.0084],\n",
      "          [ 0.0110, -0.0060, -0.0108]],\n",
      "\n",
      "         [[ 0.0071, -0.0074,  0.0137],\n",
      "          [-0.0088,  0.0146,  0.0154],\n",
      "          [ 0.0026,  0.0134, -0.0089]],\n",
      "\n",
      "         [[ 0.0107,  0.0110, -0.0047],\n",
      "          [-0.0066, -0.0018,  0.0169],\n",
      "          [-0.0093,  0.0032,  0.0150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0023, -0.0175,  0.0103],\n",
      "          [-0.0124, -0.0095, -0.0075],\n",
      "          [ 0.0123, -0.0168,  0.0156]],\n",
      "\n",
      "         [[ 0.0005,  0.0019,  0.0017],\n",
      "          [-0.0155, -0.0022, -0.0132],\n",
      "          [ 0.0097, -0.0064, -0.0191]],\n",
      "\n",
      "         [[ 0.0001, -0.0152,  0.0191],\n",
      "          [ 0.0199,  0.0147,  0.0156],\n",
      "          [ 0.0089, -0.0104,  0.0107]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0188, -0.0192, -0.0079],\n",
      "          [-0.0030,  0.0189,  0.0077],\n",
      "          [-0.0173,  0.0092,  0.0001]],\n",
      "\n",
      "         [[ 0.0097, -0.0086,  0.0097],\n",
      "          [ 0.0041,  0.0025,  0.0149],\n",
      "          [ 0.0085,  0.0171,  0.0182]],\n",
      "\n",
      "         [[-0.0113,  0.0017, -0.0149],\n",
      "          [-0.0006, -0.0034,  0.0033],\n",
      "          [ 0.0009, -0.0125,  0.0169]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0154,  0.0052, -0.0075],\n",
      "          [-0.0094, -0.0189, -0.0130],\n",
      "          [ 0.0067, -0.0165, -0.0089]],\n",
      "\n",
      "         [[-0.0110,  0.0098, -0.0069],\n",
      "          [-0.0173,  0.0174, -0.0066],\n",
      "          [-0.0076,  0.0178,  0.0183]],\n",
      "\n",
      "         [[-0.0087, -0.0112, -0.0112],\n",
      "          [-0.0180,  0.0175, -0.0096],\n",
      "          [ 0.0117, -0.0068,  0.0200]]],\n",
      "\n",
      "\n",
      "        [[[-0.0047,  0.0069, -0.0148],\n",
      "          [ 0.0156, -0.0104,  0.0173],\n",
      "          [-0.0063,  0.0100, -0.0183]],\n",
      "\n",
      "         [[-0.0152,  0.0037,  0.0159],\n",
      "          [ 0.0076, -0.0033,  0.0015],\n",
      "          [-0.0109, -0.0154, -0.0108]],\n",
      "\n",
      "         [[ 0.0083,  0.0165,  0.0005],\n",
      "          [-0.0004,  0.0108,  0.0160],\n",
      "          [ 0.0040,  0.0118, -0.0188]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0106, -0.0114, -0.0162],\n",
      "          [-0.0101, -0.0094, -0.0082],\n",
      "          [ 0.0042, -0.0034, -0.0097]],\n",
      "\n",
      "         [[-0.0006,  0.0070,  0.0125],\n",
      "          [-0.0143, -0.0174,  0.0004],\n",
      "          [ 0.0106,  0.0081, -0.0042]],\n",
      "\n",
      "         [[-0.0153,  0.0035,  0.0068],\n",
      "          [ 0.0099, -0.0190, -0.0047],\n",
      "          [-0.0171,  0.0165,  0.0096]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0059,  0.0152, -0.0042],\n",
      "          [ 0.0154, -0.0021,  0.0014],\n",
      "          [ 0.0172,  0.0165,  0.0013]],\n",
      "\n",
      "         [[-0.0148, -0.0081, -0.0033],\n",
      "          [ 0.0030,  0.0054,  0.0036],\n",
      "          [-0.0108,  0.0011,  0.0050]],\n",
      "\n",
      "         [[ 0.0082,  0.0100, -0.0090],\n",
      "          [-0.0203,  0.0107, -0.0067],\n",
      "          [-0.0071, -0.0115,  0.0126]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0031, -0.0098, -0.0150],\n",
      "          [ 0.0014,  0.0004, -0.0156],\n",
      "          [-0.0082, -0.0060, -0.0168]],\n",
      "\n",
      "         [[-0.0152, -0.0172,  0.0020],\n",
      "          [-0.0025,  0.0063, -0.0183],\n",
      "          [ 0.0069, -0.0205, -0.0092]],\n",
      "\n",
      "         [[-0.0111,  0.0039,  0.0046],\n",
      "          [ 0.0115,  0.0007,  0.0086],\n",
      "          [-0.0105,  0.0142,  0.0169]]]])), ('convolution_block3.0.bias', tensor([-2.0567e-02,  1.9674e-03,  2.7203e-03,  4.5886e-04,  6.4717e-03,\n",
      "         9.0158e-03,  1.6998e-02,  4.8023e-03,  1.6946e-02,  2.0412e-02,\n",
      "        -2.2503e-03,  1.1651e-03,  6.3872e-03, -2.0258e-02,  5.3051e-04,\n",
      "        -7.8637e-04, -2.3707e-03,  1.0386e-02,  1.8601e-02, -1.2752e-02,\n",
      "         1.2097e-03, -1.9382e-02,  3.1591e-03, -9.8287e-04,  8.8892e-03,\n",
      "        -1.7937e-02,  1.0846e-02,  8.0039e-03, -4.1891e-03,  2.0214e-02,\n",
      "        -1.6530e-02,  3.1708e-05,  1.5296e-02, -1.6315e-02, -1.9512e-02,\n",
      "        -1.4360e-02, -1.3352e-02,  3.3157e-03,  6.8414e-03, -5.7700e-03,\n",
      "         1.3083e-04, -6.8514e-03, -1.1033e-02, -1.1611e-02,  3.9813e-03,\n",
      "        -1.9256e-02, -4.4189e-03, -6.5817e-03,  9.0269e-03, -1.6703e-02,\n",
      "        -1.2938e-02, -1.8496e-03,  1.9943e-02,  9.3729e-04, -1.6135e-02,\n",
      "         1.0434e-03, -1.9454e-02,  7.0644e-03,  1.9761e-02,  1.8310e-02,\n",
      "        -1.1849e-02, -7.8474e-03,  1.0546e-03, -3.5524e-03, -1.2340e-02,\n",
      "         3.7825e-03,  1.1122e-03,  1.2428e-02, -1.3991e-03,  6.9465e-03,\n",
      "         8.2371e-03, -6.7120e-04, -1.5374e-02, -2.9345e-03,  1.8647e-02,\n",
      "         5.4930e-03, -1.9136e-02,  1.4549e-02, -2.0805e-03, -6.1452e-03,\n",
      "        -1.3634e-02, -7.5811e-03, -1.1132e-02, -4.4138e-03, -1.5094e-02,\n",
      "        -2.0650e-02, -1.5461e-02, -2.9993e-03,  1.8889e-02,  7.9388e-03,\n",
      "        -7.3731e-03,  1.4790e-02,  1.7715e-02, -1.6633e-02, -4.0701e-03,\n",
      "         1.3012e-02, -1.9526e-02,  6.9271e-04, -1.3397e-02, -8.1616e-03,\n",
      "         4.8263e-03, -4.9633e-03,  1.0170e-02,  1.9854e-02,  1.7040e-02,\n",
      "        -1.5961e-02, -1.6362e-02,  1.1795e-03, -6.0959e-03, -2.0716e-02,\n",
      "         4.4526e-03,  1.9355e-02,  1.0862e-02, -3.9431e-03, -5.8464e-03,\n",
      "         4.9990e-03,  2.0629e-02, -1.9964e-02, -1.5546e-02, -9.6005e-03,\n",
      "         5.0652e-03, -1.2457e-02,  1.4687e-02, -1.6941e-02,  1.2583e-02,\n",
      "        -7.3018e-03,  8.2826e-03, -3.8263e-03, -1.6998e-02, -8.4270e-03,\n",
      "        -1.3184e-02, -7.1750e-03,  1.0437e-02,  2.0663e-02, -1.4032e-02,\n",
      "        -2.8358e-03, -1.3393e-02, -4.6279e-04, -4.2790e-03,  2.0316e-02,\n",
      "         2.9820e-04, -1.3304e-02,  1.5296e-02, -1.7327e-02,  1.2193e-02,\n",
      "        -1.9510e-02,  1.1102e-02,  5.5907e-03, -1.1974e-02, -2.2837e-04,\n",
      "        -1.7677e-03,  3.1395e-03,  1.3410e-02, -1.2240e-02, -9.1765e-04,\n",
      "        -1.0492e-02,  1.1551e-02,  1.3157e-02,  1.5704e-05, -1.0769e-02,\n",
      "        -1.4451e-02,  1.3475e-02, -2.1484e-03,  1.0395e-02, -1.1261e-02,\n",
      "         3.3645e-03,  3.8926e-03, -1.2631e-02,  5.0303e-03,  1.4341e-02,\n",
      "        -1.5871e-02,  7.1133e-03,  2.4951e-03,  6.4216e-03,  5.1748e-03,\n",
      "        -2.2512e-03,  3.3750e-03, -1.7733e-02,  9.6284e-03,  8.3219e-03,\n",
      "        -5.4641e-03,  1.2078e-02, -1.8674e-03,  1.2363e-02, -1.5417e-02,\n",
      "        -3.4554e-03,  1.8592e-02, -2.0112e-03,  5.3636e-03,  1.5255e-02,\n",
      "        -2.8001e-03, -9.6730e-03, -1.8387e-02,  6.5189e-04,  2.2513e-03,\n",
      "         1.1802e-02,  1.4371e-02,  1.8687e-02, -1.5712e-02,  1.5711e-02,\n",
      "        -7.4244e-03, -1.5140e-02,  1.6944e-02, -3.4041e-03,  5.0351e-03,\n",
      "        -1.1532e-02, -1.3796e-02, -3.8345e-03, -1.4783e-02,  4.2016e-04,\n",
      "         1.9176e-02,  5.0242e-03,  1.8889e-03, -8.8487e-03,  1.0951e-02,\n",
      "        -8.4688e-03,  4.6022e-03,  1.9572e-02,  1.0187e-02,  1.9512e-02,\n",
      "        -2.5790e-03, -4.6147e-03, -1.4453e-02, -1.0585e-02,  2.0726e-02,\n",
      "        -1.1750e-02,  7.7281e-03,  9.8011e-05, -1.6666e-02, -6.2071e-03,\n",
      "        -1.8374e-02,  4.2722e-03,  1.4553e-02, -1.7962e-02, -1.4637e-02,\n",
      "        -1.6920e-02, -2.0643e-02,  8.4120e-03, -1.7066e-02,  1.8745e-02,\n",
      "         9.2414e-03, -2.0798e-02,  5.7325e-03,  6.9046e-04, -1.9752e-02,\n",
      "         4.3521e-03,  1.1962e-02, -1.9569e-02,  1.5354e-02,  1.4109e-02,\n",
      "         3.8354e-03, -3.5159e-03, -1.3186e-02,  9.5561e-03, -1.4787e-02,\n",
      "        -1.2522e-02, -2.0004e-02,  1.3146e-02,  2.0447e-02, -1.0872e-03,\n",
      "        -1.0060e-02, -1.2362e-02, -1.3313e-02, -1.5757e-02,  1.4850e-02,\n",
      "         4.7351e-04, -8.2301e-03, -9.3502e-03, -1.6644e-02, -3.0830e-03,\n",
      "         5.7011e-03, -3.1531e-03, -2.0006e-03,  1.7100e-02,  1.3728e-02,\n",
      "         1.2076e-02, -5.9655e-03, -2.0631e-02, -1.5632e-02,  1.0947e-02,\n",
      "        -1.9453e-02,  1.6726e-02, -8.8322e-03,  1.0917e-02,  1.5371e-02,\n",
      "         8.3918e-03, -7.9914e-03, -1.8640e-03,  3.3820e-03,  1.2476e-02,\n",
      "        -2.0770e-02, -3.3614e-03, -1.2094e-03, -1.1038e-02,  6.9086e-03,\n",
      "         9.0640e-03,  4.5525e-03, -1.4222e-02, -1.2798e-02, -1.2402e-02,\n",
      "        -1.1727e-02, -2.0318e-02,  1.0225e-02,  1.8922e-02, -1.3260e-02,\n",
      "         8.3148e-03,  1.3239e-02, -1.3807e-02,  3.7978e-03, -7.6205e-03,\n",
      "         1.2882e-02,  6.2679e-03,  1.2819e-02, -1.8126e-02,  6.2411e-03,\n",
      "        -9.6546e-03, -9.1784e-05, -2.9121e-03,  1.1018e-02,  3.1682e-03,\n",
      "         1.9498e-02,  1.4053e-02,  4.7687e-04, -1.6116e-02,  1.2750e-02,\n",
      "         1.8652e-02, -3.2795e-03, -4.3236e-03,  2.6891e-03, -5.9840e-03,\n",
      "        -1.0873e-03,  1.4183e-02,  1.6076e-02,  1.8587e-02,  1.9221e-02,\n",
      "        -8.0732e-04, -4.4204e-04,  5.0410e-03, -1.3081e-02,  1.8000e-02,\n",
      "         1.9575e-03, -1.6488e-02,  9.7307e-03,  1.3148e-02, -8.4504e-03,\n",
      "         7.4343e-03, -4.8115e-03,  1.1153e-02,  9.6454e-03, -1.4739e-02,\n",
      "        -1.5174e-02,  5.6058e-03, -1.0459e-02, -1.7074e-03,  1.0425e-02,\n",
      "         9.5193e-03,  7.1262e-03, -1.9571e-02,  4.5165e-03,  1.9326e-02,\n",
      "         1.4358e-02, -2.0573e-02, -5.4352e-03, -1.3594e-02, -1.8888e-02,\n",
      "         1.3937e-03, -1.7787e-02, -1.7241e-03,  1.5655e-02,  1.2087e-02,\n",
      "        -1.9535e-02,  2.0802e-02,  1.0454e-03, -1.6713e-02,  1.9602e-02,\n",
      "        -8.7514e-03, -8.6843e-03,  1.6154e-02, -4.8122e-03, -8.2781e-03,\n",
      "         1.7998e-02,  1.9648e-02, -2.9789e-03,  9.9516e-04])), ('convolution_block3.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])), ('convolution_block3.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block3.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block3.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])), ('convolution_block3.1.num_batches_tracked', tensor(0)), ('convolution_block4.0.weight', tensor([[[[-0.0015,  0.0157, -0.0093],\n",
      "          [ 0.0036,  0.0022, -0.0164],\n",
      "          [ 0.0118,  0.0022, -0.0026]],\n",
      "\n",
      "         [[-0.0102, -0.0027, -0.0041],\n",
      "          [-0.0030,  0.0087, -0.0025],\n",
      "          [ 0.0074,  0.0052, -0.0113]],\n",
      "\n",
      "         [[-0.0138, -0.0116,  0.0003],\n",
      "          [ 0.0127, -0.0097, -0.0109],\n",
      "          [ 0.0127, -0.0169,  0.0012]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0165, -0.0002, -0.0048],\n",
      "          [ 0.0011, -0.0046,  0.0170],\n",
      "          [-0.0024, -0.0012, -0.0017]],\n",
      "\n",
      "         [[-0.0152, -0.0122, -0.0106],\n",
      "          [-0.0044,  0.0049,  0.0041],\n",
      "          [-0.0023,  0.0072,  0.0108]],\n",
      "\n",
      "         [[-0.0128,  0.0080,  0.0117],\n",
      "          [-0.0099, -0.0089,  0.0034],\n",
      "          [ 0.0025,  0.0052, -0.0144]]],\n",
      "\n",
      "\n",
      "        [[[-0.0086, -0.0031,  0.0002],\n",
      "          [-0.0137, -0.0074,  0.0111],\n",
      "          [-0.0010, -0.0050, -0.0145]],\n",
      "\n",
      "         [[ 0.0162,  0.0136,  0.0065],\n",
      "          [-0.0021,  0.0137, -0.0051],\n",
      "          [ 0.0059,  0.0051,  0.0025]],\n",
      "\n",
      "         [[ 0.0098,  0.0149, -0.0004],\n",
      "          [ 0.0027, -0.0029,  0.0141],\n",
      "          [ 0.0028, -0.0069, -0.0123]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0112,  0.0037, -0.0029],\n",
      "          [-0.0037,  0.0145,  0.0148],\n",
      "          [-0.0148, -0.0092, -0.0016]],\n",
      "\n",
      "         [[ 0.0011,  0.0031, -0.0069],\n",
      "          [-0.0051,  0.0057,  0.0068],\n",
      "          [ 0.0138,  0.0151,  0.0041]],\n",
      "\n",
      "         [[ 0.0142, -0.0043,  0.0156],\n",
      "          [-0.0005, -0.0138,  0.0148],\n",
      "          [-0.0167, -0.0127, -0.0083]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0009, -0.0092, -0.0091],\n",
      "          [ 0.0129,  0.0148, -0.0145],\n",
      "          [-0.0145, -0.0131,  0.0063]],\n",
      "\n",
      "         [[ 0.0139, -0.0003,  0.0151],\n",
      "          [-0.0113,  0.0146, -0.0057],\n",
      "          [-0.0033, -0.0088, -0.0054]],\n",
      "\n",
      "         [[ 0.0092, -0.0112, -0.0088],\n",
      "          [ 0.0008, -0.0069, -0.0076],\n",
      "          [-0.0099,  0.0102,  0.0162]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0125,  0.0082,  0.0132],\n",
      "          [-0.0022,  0.0103, -0.0153],\n",
      "          [-0.0047,  0.0132, -0.0132]],\n",
      "\n",
      "         [[ 0.0157,  0.0164,  0.0029],\n",
      "          [ 0.0047, -0.0116, -0.0164],\n",
      "          [-0.0012, -0.0024,  0.0063]],\n",
      "\n",
      "         [[-0.0165, -0.0052, -0.0150],\n",
      "          [-0.0131, -0.0059, -0.0064],\n",
      "          [ 0.0076, -0.0119,  0.0117]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0140, -0.0037, -0.0035],\n",
      "          [ 0.0010,  0.0082,  0.0073],\n",
      "          [ 0.0034, -0.0145,  0.0069]],\n",
      "\n",
      "         [[-0.0020,  0.0164, -0.0002],\n",
      "          [-0.0160, -0.0068, -0.0014],\n",
      "          [ 0.0142, -0.0050,  0.0089]],\n",
      "\n",
      "         [[-0.0079, -0.0033, -0.0027],\n",
      "          [ 0.0068, -0.0151,  0.0017],\n",
      "          [-0.0089, -0.0136, -0.0035]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0053, -0.0097, -0.0168],\n",
      "          [-0.0118, -0.0106, -0.0011],\n",
      "          [ 0.0120, -0.0043,  0.0027]],\n",
      "\n",
      "         [[-0.0118, -0.0113,  0.0130],\n",
      "          [ 0.0027,  0.0107,  0.0081],\n",
      "          [-0.0153, -0.0047, -0.0085]],\n",
      "\n",
      "         [[-0.0096, -0.0029,  0.0006],\n",
      "          [ 0.0018, -0.0083,  0.0143],\n",
      "          [-0.0132, -0.0069, -0.0025]]],\n",
      "\n",
      "\n",
      "        [[[-0.0045,  0.0128,  0.0157],\n",
      "          [ 0.0098,  0.0103,  0.0132],\n",
      "          [ 0.0163, -0.0076, -0.0139]],\n",
      "\n",
      "         [[-0.0041,  0.0081,  0.0086],\n",
      "          [ 0.0075, -0.0119,  0.0166],\n",
      "          [-0.0131, -0.0047, -0.0170]],\n",
      "\n",
      "         [[-0.0099, -0.0040,  0.0165],\n",
      "          [-0.0052,  0.0081, -0.0167],\n",
      "          [-0.0139, -0.0143,  0.0120]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0057, -0.0170, -0.0145],\n",
      "          [ 0.0051, -0.0143,  0.0008],\n",
      "          [-0.0079,  0.0131,  0.0021]],\n",
      "\n",
      "         [[-0.0143, -0.0070,  0.0150],\n",
      "          [ 0.0048,  0.0034, -0.0016],\n",
      "          [ 0.0088, -0.0134, -0.0070]],\n",
      "\n",
      "         [[ 0.0078, -0.0095,  0.0021],\n",
      "          [-0.0087,  0.0139,  0.0163],\n",
      "          [ 0.0119,  0.0036,  0.0134]]],\n",
      "\n",
      "\n",
      "        [[[-0.0111, -0.0023,  0.0165],\n",
      "          [ 0.0017, -0.0031,  0.0005],\n",
      "          [-0.0146, -0.0038, -0.0067]],\n",
      "\n",
      "         [[-0.0151,  0.0113,  0.0008],\n",
      "          [ 0.0021,  0.0014,  0.0091],\n",
      "          [-0.0116,  0.0042,  0.0091]],\n",
      "\n",
      "         [[-0.0110, -0.0148,  0.0155],\n",
      "          [ 0.0109,  0.0074,  0.0013],\n",
      "          [ 0.0033, -0.0027,  0.0010]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0067, -0.0048, -0.0124],\n",
      "          [-0.0156,  0.0077, -0.0083],\n",
      "          [ 0.0120, -0.0019, -0.0153]],\n",
      "\n",
      "         [[-0.0043, -0.0139, -0.0122],\n",
      "          [-0.0024,  0.0073, -0.0086],\n",
      "          [ 0.0123,  0.0092,  0.0007]],\n",
      "\n",
      "         [[-0.0010,  0.0065, -0.0023],\n",
      "          [-0.0036, -0.0158,  0.0095],\n",
      "          [ 0.0055, -0.0018,  0.0026]]]])), ('convolution_block4.0.bias', tensor([ 7.1006e-03, -6.6877e-03,  1.0915e-02, -1.3710e-02, -1.1909e-02,\n",
      "        -2.7173e-03, -5.2836e-03,  1.1084e-02, -4.9418e-03, -1.6363e-03,\n",
      "        -1.6779e-03,  1.3660e-02, -3.3786e-03, -1.5313e-02, -1.2926e-02,\n",
      "         5.4273e-03,  1.6277e-02,  3.8220e-03,  3.3452e-03,  2.0220e-03,\n",
      "        -1.5031e-02, -1.2228e-02, -1.6201e-02, -1.5147e-02, -1.4726e-02,\n",
      "         4.4670e-03,  6.1244e-03,  1.2581e-02, -4.5250e-03, -4.3341e-04,\n",
      "         1.2888e-02, -1.2281e-02, -8.2374e-03, -8.9552e-03, -1.9222e-03,\n",
      "         6.9517e-03, -2.2445e-04, -1.6691e-02, -6.3818e-03,  9.1211e-03,\n",
      "         1.6258e-02, -1.5758e-03, -1.1788e-02,  3.2556e-03,  3.0536e-03,\n",
      "         8.0098e-04,  2.0565e-04,  1.4059e-02,  5.4259e-03, -8.7029e-03,\n",
      "         1.4582e-03, -6.4658e-03,  6.7683e-03,  5.4885e-03,  1.3527e-02,\n",
      "         1.4477e-02, -1.1407e-02,  4.0318e-04,  9.2573e-03, -7.7624e-03,\n",
      "         1.4234e-02,  2.3820e-03,  7.7121e-03, -5.9230e-04,  1.4948e-02,\n",
      "        -1.1937e-02, -1.2689e-02, -7.6531e-03,  1.1189e-02, -1.2832e-02,\n",
      "         6.9028e-04, -5.8237e-03,  2.7487e-03, -1.4740e-02, -9.9575e-03,\n",
      "         4.5018e-03, -1.5504e-02, -7.9036e-03,  9.1994e-03, -1.5866e-02,\n",
      "         7.6026e-03,  6.3164e-03, -1.6348e-02,  6.7750e-04, -1.8655e-03,\n",
      "        -1.6038e-02, -5.2503e-03,  9.3989e-04,  6.5346e-03, -1.4533e-02,\n",
      "         9.4856e-03, -4.6774e-03, -3.2154e-03,  5.8416e-03, -1.4885e-02,\n",
      "        -1.3383e-02, -8.1552e-04, -1.3081e-02, -6.8165e-03, -4.2504e-03,\n",
      "        -1.1653e-02, -1.6250e-02,  1.1384e-02, -2.1763e-03, -1.4721e-02,\n",
      "         4.5455e-03,  7.2364e-03,  6.6535e-03,  7.3587e-03,  1.5700e-02,\n",
      "         3.0036e-03,  6.0625e-03, -6.7021e-03,  9.7266e-03, -1.5232e-02,\n",
      "        -4.7283e-03, -3.7170e-03,  3.8914e-03, -2.2809e-03, -8.1053e-03,\n",
      "        -9.2494e-03, -1.5937e-02, -1.6874e-02, -1.0020e-02, -1.3684e-02,\n",
      "         6.0934e-03, -1.5835e-02,  1.3639e-02,  1.0521e-02,  6.2226e-03,\n",
      "         1.6808e-02,  1.3016e-02,  8.9922e-03,  4.1776e-03,  9.9232e-04,\n",
      "         9.2801e-03, -8.6145e-04,  5.8144e-03,  8.9646e-03,  9.3361e-03,\n",
      "        -8.1061e-03, -9.8563e-03, -2.8925e-03,  1.2523e-02,  4.8615e-07,\n",
      "        -1.6117e-02, -5.4034e-04,  1.7369e-03, -7.1738e-03,  1.6049e-02,\n",
      "        -1.0625e-02,  9.7066e-03,  7.2747e-03,  1.4092e-02, -1.5096e-04,\n",
      "        -3.8546e-03, -1.4566e-02, -1.4226e-02,  1.4774e-02,  5.6852e-03,\n",
      "         1.5495e-03,  4.3563e-03, -5.4002e-03, -1.2593e-02, -5.9781e-03,\n",
      "        -3.0110e-03,  1.7984e-03,  1.2337e-02,  5.3775e-03,  2.6899e-03,\n",
      "        -8.8723e-03, -8.0451e-03,  5.9883e-03, -4.3467e-04,  1.5173e-02,\n",
      "        -5.0238e-03,  3.2985e-04, -1.9555e-03,  1.3736e-02, -2.7110e-03,\n",
      "        -1.0414e-02, -6.1877e-03,  1.2714e-02,  1.0992e-02,  1.5898e-03,\n",
      "         1.1458e-02, -1.2830e-02, -7.5102e-03,  1.6613e-02, -6.3802e-03,\n",
      "        -1.5989e-02,  6.7622e-03,  6.3428e-03,  3.2291e-03,  2.6631e-03,\n",
      "         4.5112e-03, -2.1280e-03,  1.3153e-03,  1.3623e-02,  1.5771e-03,\n",
      "         1.0619e-02,  2.9158e-03, -1.1398e-02, -4.2028e-04, -1.4164e-02,\n",
      "         5.4086e-03,  1.8510e-03,  5.8605e-03,  1.2396e-02, -1.1267e-02,\n",
      "        -4.2921e-04, -1.1082e-02,  1.1225e-02,  5.4580e-03, -9.9212e-03,\n",
      "         5.7637e-03, -6.9071e-03, -1.4721e-02,  1.5053e-02, -3.3956e-03,\n",
      "         1.0791e-02, -6.2138e-03,  5.9852e-04, -7.5746e-03, -7.9343e-03,\n",
      "        -3.2449e-03,  5.0667e-03, -5.0920e-03, -1.0999e-02,  1.6801e-02,\n",
      "        -1.1245e-02, -9.1329e-04,  6.7242e-03, -1.4585e-02, -3.0263e-03,\n",
      "         3.9149e-03,  1.6472e-02, -1.0414e-02, -8.2357e-03, -1.7004e-03,\n",
      "         1.4942e-02,  4.8766e-04,  2.5016e-04,  1.2114e-02, -1.1944e-02,\n",
      "        -9.0630e-03, -9.3310e-03, -1.6194e-02,  1.2410e-02,  1.2129e-02,\n",
      "         3.9975e-03, -1.2913e-03, -8.8650e-03, -1.0027e-02, -9.5083e-03,\n",
      "         1.0060e-02,  1.4771e-02,  1.1903e-02, -1.0639e-02,  1.1098e-02,\n",
      "        -1.1698e-02,  4.1542e-03, -4.1790e-03, -1.4179e-02,  1.5050e-03,\n",
      "         1.2885e-02, -9.3781e-03, -1.0582e-02, -3.8037e-03, -8.4499e-03,\n",
      "        -1.2612e-03,  3.2018e-03,  1.9010e-03, -1.6903e-02, -8.1036e-03,\n",
      "         9.9361e-03, -1.5840e-02, -1.4771e-02,  2.6205e-03,  6.4798e-03,\n",
      "         2.7406e-03, -8.5887e-03,  6.7007e-03,  2.2264e-03, -5.5523e-03,\n",
      "         9.9496e-03,  1.0721e-02, -1.1487e-02, -3.2003e-04, -6.9331e-03,\n",
      "         8.8808e-03, -1.3986e-04,  5.9238e-03, -1.5464e-02,  3.0175e-03,\n",
      "         1.0902e-02,  1.3984e-02,  1.3759e-02,  3.7598e-03, -1.1113e-02,\n",
      "         1.2962e-02,  7.4920e-03,  5.4884e-03,  1.5328e-02,  1.6413e-03,\n",
      "        -4.2110e-03,  1.6049e-02, -5.0199e-03,  7.5693e-03, -1.4093e-02,\n",
      "         6.5876e-03,  4.0573e-04,  3.2404e-03, -1.3582e-02, -1.0322e-02,\n",
      "        -1.5489e-03, -9.7888e-03,  1.5814e-02, -1.2870e-02, -1.1363e-02,\n",
      "         9.5168e-03,  5.4404e-03,  3.1080e-04, -1.5460e-02, -3.8553e-03,\n",
      "        -1.1417e-02,  8.2213e-03, -1.3427e-02,  3.2240e-03, -4.8602e-03,\n",
      "        -7.4722e-03, -8.9160e-03, -4.5454e-03,  5.0746e-04, -1.4183e-02,\n",
      "         1.6969e-02, -4.4028e-03,  1.2059e-02, -1.7744e-03,  2.1712e-03,\n",
      "        -2.3149e-03,  1.6179e-02,  1.2155e-02,  5.5310e-03,  1.3415e-02,\n",
      "        -1.7128e-03,  1.5625e-03, -5.8384e-03,  1.1743e-02, -1.0979e-02,\n",
      "         6.7659e-03,  1.3764e-02, -9.1792e-03, -1.5979e-02, -8.1443e-04,\n",
      "        -1.5198e-02, -4.4140e-03, -1.0519e-02,  3.0042e-03, -9.1106e-03,\n",
      "        -1.6281e-02,  1.4766e-02,  1.2223e-02,  9.7814e-03, -1.0637e-02,\n",
      "         8.8503e-03, -3.1486e-03, -1.0139e-02, -1.1457e-02, -3.7203e-03,\n",
      "         7.8923e-04, -3.3877e-03,  1.5801e-02,  1.7662e-03, -5.2939e-03,\n",
      "        -9.4012e-03,  1.3728e-02,  1.3964e-02, -1.9736e-03, -6.4723e-04,\n",
      "         5.5447e-03,  5.5352e-03,  1.6334e-02, -4.5077e-03])), ('convolution_block4.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])), ('convolution_block4.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block4.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block4.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])), ('convolution_block4.1.num_batches_tracked', tensor(0)), ('convolution_block5.0.weight', tensor([[[[-6.5410e-03, -4.0932e-03, -1.2871e-02],\n",
      "          [ 3.4661e-03,  1.1402e-02,  5.7929e-03],\n",
      "          [ 7.9726e-03, -1.2293e-02,  1.0570e-02]],\n",
      "\n",
      "         [[-1.3692e-02,  5.1379e-03, -1.0329e-02],\n",
      "          [-6.2702e-03, -1.6100e-02, -2.1756e-03],\n",
      "          [ 1.8480e-03, -1.1986e-04, -1.6802e-02]],\n",
      "\n",
      "         [[-5.0662e-03, -8.9102e-03, -3.2824e-04],\n",
      "          [-1.2809e-02,  1.5537e-02,  1.2824e-02],\n",
      "          [ 1.0085e-02,  1.2525e-02,  6.7611e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1734e-02,  3.7060e-04,  9.6445e-03],\n",
      "          [ 8.3872e-03,  5.4787e-03, -8.0583e-03],\n",
      "          [-8.4293e-04,  1.4394e-02, -1.1341e-03]],\n",
      "\n",
      "         [[ 1.4200e-02, -8.3803e-03,  3.0948e-03],\n",
      "          [ 9.7596e-03, -7.2798e-03, -1.0707e-03],\n",
      "          [-1.1729e-02,  7.8971e-03,  8.9508e-03]],\n",
      "\n",
      "         [[ 6.7774e-03, -1.0224e-02, -1.9555e-03],\n",
      "          [ 7.5680e-03,  6.2366e-03, -1.5341e-02],\n",
      "          [ 6.0017e-04, -1.3584e-02, -2.8859e-03]]],\n",
      "\n",
      "\n",
      "        [[[-8.3750e-03,  1.5979e-02,  1.1217e-03],\n",
      "          [ 1.8006e-03, -1.2802e-02, -7.3154e-03],\n",
      "          [-6.0039e-03,  1.2681e-02, -1.0678e-02]],\n",
      "\n",
      "         [[ 1.1389e-02,  1.0672e-02,  1.0307e-02],\n",
      "          [ 7.3293e-05, -9.6441e-03,  1.2155e-02],\n",
      "          [-1.2062e-02, -1.5329e-02,  4.8177e-03]],\n",
      "\n",
      "         [[ 1.2925e-02,  1.2980e-02, -1.4862e-02],\n",
      "          [-9.0871e-03, -1.5107e-02, -6.2468e-03],\n",
      "          [-1.0762e-02,  1.4454e-02, -2.8602e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0003e-03, -1.6934e-02, -8.5515e-03],\n",
      "          [ 1.3202e-02, -1.0663e-02,  1.2148e-02],\n",
      "          [ 9.0064e-03, -5.5085e-03,  1.1557e-02]],\n",
      "\n",
      "         [[ 1.1518e-02,  5.7453e-03, -1.0820e-02],\n",
      "          [-7.0729e-03,  1.0593e-02, -4.4738e-04],\n",
      "          [-1.0868e-02,  1.4948e-02, -2.7389e-03]],\n",
      "\n",
      "         [[-6.0620e-03, -1.6015e-02,  4.7021e-03],\n",
      "          [ 1.4938e-02, -4.0795e-03, -1.4318e-02],\n",
      "          [ 1.4242e-02,  5.9509e-03, -3.0453e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.5739e-02, -8.3255e-03,  3.7510e-03],\n",
      "          [ 1.0096e-02,  1.7590e-03, -2.9030e-03],\n",
      "          [-3.9644e-03, -5.2709e-04,  1.1041e-02]],\n",
      "\n",
      "         [[ 2.3510e-03, -3.0236e-03, -1.6945e-02],\n",
      "          [-1.1148e-02,  3.7090e-03,  3.4886e-04],\n",
      "          [ 1.1690e-02,  1.2035e-02, -1.3745e-02]],\n",
      "\n",
      "         [[ 4.1468e-03, -1.4896e-02, -9.1333e-03],\n",
      "          [ 1.2545e-02,  1.0256e-03,  5.0815e-04],\n",
      "          [-2.3976e-03,  4.2267e-03, -7.9848e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2091e-02, -1.4074e-02,  1.4000e-03],\n",
      "          [ 1.5733e-02, -1.6722e-02, -2.7976e-03],\n",
      "          [-6.2372e-03,  1.2897e-02, -5.2741e-03]],\n",
      "\n",
      "         [[-9.9202e-03,  3.7146e-03,  1.0496e-02],\n",
      "          [ 5.6328e-03, -1.0415e-02,  1.2928e-02],\n",
      "          [ 1.3396e-02, -3.2452e-03,  1.6730e-02]],\n",
      "\n",
      "         [[ 9.9822e-03,  1.6149e-02, -2.1083e-05],\n",
      "          [ 1.1863e-02, -1.5650e-02, -1.5536e-02],\n",
      "          [-1.2154e-02, -9.7107e-03, -8.1675e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.4566e-02, -2.3347e-03, -1.3659e-02],\n",
      "          [ 9.9097e-03,  1.3840e-02,  1.4310e-02],\n",
      "          [-1.3821e-02, -5.7350e-03,  8.3419e-03]],\n",
      "\n",
      "         [[ 1.3962e-02, -4.3761e-03, -1.3115e-02],\n",
      "          [ 3.1736e-03,  1.6881e-02, -1.4438e-02],\n",
      "          [ 1.5259e-02,  1.0254e-02, -1.2602e-02]],\n",
      "\n",
      "         [[-1.0818e-02,  2.6789e-04, -8.5452e-03],\n",
      "          [ 1.1292e-02,  2.7481e-03,  1.1194e-02],\n",
      "          [ 1.6988e-02,  1.4192e-02, -6.4153e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.5558e-03,  8.8329e-03, -6.6160e-03],\n",
      "          [-1.0849e-02, -1.1951e-02, -2.9336e-03],\n",
      "          [ 1.4338e-02, -5.3329e-03,  1.3823e-02]],\n",
      "\n",
      "         [[-1.6221e-02,  5.2677e-03, -6.2935e-03],\n",
      "          [-1.0300e-02,  1.3799e-02,  1.1974e-02],\n",
      "          [-1.6334e-03,  2.4253e-03,  7.7256e-03]],\n",
      "\n",
      "         [[ 5.7656e-03,  1.2614e-02,  1.5574e-03],\n",
      "          [ 2.6644e-03,  1.6214e-02,  2.5065e-03],\n",
      "          [ 1.3942e-02,  1.3189e-02,  9.7677e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.5917e-03,  6.0292e-03,  9.8929e-03],\n",
      "          [-1.6097e-02,  7.8560e-03, -1.1866e-02],\n",
      "          [-1.4740e-02, -2.3484e-03,  1.3581e-02]],\n",
      "\n",
      "         [[-9.5293e-03, -1.1187e-03,  1.2972e-02],\n",
      "          [-1.0399e-02,  4.7606e-03, -8.0026e-03],\n",
      "          [ 1.1454e-02, -1.1966e-03,  1.5530e-02]],\n",
      "\n",
      "         [[ 1.2404e-02,  1.0470e-02, -1.3461e-03],\n",
      "          [ 9.3586e-03,  1.0217e-02, -1.0867e-02],\n",
      "          [ 1.3229e-02, -1.5792e-02,  5.4354e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3585e-03,  1.0693e-03, -7.8576e-03],\n",
      "          [-1.3864e-02,  9.3193e-03,  1.7831e-03],\n",
      "          [ 1.3809e-02, -1.4552e-03,  4.5518e-03]],\n",
      "\n",
      "         [[ 9.0877e-03, -9.4897e-03,  6.0029e-03],\n",
      "          [-4.8284e-03, -6.4988e-03,  1.2081e-02],\n",
      "          [-1.7380e-03, -7.2845e-03, -1.1936e-02]],\n",
      "\n",
      "         [[ 1.3427e-02, -6.7924e-03,  1.3326e-02],\n",
      "          [-1.3486e-02,  1.1654e-02, -1.2393e-03],\n",
      "          [ 8.2134e-03, -9.8556e-03, -5.5647e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6223e-03,  1.1713e-02,  4.4099e-03],\n",
      "          [-1.3779e-02, -8.8327e-03,  6.0803e-03],\n",
      "          [-1.5902e-02,  2.3574e-03,  1.6521e-02]],\n",
      "\n",
      "         [[ 6.3813e-03,  7.4858e-03, -1.0328e-02],\n",
      "          [-9.2557e-03,  1.6688e-02, -1.0252e-02],\n",
      "          [ 7.2303e-03,  9.8691e-03, -1.5519e-02]],\n",
      "\n",
      "         [[ 7.1391e-03,  3.4276e-03,  1.0837e-02],\n",
      "          [-1.0928e-02, -9.2734e-03,  1.6428e-02],\n",
      "          [-1.4698e-03, -9.8506e-03,  1.6652e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4299e-02, -1.2386e-03, -1.0472e-02],\n",
      "          [-1.5603e-02, -6.3902e-03, -6.8059e-03],\n",
      "          [-1.3691e-02,  1.6797e-02,  4.7723e-03]],\n",
      "\n",
      "         [[-1.1435e-02, -1.3165e-02, -1.0941e-02],\n",
      "          [ 2.7227e-03, -6.1686e-03, -1.2023e-02],\n",
      "          [ 8.6132e-03, -1.0921e-02,  1.1551e-02]],\n",
      "\n",
      "         [[ 1.6885e-02,  4.7818e-03,  8.4087e-03],\n",
      "          [ 1.1725e-02, -4.2927e-03, -1.2424e-02],\n",
      "          [ 1.0934e-02, -8.6075e-03, -4.4116e-03]]]])), ('convolution_block5.0.bias', tensor([-3.8338e-03, -1.6226e-02,  3.1702e-03,  4.1967e-04, -1.3097e-02,\n",
      "         8.4474e-04,  6.9918e-03, -1.0431e-02,  1.0798e-02,  8.6045e-03,\n",
      "         5.4805e-03, -1.6559e-02,  1.0451e-02,  6.3058e-03, -1.4517e-02,\n",
      "        -1.0480e-02, -3.4903e-04, -1.0920e-02,  9.8590e-03, -1.1824e-02,\n",
      "         5.7316e-03,  1.5363e-03,  3.5042e-03, -1.4668e-02, -9.6904e-03,\n",
      "         2.9559e-03,  8.1595e-03, -3.6753e-03,  8.1886e-04,  7.0316e-03,\n",
      "        -1.2358e-02, -3.4285e-03,  7.9481e-03,  1.3750e-02,  1.5443e-03,\n",
      "        -1.5270e-02, -6.7289e-03,  7.5551e-03,  3.8059e-03,  7.6489e-03,\n",
      "        -6.1826e-03,  1.2588e-02, -9.9214e-03,  6.7967e-03,  9.3816e-03,\n",
      "        -1.6721e-02, -9.3548e-03, -1.2062e-02, -1.0906e-02, -1.1040e-02,\n",
      "         1.1374e-02,  7.3291e-03, -6.5988e-03,  9.6576e-03, -9.0406e-03,\n",
      "         1.0558e-02,  1.6870e-02, -1.5662e-02,  6.2315e-03, -8.3139e-03,\n",
      "         2.0152e-03, -1.0524e-02, -1.2628e-03,  8.3749e-03,  1.8779e-03,\n",
      "        -1.5961e-02, -1.6978e-02, -1.1378e-02,  1.1984e-02, -1.1705e-02,\n",
      "         6.5835e-03,  5.2071e-03,  8.2762e-03,  1.3698e-02, -5.8602e-03,\n",
      "        -9.2891e-04, -8.0219e-03,  6.8195e-03,  9.0656e-03,  4.2547e-03,\n",
      "        -4.3450e-03,  1.2322e-02, -2.7248e-03, -1.0578e-02,  1.6896e-02,\n",
      "         8.7731e-03, -1.6748e-02, -1.6170e-02,  9.3690e-03,  3.0104e-03,\n",
      "         1.5406e-02, -4.2614e-03,  6.0820e-03,  1.0819e-02,  9.5062e-03,\n",
      "        -1.4774e-02,  1.5421e-02,  7.8579e-03,  9.4699e-03, -1.1440e-02,\n",
      "        -8.6791e-03, -1.2296e-02,  2.3386e-03,  7.6381e-03, -1.6255e-02,\n",
      "         4.2279e-03,  1.1894e-02,  1.1000e-02,  1.0472e-02,  7.0624e-03,\n",
      "        -1.7720e-03, -1.3392e-02,  2.8548e-04,  1.1966e-02, -1.6923e-02,\n",
      "         1.3992e-03, -1.2574e-02,  1.4558e-02, -4.3558e-03, -9.2580e-03,\n",
      "         1.2531e-02,  1.0593e-02,  1.0476e-02, -7.2594e-03, -1.6702e-02,\n",
      "        -5.5587e-03, -5.6421e-03, -9.0564e-03, -4.9808e-03, -1.0350e-02,\n",
      "         8.1051e-03, -1.5424e-02,  2.7741e-03, -6.6866e-03, -4.3519e-03,\n",
      "         1.8473e-03,  8.1741e-03, -1.5211e-02,  1.1053e-02, -1.6817e-02,\n",
      "         1.5923e-03,  1.6633e-02, -1.0161e-02, -1.1415e-02, -1.5045e-02,\n",
      "        -2.1522e-03,  1.4699e-02,  2.6024e-03, -1.2350e-02, -6.4027e-03,\n",
      "        -3.9532e-03,  7.9209e-03, -1.2105e-02, -4.5629e-03, -6.4491e-04,\n",
      "        -1.7011e-03,  8.1580e-03,  3.7069e-03, -4.3178e-03,  1.1421e-02,\n",
      "         4.8293e-03,  9.7102e-03,  9.0518e-03, -7.5912e-03, -1.4657e-02,\n",
      "         1.3555e-02,  5.6266e-03,  1.0477e-02, -1.6777e-02, -1.1049e-02,\n",
      "         5.4522e-03,  7.9171e-03, -1.0289e-02,  1.2793e-02,  7.9000e-03,\n",
      "         1.0689e-02,  1.5922e-02,  8.4979e-03, -1.1774e-02,  7.3240e-03,\n",
      "        -1.3041e-02, -4.6929e-03,  6.0680e-03,  1.1991e-02,  6.2184e-04,\n",
      "         4.7159e-03,  1.0542e-02, -1.6362e-02,  1.1903e-02,  1.2308e-02,\n",
      "         9.2222e-03,  5.3499e-03, -6.8324e-03,  1.2894e-02, -1.1933e-02,\n",
      "        -1.6272e-02,  1.2208e-02, -7.3162e-03, -1.2210e-02, -5.0232e-03,\n",
      "        -9.7375e-03, -1.0879e-02, -1.6375e-02,  1.1390e-02,  2.7455e-05,\n",
      "        -1.3350e-03,  2.7847e-03, -2.1752e-03, -2.1348e-03, -1.1923e-02,\n",
      "         1.0726e-02, -1.0537e-03,  8.0558e-04, -7.9997e-03,  1.2586e-02,\n",
      "         7.2534e-03,  1.2823e-02, -5.4539e-03, -4.7628e-03, -8.5043e-03,\n",
      "        -9.1865e-03, -4.1998e-03,  1.1820e-02,  8.2095e-03,  5.2888e-03,\n",
      "        -7.1751e-03,  6.1402e-03,  1.6267e-02, -5.3457e-04,  3.0757e-03,\n",
      "         7.4348e-03, -8.5888e-03,  5.2197e-03,  1.5325e-02, -1.4012e-02,\n",
      "        -1.0358e-02,  2.6968e-03, -7.1629e-03,  8.4669e-03,  5.8617e-03,\n",
      "         2.6487e-03,  8.2993e-03,  1.5631e-03,  1.3787e-02, -3.4816e-04,\n",
      "        -1.4378e-02,  3.0119e-04,  1.1696e-03,  3.8630e-03,  6.3565e-03,\n",
      "        -9.4991e-03, -5.3887e-03, -1.5731e-02, -5.9313e-03, -1.6920e-02,\n",
      "        -1.0304e-02])), ('convolution_block5.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])), ('convolution_block5.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block5.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block5.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])), ('convolution_block5.1.num_batches_tracked', tensor(0)), ('fully_connected.1.weight', tensor([[-0.0271,  0.0605, -0.0592,  ...,  0.0272,  0.0134,  0.0264],\n",
      "        [ 0.0316, -0.0459,  0.0552,  ...,  0.0197,  0.0074, -0.0155],\n",
      "        [-0.0335,  0.0155,  0.0203,  ...,  0.0446,  0.0056, -0.0464],\n",
      "        ...,\n",
      "        [ 0.0047, -0.0573, -0.0156,  ...,  0.0568,  0.0498,  0.0609],\n",
      "        [ 0.0625,  0.0116, -0.0110,  ...,  0.0173, -0.0056, -0.0405],\n",
      "        [ 0.0391,  0.0569,  0.0018,  ...,  0.0101, -0.0284, -0.0272]])), ('fully_connected.1.bias', tensor([ 0.0065, -0.0540,  0.0257,  0.0535,  0.0333,  0.0526, -0.0576,  0.0582,\n",
      "         0.0453,  0.0509,  0.0126, -0.0483, -0.0263,  0.0211, -0.0370, -0.0213,\n",
      "         0.0596,  0.0083,  0.0490, -0.0283,  0.0589, -0.0620, -0.0443, -0.0190,\n",
      "         0.0045,  0.0161,  0.0480, -0.0109, -0.0454, -0.0149, -0.0470, -0.0145,\n",
      "         0.0049,  0.0368,  0.0096,  0.0143,  0.0245,  0.0611,  0.0354,  0.0059,\n",
      "         0.0196,  0.0289,  0.0403, -0.0034, -0.0332, -0.0362,  0.0083,  0.0046,\n",
      "         0.0377,  0.0121,  0.0450,  0.0268, -0.0151,  0.0349, -0.0503,  0.0239,\n",
      "         0.0532, -0.0402, -0.0013, -0.0126,  0.0242,  0.0606,  0.0314, -0.0120,\n",
      "         0.0177,  0.0099,  0.0387,  0.0133,  0.0455, -0.0209,  0.0193, -0.0405,\n",
      "        -0.0378,  0.0556,  0.0283, -0.0334, -0.0449,  0.0391,  0.0501, -0.0456,\n",
      "         0.0328,  0.0049, -0.0241,  0.0169, -0.0480,  0.0406,  0.0014, -0.0019,\n",
      "        -0.0043,  0.0357, -0.0423, -0.0453,  0.0049, -0.0002,  0.0609,  0.0533,\n",
      "         0.0308, -0.0401,  0.0276, -0.0459, -0.0388,  0.0377, -0.0010,  0.0443,\n",
      "        -0.0443,  0.0335,  0.0043, -0.0419, -0.0170,  0.0515, -0.0007, -0.0275,\n",
      "         0.0119, -0.0015, -0.0566, -0.0433, -0.0308,  0.0603, -0.0004,  0.0127,\n",
      "         0.0507, -0.0170,  0.0136, -0.0238, -0.0356,  0.0201, -0.0600, -0.0562])), ('fully_connected1.1.weight', tensor([[ 0.0295,  0.0835,  0.0602,  ...,  0.0417, -0.0484, -0.0500],\n",
      "        [ 0.0763,  0.0420, -0.0531,  ..., -0.0405, -0.0484, -0.0803],\n",
      "        [ 0.0688,  0.0606,  0.0351,  ...,  0.0275,  0.0329,  0.0615],\n",
      "        ...,\n",
      "        [-0.0707,  0.0116,  0.0173,  ..., -0.0018, -0.0754,  0.0790],\n",
      "        [ 0.0843,  0.0741,  0.0380,  ..., -0.0782, -0.0824,  0.0662],\n",
      "        [-0.0200,  0.0293,  0.0465,  ..., -0.0078,  0.0660, -0.0778]])), ('fully_connected1.1.bias', tensor([-0.0737, -0.0848, -0.0828, -0.0283, -0.0617, -0.0601,  0.0171,  0.0114,\n",
      "         0.0738, -0.0305, -0.0169,  0.0464,  0.0487,  0.0623, -0.0159, -0.0676,\n",
      "        -0.0481,  0.0180,  0.0133,  0.0020,  0.0494, -0.0110, -0.0289,  0.0063,\n",
      "        -0.0635, -0.0340, -0.0477, -0.0037,  0.0612,  0.0671,  0.0744,  0.0760,\n",
      "         0.0347,  0.0538,  0.0393, -0.0762, -0.0844, -0.0382,  0.0209, -0.0746,\n",
      "        -0.0137, -0.0695, -0.0880,  0.0158, -0.0536,  0.0031,  0.0235,  0.0365,\n",
      "        -0.0832,  0.0117, -0.0128, -0.0109,  0.0339,  0.0007,  0.0778, -0.0827,\n",
      "         0.0091, -0.0215,  0.0338, -0.0175,  0.0192, -0.0148, -0.0847,  0.0178])), ('fully_connected2.0.weight', tensor([[ 8.0006e-02, -1.0753e-01,  1.0347e-01, -1.1211e-01,  7.0150e-03,\n",
      "          4.8280e-02,  6.5944e-02,  6.3235e-02, -8.7350e-02,  5.5069e-02,\n",
      "          1.7151e-03,  6.9631e-02, -3.8714e-02,  2.2576e-03, -1.7934e-02,\n",
      "          8.8488e-02, -1.0810e-01,  9.2202e-02, -7.9997e-02, -3.7488e-02,\n",
      "         -8.2380e-02,  6.9608e-04,  4.6798e-02,  1.5816e-02,  1.6564e-02,\n",
      "         -6.2476e-02,  5.2081e-02, -4.2063e-02,  1.1380e-01,  1.0094e-01,\n",
      "          7.5501e-02,  7.7699e-02,  7.7035e-02, -1.1474e-01, -5.3570e-03,\n",
      "         -9.4275e-02, -1.0699e-01, -3.8425e-02, -4.8595e-02, -1.1029e-01,\n",
      "          9.8323e-02, -5.2621e-02,  1.7845e-02, -3.4991e-02,  1.1927e-01,\n",
      "          8.9910e-03, -8.4382e-03,  4.9152e-02, -1.2401e-01,  1.1630e-01,\n",
      "         -9.9839e-02, -3.8893e-02,  1.0255e-01,  1.1829e-02,  9.2234e-02,\n",
      "         -9.3793e-02,  6.7205e-02, -3.2818e-02, -5.6992e-02, -1.9430e-02,\n",
      "         -1.0341e-01,  5.7905e-02,  8.2165e-02,  8.3417e-03],\n",
      "        [ 7.2310e-03,  1.0999e-01, -4.4153e-02,  4.2321e-02, -6.8123e-02,\n",
      "          1.1053e-01,  5.0515e-02, -8.2274e-02, -8.1939e-02,  1.0548e-01,\n",
      "          3.4954e-02, -2.8546e-02,  6.7421e-02, -1.4915e-02, -1.2379e-01,\n",
      "         -9.2439e-02, -9.2838e-02, -1.1394e-01, -5.4567e-02,  1.2290e-01,\n",
      "         -3.5703e-02, -6.3921e-02, -1.2185e-01, -7.8605e-02,  2.8623e-02,\n",
      "         -5.6806e-02,  6.9620e-02,  3.0904e-02, -8.1938e-02, -1.0098e-01,\n",
      "          4.0340e-02, -3.0546e-02, -8.6797e-02, -6.3704e-02, -3.7215e-03,\n",
      "         -9.0268e-03, -5.4276e-02, -5.2279e-02,  1.1555e-01,  3.8499e-02,\n",
      "          1.2419e-01, -4.8845e-02,  9.4236e-02,  1.1475e-01,  1.1006e-01,\n",
      "         -3.8104e-02, -2.0593e-02,  1.1683e-01, -1.1960e-01,  1.0523e-01,\n",
      "         -2.1212e-02, -5.2740e-02, -5.6530e-02, -4.1058e-02,  6.0693e-02,\n",
      "         -9.9333e-02, -3.9888e-02,  5.0265e-03, -7.5892e-02,  2.0436e-03,\n",
      "          1.1761e-02,  9.8880e-02,  7.5645e-02, -5.1031e-02],\n",
      "        [ 1.1096e-01, -2.9484e-02,  8.4360e-02,  1.1286e-01, -1.2456e-01,\n",
      "         -1.7641e-02, -9.4857e-02,  2.5625e-02,  7.4421e-02, -2.5951e-02,\n",
      "          7.2550e-03, -1.0771e-02, -5.7181e-02,  3.5175e-02,  8.3449e-02,\n",
      "          1.0715e-01,  9.5988e-02,  1.1921e-01,  4.1921e-02,  2.3355e-02,\n",
      "          8.4819e-02,  3.0921e-02,  5.6624e-02,  5.2696e-02,  7.3920e-02,\n",
      "          5.3091e-02, -9.2767e-02,  7.6780e-02, -4.2606e-02,  7.2457e-02,\n",
      "          1.2487e-04,  1.0532e-01,  1.0222e-01,  4.4653e-02, -3.0216e-02,\n",
      "          1.2092e-01, -1.0248e-01, -2.7380e-02,  8.1975e-02,  5.8374e-02,\n",
      "         -1.1968e-01, -1.2307e-01,  1.7041e-02, -6.2273e-02, -1.4598e-02,\n",
      "         -6.7593e-02, -1.2037e-01,  9.6602e-02, -1.2434e-01,  6.5912e-02,\n",
      "         -4.3724e-03, -2.6425e-02, -1.1560e-01,  8.5567e-02, -1.1219e-01,\n",
      "         -8.6665e-03, -7.0470e-02,  8.2788e-02, -3.5996e-02, -3.9140e-03,\n",
      "         -1.0527e-01, -9.5568e-02,  1.2047e-01,  1.0074e-01],\n",
      "        [ 8.7336e-02, -1.0800e-01,  4.7985e-02, -1.1227e-01, -1.1762e-01,\n",
      "          1.0459e-01,  5.9983e-02,  4.0797e-02, -2.0176e-03,  8.5859e-02,\n",
      "          8.4055e-02, -2.2261e-02, -1.4081e-02, -1.0146e-01, -4.5706e-02,\n",
      "          7.0251e-02, -1.2113e-02, -9.2643e-02, -1.9243e-02,  7.7775e-02,\n",
      "         -4.8659e-02,  3.8435e-02,  4.4539e-02,  2.2430e-02, -9.0055e-02,\n",
      "         -4.4783e-02, -2.7364e-02, -6.5117e-02, -6.5333e-02,  4.0722e-02,\n",
      "          1.7659e-02, -5.8316e-02, -1.0544e-01, -4.2637e-02, -9.3997e-02,\n",
      "          8.5790e-02, -6.3503e-02, -6.1131e-03, -1.1791e-02, -9.9980e-02,\n",
      "          4.8853e-02, -1.0237e-01,  8.3318e-02,  6.4625e-03,  1.1788e-01,\n",
      "         -2.6787e-02,  1.8002e-02,  4.6911e-02,  8.0150e-02,  8.8236e-02,\n",
      "         -7.8604e-02,  9.0625e-02, -6.5071e-02, -8.6439e-02, -9.3865e-02,\n",
      "         -5.1054e-02, -7.5958e-02, -1.1391e-01,  7.5539e-02,  1.1344e-01,\n",
      "         -1.0045e-01, -9.7110e-03, -9.4882e-02,  9.2455e-02],\n",
      "        [-1.1825e-01, -9.2621e-02, -2.2392e-02,  2.4579e-02, -8.0049e-02,\n",
      "          2.3531e-02, -7.9302e-02,  4.6731e-02, -1.7859e-02,  6.0081e-02,\n",
      "         -4.1354e-02, -7.3310e-02,  2.3170e-02,  9.7400e-02, -9.8131e-02,\n",
      "         -4.4239e-02, -8.4442e-02, -1.0848e-02,  1.0719e-02, -8.4930e-02,\n",
      "         -6.3447e-02, -3.9436e-02,  3.4149e-02,  8.4624e-02,  2.8282e-02,\n",
      "          1.3293e-02, -5.1026e-02,  1.9968e-02, -7.0106e-02,  8.4856e-03,\n",
      "         -8.4308e-02,  9.0234e-02, -2.0454e-02, -2.1520e-02, -7.5107e-03,\n",
      "          2.0516e-02,  8.8608e-02,  1.0370e-01,  3.3900e-02, -1.1270e-01,\n",
      "          3.6060e-02, -1.4679e-02,  9.6539e-02,  3.2520e-02, -6.5403e-02,\n",
      "          6.3348e-02,  7.5782e-02, -1.6603e-02, -3.9565e-02,  7.0844e-02,\n",
      "         -1.9934e-02,  1.2415e-02, -4.4804e-02,  1.1601e-03, -6.4104e-02,\n",
      "          1.0931e-01, -3.5311e-02, -4.8272e-02, -2.0547e-02, -5.6929e-02,\n",
      "         -6.6825e-03,  3.4194e-02,  1.0443e-01, -6.7780e-02],\n",
      "        [ 5.7610e-02,  1.1359e-01, -5.5231e-02,  2.6031e-02, -1.0269e-01,\n",
      "          1.1590e-01,  1.2368e-01, -9.3560e-02,  9.1297e-02, -1.6380e-02,\n",
      "          1.7096e-02,  5.9466e-02, -6.5263e-02,  5.4664e-02, -1.1379e-01,\n",
      "         -1.1013e-01,  4.8979e-02, -4.8132e-02, -1.1328e-01,  1.5242e-02,\n",
      "          1.5699e-02, -1.5044e-03, -3.0855e-02,  1.0595e-01, -4.6104e-02,\n",
      "          1.8859e-02, -9.3398e-02, -8.1528e-02,  5.7841e-02, -3.4417e-02,\n",
      "         -4.7706e-02, -6.8190e-02,  3.1116e-02, -1.2211e-01, -1.6295e-03,\n",
      "          3.4376e-02,  1.1745e-01,  2.0145e-02, -6.7272e-02, -1.1909e-02,\n",
      "         -1.0241e-02,  8.4308e-02,  8.0172e-02, -4.6517e-02, -1.5879e-02,\n",
      "         -7.1296e-02,  8.4133e-02, -9.1442e-02, -8.1382e-03,  1.0905e-01,\n",
      "          9.5332e-02,  6.3450e-02, -4.0427e-02,  3.1519e-03, -1.1601e-01,\n",
      "         -3.7986e-02, -8.4748e-02, -3.5602e-02, -7.9261e-02, -3.6827e-02,\n",
      "          1.0688e-02,  4.8985e-02,  5.7314e-03, -3.0751e-02],\n",
      "        [ 6.4215e-02,  4.4981e-02,  1.1623e-01,  9.9474e-02, -2.1995e-02,\n",
      "         -1.0542e-01, -5.9149e-02, -8.9936e-02,  7.1121e-02,  2.2321e-03,\n",
      "          8.2324e-02, -1.0001e-01, -7.6353e-02,  8.7880e-02,  2.5681e-02,\n",
      "         -1.3340e-02,  1.9140e-02, -6.6221e-02,  7.8030e-02,  4.6911e-02,\n",
      "         -2.4214e-04, -1.6265e-02,  5.2887e-02,  6.8107e-02,  5.8434e-02,\n",
      "          1.1988e-01, -8.3310e-02, -8.8364e-02, -8.6764e-02, -2.1162e-02,\n",
      "          4.5588e-02, -5.8607e-02,  5.3146e-02,  2.3239e-02,  8.8027e-02,\n",
      "          1.1459e-01,  2.4013e-02, -1.1161e-01, -9.5927e-02,  3.6866e-02,\n",
      "          9.9355e-02, -6.2274e-02, -9.7699e-02,  1.2001e-02,  7.0679e-02,\n",
      "          6.7444e-02,  5.6661e-02,  6.9926e-03,  1.1372e-01, -5.4843e-02,\n",
      "          7.8706e-03,  6.5930e-03,  4.2897e-03,  3.7209e-02,  5.3065e-02,\n",
      "         -5.1310e-02, -6.1419e-02,  1.2271e-01, -1.8359e-02, -1.0840e-03,\n",
      "         -6.9362e-02,  5.1705e-02,  4.0332e-02,  8.2088e-02],\n",
      "        [ 5.1402e-02,  3.1434e-02, -3.3119e-02,  4.4915e-02, -1.7506e-02,\n",
      "         -1.1927e-01,  2.4261e-02,  7.8084e-02, -1.3006e-02,  1.1865e-01,\n",
      "          3.8069e-02, -5.0305e-03, -9.5928e-02, -4.1312e-02, -3.4159e-02,\n",
      "         -5.4341e-03, -7.3317e-02, -5.2765e-03,  1.2136e-01,  8.9607e-02,\n",
      "          7.4826e-03,  1.0239e-01, -6.1039e-02, -5.8693e-02,  1.1994e-01,\n",
      "         -8.5337e-02, -1.3279e-03,  4.1641e-02,  1.1752e-01, -1.7315e-03,\n",
      "          1.7420e-02,  7.9382e-02,  5.2826e-02, -1.3164e-02,  8.2901e-02,\n",
      "          8.7031e-02,  1.6108e-05, -1.7013e-02,  9.7891e-02,  6.6731e-02,\n",
      "          4.4454e-02, -4.1929e-03,  3.2809e-02, -5.7558e-02, -7.7665e-02,\n",
      "          9.3957e-02,  9.7856e-02,  1.1499e-01,  1.0234e-02,  4.8210e-04,\n",
      "         -6.2864e-02,  4.2782e-02,  1.2474e-01, -2.8375e-02,  1.3956e-03,\n",
      "         -1.4160e-02,  6.2241e-02, -6.3005e-02,  1.1685e-01, -2.5900e-02,\n",
      "          1.0853e-03,  4.1080e-02, -1.1391e-01,  1.1097e-01],\n",
      "        [-1.2356e-01, -1.1828e-01, -5.1152e-02,  9.1184e-02,  3.4859e-02,\n",
      "          4.2199e-03,  3.5267e-02,  6.5444e-02,  6.9904e-02, -7.8377e-02,\n",
      "         -2.9522e-02,  2.9579e-02,  7.5826e-02,  1.2299e-01, -5.8083e-02,\n",
      "          1.4542e-02,  9.9889e-02, -1.1756e-01, -2.6520e-02,  2.6265e-02,\n",
      "         -2.2715e-02,  5.4280e-02,  2.7040e-02,  8.9112e-02, -3.5488e-02,\n",
      "          1.9791e-02,  1.0147e-01, -9.2626e-03,  7.4977e-02,  3.0081e-02,\n",
      "          3.4834e-02, -4.0693e-02,  7.3045e-02,  9.8319e-02, -1.7657e-02,\n",
      "          3.3605e-03, -7.8931e-02, -4.5903e-02,  8.9335e-02,  3.6906e-02,\n",
      "         -9.5655e-03, -1.1350e-01,  9.9797e-02, -7.9142e-02,  5.6917e-02,\n",
      "          2.3464e-02,  1.1675e-01, -9.8895e-03, -5.1493e-02,  5.6134e-02,\n",
      "          4.2654e-02, -7.5733e-02,  7.9066e-02,  5.2352e-02,  5.4713e-03,\n",
      "         -1.1371e-01, -2.8741e-03, -5.8189e-05, -5.2976e-02, -1.2268e-01,\n",
      "         -2.7689e-02,  1.1333e-01, -3.0179e-02, -7.2207e-02],\n",
      "        [-5.4280e-02,  1.2378e-01,  5.4840e-02, -7.0602e-02,  8.6763e-02,\n",
      "         -8.6934e-02, -5.1994e-02, -4.7596e-02,  1.1355e-01,  1.7506e-02,\n",
      "          1.0783e-01, -1.1896e-02,  2.7793e-02,  4.1589e-02,  1.1027e-01,\n",
      "         -9.4983e-02,  1.8705e-03,  5.3042e-02, -6.8567e-02, -1.0249e-01,\n",
      "         -1.0110e-01,  2.7829e-02,  2.9891e-02, -3.2748e-02,  1.4662e-02,\n",
      "          7.7153e-03,  2.6905e-02,  6.6180e-02, -3.5394e-02,  7.2361e-02,\n",
      "          2.2366e-02, -1.1158e-03,  4.9579e-02,  2.8159e-02, -1.1313e-01,\n",
      "         -1.2026e-01, -7.4840e-02, -9.2700e-02, -8.5426e-02, -1.0876e-01,\n",
      "          2.5564e-02,  1.0635e-01,  3.7198e-02,  1.0618e-01, -1.3526e-03,\n",
      "         -1.2223e-01, -9.1189e-02,  1.8088e-02,  1.0889e-01, -5.7400e-02,\n",
      "         -2.3600e-03, -8.1317e-02, -5.8785e-02, -3.3611e-02,  7.1991e-02,\n",
      "         -9.1359e-02, -4.7827e-02,  7.4167e-02,  9.8498e-02, -6.6788e-02,\n",
      "          1.0110e-01, -6.2080e-02,  9.6355e-02,  7.8532e-02]])), ('fully_connected2.0.bias', tensor([-0.1010,  0.0756, -0.0108, -0.0471,  0.1137,  0.1229, -0.0650,  0.0649,\n",
      "         0.1019, -0.0722]))])\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(number_classes=10)\n",
    "print(model)\n",
    "#model.convolution_block\n",
    "#model.flatten\n",
    "print(model.state_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001, weight_decay = 0.005, momentum = 0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss\n",
    "loss_fn1 = nn.MSELoss()\n",
    "loss_fn2 = nn.CrossEntropyLoss()       # Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "def get_test_loader(data_dir,\n",
    "                    batch_size,\n",
    "                    shuffle=True):\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "\n",
    "    # define transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((227,227)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=False,\n",
    "        download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fns, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader): # y : GT\n",
    "        pred = model(X)\n",
    "        loss_sum = 0.0\n",
    "        for loss_fn in loss_fns:\n",
    "          pred_max, max_indices = torch.max(pred, dim=1)\n",
    "          pred_max = pred_max.to(torch.float)\n",
    "          y = y.to(torch.float)\n",
    "          loss_sum += loss_fn(pred_max, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_sum = loss_sum.to(torch.float)\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss_sum\n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss_sum.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    train_loss /= len(dataloader)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fns):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad(): # To freeze the network\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss_sum = 0.0\n",
    "            for loss_fn in loss_fns: \n",
    "                pred_max, max_indices = torch.max(pred, dim=1)\n",
    "                test_loss_sum += loss_fn(pred_max, y).item()\n",
    "            test_loss += test_loss_sum\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item() # calculating number of batches\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.CIFAR10(root=\"../data/cifar10/\", train=True, download=False, transform=ToTensor())\n",
    "\n",
    "test_data = datasets.CIFAR10(root=\"../data/cifar10/\", train=False, download=False, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "indices = torch.arange(0,1000)\n",
    "training_data = data_utils.Subset(training_data, indices)\n",
    "\n",
    "indices = torch.arange(0,100)\n",
    "test_data = data_utils.Subset(test_data, indices)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "loaded_train = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "loaded_test = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(model, loss_fns, optimizer, num_epochs = 5):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for t in range(num_epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = train(loaded_train, model, loss_fns, optimizer)\n",
    "        train_loss = train_loss.detach().numpy()\n",
    "        test_loss, accuracy = test(loaded_test, model, loss_fns)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        accuracy_scores.append(accuracy)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    fig,axs = plt.subplots(1, 2, figsize=(8,8))\n",
    "    axs = axs.ravel()\n",
    "    axs[0].plot(range(num_epochs), train_losses, \":r\")\n",
    "    axs[0].plot(range(num_epochs), test_losses, \"-b\")\n",
    "\n",
    "    axs[1].plot(range(num_epochs), accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 19.568432  [    0/ 1000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yusuf\\.conda\\envs\\mldl\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (64) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m eval_net(model, loss_fns\u001b[39m=\u001b[39;49m[loss_fn1], optimizer\u001b[39m=\u001b[39;49moptimizer, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[192], line 10\u001b[0m, in \u001b[0;36meval_net\u001b[1;34m(model, loss_fns, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m      8\u001b[0m train_loss \u001b[39m=\u001b[39m train(loaded_train, model, loss_fns, optimizer)\n\u001b[0;32m      9\u001b[0m train_loss \u001b[39m=\u001b[39m train_loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m---> 10\u001b[0m test_loss, accuracy \u001b[39m=\u001b[39m test(loaded_test, model, loss_fns)\n\u001b[0;32m     11\u001b[0m train_losses\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[0;32m     12\u001b[0m test_losses\u001b[39m.\u001b[39mappend(test_loss)\n",
      "Cell \u001b[1;32mIn[189], line 12\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(dataloader, model, loss_fns)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m loss_fn \u001b[39min\u001b[39;00m loss_fns: \n\u001b[0;32m     11\u001b[0m     pred_max, max_indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(pred, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     test_loss_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_fn(pred, y)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     13\u001b[0m test_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m test_loss_sum\n\u001b[0;32m     14\u001b[0m correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (pred\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m y)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem() \u001b[39m# calculating number of batches\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yusuf\\.conda\\envs\\mldl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\yusuf\\.conda\\envs\\mldl\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\yusuf\\.conda\\envs\\mldl\\lib\\site-packages\\torch\\nn\\functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3291\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3292\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[0;32m   3295\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[1;32mc:\\Users\\yusuf\\.conda\\envs\\mldl\\lib\\site-packages\\torch\\functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[1;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (64) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "eval_net(model, loss_fns=[loss_fn1], optimizer=optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
