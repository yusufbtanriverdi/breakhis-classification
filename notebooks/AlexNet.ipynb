{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet is a convolutional neural network (CNN).\n",
    "It was one of the first CNNs to demonstrate the effectiveness of deep learning for image classification tasks.\n",
    "\n",
    "AlexNet is composed of 8 layers: 5 convolutional layers, 2 fully connected layers, and 1 softmax layer. It uses the Rectified Linear Unit (ReLU) activation function, local response normalization, and dropout regularization to prevent overfitting.\n",
    "\n",
    "Firstly, it operated with 3-channel images that were (224x224x3) in size. It used max pooling along with ReLU activations when subsampling. The kernels used for convolutions were either 11x11, 5x5, or 3x3 while kernels used for max pooling were 3x3 in size. It classified images into 1000 classes. It also utilized multiple GPUs.\n",
    "\n",
    "Source: https://blog.paperspace.com/alexnet-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn # For the dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, number_classes=10):\n",
    "\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.number_classes = number_classes\n",
    "        self.convolution_block1 = nn.Sequential(       # First convolution layer\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),  # 2D convolution layer, 3 channel image, applies 96 filters of size 11x11 with a stride of 4 and no padding\n",
    "            nn.BatchNorm2d(96),                                     # Normalizing batch layer for the first convolution layer\n",
    "            nn.ReLU(),                                              # ReLU is a non-linear activation function\n",
    "            nn.MaxPool2d(kernel_size=2, stride = 2),                # reducing the spatial dimensions of the output tensor by half.\n",
    "        )\n",
    "        self.convolution_block2 = nn.Sequential(                    # Second convolution layer, to learn more complex and abstract features from the image.\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2), # input tensor is the output from the first convolutional layer\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.convolution_block3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.convolution_block4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.convolution_block5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        # Fully connected layers,  to convert the high-dimensional output from the convolutional layers to a probability distribution over the possible classes.\n",
    "        # used to prevent overfitting by randomly dropping out units during training\n",
    "        # RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x256 and 9216x4096)\n",
    "        self.fully_connected = nn.Sequential(                       \n",
    "            nn.Dropout(0.3),                                        \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU())\n",
    "        self.fully_connected1 = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU())\n",
    "        self.fully_connected2= nn.Sequential(                     \n",
    "            nn.Linear(64, number_classes))                        #Softmax function,  produces a probability distribution over the possible classes, allowing the network to make a prediction.         \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.convolution_block1(x)\n",
    "        out = self.convolution_block2(out)\n",
    "        out = self.convolution_block3(out)\n",
    "        out = self.convolution_block4(out)\n",
    "        out = self.convolution_block5(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fully_connected(out)\n",
    "        out = self.fully_connected1(out)\n",
    "        logits = self.fully_connected2(out)\n",
    "\n",
    "        return logits      # class probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (convolution_block1): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (convolution_block2): Sequential(\n",
      "    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (convolution_block3): Sequential(\n",
      "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (convolution_block4): Sequential(\n",
      "    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (convolution_block5): Sequential(\n",
      "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fully_connected): Sequential(\n",
      "    (0): Dropout(p=0.3, inplace=False)\n",
      "    (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fully_connected1): Sequential(\n",
      "    (0): Dropout(p=0.3, inplace=False)\n",
      "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fully_connected2): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "OrderedDict([('convolution_block1.0.weight', tensor([[[[-2.9489e-02,  2.5328e-02, -4.9918e-02,  ...,  1.7282e-03,\n",
      "           -4.1940e-02,  1.7447e-02],\n",
      "          [-2.0848e-02,  4.1766e-02,  3.9791e-02,  ..., -2.4624e-02,\n",
      "            7.8293e-04,  2.8776e-02],\n",
      "          [-3.6706e-02,  3.1944e-02, -1.3326e-03,  ..., -2.9502e-02,\n",
      "            2.4651e-02, -4.9864e-02],\n",
      "          ...,\n",
      "          [-7.2629e-03,  1.3549e-02, -1.4187e-02,  ...,  4.7907e-02,\n",
      "           -2.0749e-02, -2.8833e-02],\n",
      "          [ 4.5358e-02, -3.1652e-02,  1.8412e-02,  ...,  3.0836e-02,\n",
      "           -4.1700e-02,  4.0731e-02],\n",
      "          [ 4.0335e-02, -1.8159e-02, -2.3081e-02,  ...,  2.7216e-04,\n",
      "            1.1346e-02, -2.9965e-02]],\n",
      "\n",
      "         [[ 4.9104e-02,  2.6860e-02, -3.7993e-02,  ..., -5.1913e-02,\n",
      "            4.7883e-02,  2.6826e-02],\n",
      "          [ 2.8094e-02, -2.5023e-02, -1.1986e-02,  ...,  5.0476e-02,\n",
      "           -5.1087e-02,  8.0131e-03],\n",
      "          [ 2.5625e-02, -4.0649e-02,  2.5865e-02,  ..., -3.1039e-02,\n",
      "            3.9054e-02, -5.1436e-02],\n",
      "          ...,\n",
      "          [ 2.3979e-03,  2.7347e-02,  4.9127e-02,  ...,  3.0299e-02,\n",
      "           -2.7958e-02, -1.5897e-02],\n",
      "          [ 8.1505e-03, -5.5554e-03, -4.6788e-02,  ..., -4.7546e-02,\n",
      "           -8.5029e-03,  3.0440e-02],\n",
      "          [-4.7408e-02,  1.5885e-03,  2.8136e-02,  ...,  8.7916e-03,\n",
      "            5.1877e-02,  1.2586e-02]],\n",
      "\n",
      "         [[-4.5325e-02, -4.8808e-02, -1.6653e-02,  ..., -1.0424e-02,\n",
      "           -4.1302e-02,  1.1526e-02],\n",
      "          [ 2.2873e-02,  4.2353e-03,  2.6468e-02,  ..., -4.2029e-02,\n",
      "            3.6693e-02, -2.1002e-02],\n",
      "          [-2.1734e-02,  1.0693e-02, -4.1522e-02,  ...,  4.1579e-02,\n",
      "           -1.0237e-02, -5.1665e-02],\n",
      "          ...,\n",
      "          [ 3.3257e-02,  4.3349e-02,  3.1990e-02,  ..., -4.6963e-02,\n",
      "           -1.1353e-02, -4.3820e-02],\n",
      "          [-5.1995e-02, -3.3579e-02,  1.0929e-02,  ..., -4.7519e-02,\n",
      "           -4.2078e-03, -2.5323e-02],\n",
      "          [-6.2444e-04,  4.8991e-02,  2.4255e-02,  ..., -3.3756e-02,\n",
      "           -3.9730e-02,  2.6142e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6235e-02, -4.1631e-02,  3.7145e-02,  ..., -4.9570e-02,\n",
      "            4.7143e-02, -4.7814e-03],\n",
      "          [ 5.0816e-02, -2.8778e-02, -2.4904e-02,  ..., -1.4746e-02,\n",
      "           -3.8184e-02,  8.1191e-03],\n",
      "          [-3.8162e-02,  3.5453e-02, -1.6557e-02,  ..., -4.0867e-02,\n",
      "            1.6649e-02, -2.6112e-02],\n",
      "          ...,\n",
      "          [-3.3792e-02,  3.8009e-02, -1.5315e-02,  ..., -2.8860e-02,\n",
      "            1.1509e-02, -5.1187e-02],\n",
      "          [ 1.5798e-02, -2.9564e-02, -2.6635e-02,  ..., -4.3012e-02,\n",
      "           -2.6707e-02, -9.6484e-03],\n",
      "          [ 4.3619e-02,  3.5752e-03,  2.1430e-02,  ..., -3.7265e-02,\n",
      "           -2.6066e-02, -5.2410e-02]],\n",
      "\n",
      "         [[-4.5202e-02,  4.3407e-02, -2.6266e-02,  ..., -3.6523e-02,\n",
      "            1.1762e-02,  4.1885e-02],\n",
      "          [-4.1450e-02,  1.5154e-02, -1.1089e-03,  ...,  7.7891e-03,\n",
      "            1.9319e-02, -2.9030e-02],\n",
      "          [ 4.5971e-02,  3.5096e-02,  9.0572e-03,  ..., -1.6931e-02,\n",
      "           -9.6702e-03, -1.6948e-02],\n",
      "          ...,\n",
      "          [-6.0926e-03, -4.1315e-02, -2.5027e-02,  ..., -2.5970e-02,\n",
      "            5.0522e-02, -3.4895e-02],\n",
      "          [-5.0688e-02,  1.2126e-03, -2.7084e-02,  ..., -4.8194e-02,\n",
      "            2.7223e-02,  1.5256e-02],\n",
      "          [ 4.4194e-02,  4.0438e-03,  4.9307e-02,  ..., -5.8230e-03,\n",
      "            2.1631e-02, -1.1033e-02]],\n",
      "\n",
      "         [[ 1.3029e-02, -2.4833e-02,  6.4815e-03,  ..., -4.8693e-02,\n",
      "           -2.5148e-02, -7.1852e-03],\n",
      "          [-5.1555e-02, -2.2259e-03,  1.8641e-02,  ...,  4.8567e-02,\n",
      "           -5.1635e-03, -3.2700e-03],\n",
      "          [ 1.4152e-02, -1.0077e-02, -4.9444e-02,  ..., -3.6852e-02,\n",
      "           -2.3533e-02,  4.3304e-02],\n",
      "          ...,\n",
      "          [ 7.4395e-03,  1.9419e-02,  3.4643e-02,  ...,  4.5827e-02,\n",
      "           -2.2304e-02,  4.0214e-02],\n",
      "          [-1.4506e-02,  2.3043e-02,  1.4907e-02,  ..., -9.5175e-03,\n",
      "           -1.8595e-02,  3.4541e-03],\n",
      "          [ 4.3150e-02, -3.0468e-02, -9.8961e-03,  ...,  3.9693e-02,\n",
      "            2.0089e-02,  2.4874e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6004e-02,  5.0658e-02, -3.5580e-02,  ..., -3.6084e-02,\n",
      "           -5.0051e-03,  2.2303e-02],\n",
      "          [ 1.7769e-02, -1.7777e-02,  4.0896e-02,  ...,  3.1030e-02,\n",
      "            4.4558e-02, -6.4553e-04],\n",
      "          [-1.0701e-02,  4.9059e-03, -4.9375e-02,  ...,  2.3798e-02,\n",
      "           -2.7882e-02, -3.0383e-02],\n",
      "          ...,\n",
      "          [ 8.5993e-03,  3.6622e-02,  1.1712e-02,  ...,  4.7114e-02,\n",
      "           -5.0615e-04, -5.4663e-03],\n",
      "          [-1.4751e-02, -1.4003e-02,  2.6775e-02,  ...,  2.8476e-02,\n",
      "            1.7789e-02, -1.2587e-02],\n",
      "          [-5.0231e-02,  3.4490e-02,  6.0203e-03,  ..., -2.8848e-02,\n",
      "            3.1517e-02,  4.4325e-02]],\n",
      "\n",
      "         [[-2.3995e-02, -3.0551e-04, -5.1641e-02,  ...,  3.7278e-02,\n",
      "           -2.4913e-02, -1.5391e-02],\n",
      "          [-3.9820e-03, -1.1010e-02, -1.8457e-04,  ...,  5.1942e-02,\n",
      "           -1.0577e-03,  2.6084e-02],\n",
      "          [ 5.8012e-03, -1.5162e-02, -3.2015e-02,  ..., -3.1798e-02,\n",
      "            2.1144e-03, -2.9832e-02],\n",
      "          ...,\n",
      "          [ 4.7768e-02,  3.3106e-02, -6.3835e-03,  ...,  5.6019e-03,\n",
      "            4.2068e-02,  1.1683e-02],\n",
      "          [-5.6323e-03,  2.4798e-04,  1.1558e-02,  ...,  3.7052e-02,\n",
      "            1.7918e-02,  2.1455e-02],\n",
      "          [-4.1564e-02,  9.2651e-03, -4.2403e-02,  ...,  1.9636e-02,\n",
      "           -1.3985e-02,  1.3403e-02]],\n",
      "\n",
      "         [[-5.1172e-02, -1.9651e-02, -1.8496e-02,  ...,  1.3467e-02,\n",
      "           -3.1430e-02,  4.9237e-02],\n",
      "          [ 1.2683e-02,  5.1855e-02,  9.4338e-03,  ...,  8.6658e-03,\n",
      "            2.0521e-02,  2.5023e-02],\n",
      "          [-2.2049e-02, -4.7917e-02,  1.6723e-02,  ..., -3.7638e-02,\n",
      "            5.2329e-02,  1.5249e-02],\n",
      "          ...,\n",
      "          [ 2.1803e-02,  4.3412e-02,  3.7886e-02,  ..., -4.7186e-02,\n",
      "           -4.0783e-02,  3.2505e-02],\n",
      "          [ 1.6029e-02, -5.1877e-02,  4.2878e-02,  ...,  6.4711e-03,\n",
      "           -5.0931e-02, -4.3620e-02],\n",
      "          [ 4.4876e-02, -6.7287e-03,  1.5687e-03,  ..., -4.0372e-02,\n",
      "            3.9791e-02,  1.0510e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.7504e-02,  3.6353e-02, -3.4426e-02,  ..., -3.4091e-02,\n",
      "            4.5921e-02, -1.9169e-02],\n",
      "          [-8.0408e-03, -3.3662e-02, -2.5676e-02,  ...,  3.8903e-02,\n",
      "            4.6762e-02,  4.8210e-02],\n",
      "          [-2.8650e-02,  4.7469e-02,  2.9811e-02,  ...,  1.6567e-02,\n",
      "            1.8276e-02,  3.5577e-02],\n",
      "          ...,\n",
      "          [-3.0027e-02, -4.8495e-02,  1.1650e-02,  ..., -7.5820e-03,\n",
      "            5.1086e-02, -5.0477e-02],\n",
      "          [ 1.1749e-02,  4.9639e-02, -3.7757e-02,  ..., -2.6849e-02,\n",
      "           -4.2986e-02,  2.4812e-02],\n",
      "          [-3.1590e-05,  5.1139e-02,  1.6040e-02,  ..., -2.4400e-02,\n",
      "            4.8305e-03, -4.9521e-02]],\n",
      "\n",
      "         [[-3.8570e-02,  4.3627e-02,  2.1384e-02,  ..., -2.6496e-02,\n",
      "            2.4430e-02,  3.1559e-02],\n",
      "          [-5.2100e-02,  3.8514e-02,  2.7158e-02,  ..., -4.7345e-02,\n",
      "           -9.2851e-03,  2.3419e-02],\n",
      "          [ 1.7386e-02,  2.2427e-02,  8.5543e-04,  ..., -1.7231e-02,\n",
      "            4.0456e-02,  8.0979e-03],\n",
      "          ...,\n",
      "          [ 1.7580e-02, -2.4994e-02,  4.5053e-02,  ...,  5.8913e-03,\n",
      "           -4.4821e-02,  2.0307e-02],\n",
      "          [ 3.2104e-03,  1.3258e-02, -3.1245e-02,  ...,  3.2838e-02,\n",
      "           -2.1805e-02,  1.8256e-02],\n",
      "          [-2.4503e-02, -5.0809e-02, -2.6438e-02,  ...,  7.1876e-03,\n",
      "            3.3512e-02,  2.1070e-02]],\n",
      "\n",
      "         [[-4.2830e-03, -1.4701e-02, -4.8482e-02,  ...,  3.2609e-02,\n",
      "           -2.0441e-02, -2.8880e-02],\n",
      "          [ 3.3954e-02, -1.9074e-02, -2.8666e-02,  ...,  3.4830e-02,\n",
      "           -1.1471e-02, -1.8743e-02],\n",
      "          [ 6.4690e-03,  2.8765e-02, -1.1486e-02,  ..., -4.2749e-02,\n",
      "            1.1289e-02, -1.4625e-02],\n",
      "          ...,\n",
      "          [ 4.9252e-02, -6.1256e-03,  1.2081e-02,  ..., -2.5473e-02,\n",
      "           -5.1731e-02,  1.0643e-02],\n",
      "          [ 1.5021e-02, -4.1474e-02,  9.0513e-03,  ...,  2.8125e-03,\n",
      "           -2.0337e-02, -4.9454e-02],\n",
      "          [ 7.3406e-03,  1.7249e-02, -3.2880e-02,  ...,  3.9970e-03,\n",
      "            2.9265e-02,  3.1961e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1804e-02, -2.5555e-02, -3.6093e-02,  ..., -1.6579e-03,\n",
      "            1.6603e-02, -1.7009e-02],\n",
      "          [-3.5796e-02, -4.2742e-02,  1.8903e-02,  ...,  3.0385e-02,\n",
      "            4.5700e-02, -2.5432e-02],\n",
      "          [ 1.4072e-02,  3.5461e-02,  1.6083e-02,  ...,  2.6557e-02,\n",
      "            1.4589e-03, -2.8339e-02],\n",
      "          ...,\n",
      "          [-3.4347e-03, -2.0536e-02,  3.4324e-02,  ...,  1.9052e-02,\n",
      "            4.7936e-02,  1.7865e-02],\n",
      "          [ 8.7720e-03, -3.4630e-02, -3.5814e-02,  ...,  3.7532e-02,\n",
      "            5.0727e-02,  1.4164e-02],\n",
      "          [ 3.8041e-02,  4.9114e-02,  4.8216e-05,  ...,  2.1923e-02,\n",
      "           -3.9643e-02,  9.1058e-03]],\n",
      "\n",
      "         [[ 4.1986e-02, -5.5387e-03, -2.3892e-02,  ..., -2.0699e-02,\n",
      "            2.6090e-02, -5.1327e-02],\n",
      "          [ 3.3421e-02,  2.6462e-03,  7.0658e-03,  ...,  3.8315e-02,\n",
      "            2.9205e-02, -1.8715e-02],\n",
      "          [-3.9945e-02, -4.5240e-02, -2.6021e-02,  ..., -3.2777e-02,\n",
      "           -4.2445e-02,  4.3783e-02],\n",
      "          ...,\n",
      "          [-2.9440e-02, -4.2574e-03,  4.8806e-02,  ...,  1.2218e-02,\n",
      "           -9.2694e-03, -8.9199e-03],\n",
      "          [-1.7198e-03,  1.3033e-02,  4.2779e-02,  ...,  3.8661e-02,\n",
      "           -4.5072e-02,  2.7548e-02],\n",
      "          [ 6.3425e-03, -3.7986e-02, -1.7115e-02,  ...,  3.8813e-02,\n",
      "            1.5811e-02,  3.3329e-02]],\n",
      "\n",
      "         [[ 1.3730e-02, -1.7884e-02,  4.9929e-02,  ..., -2.1381e-02,\n",
      "           -9.7674e-03, -3.0614e-02],\n",
      "          [ 1.8460e-02, -4.6092e-02,  7.5347e-03,  ..., -2.3714e-02,\n",
      "            2.2338e-02, -2.2388e-02],\n",
      "          [-5.1897e-02, -2.5792e-02,  2.1201e-02,  ...,  4.3234e-02,\n",
      "            4.6824e-02,  3.7614e-02],\n",
      "          ...,\n",
      "          [ 2.6918e-03, -3.9160e-02, -5.4645e-03,  ..., -1.4147e-02,\n",
      "           -3.5950e-02,  1.3017e-02],\n",
      "          [-2.8937e-02, -1.5770e-02,  3.9170e-02,  ...,  5.0414e-02,\n",
      "           -3.4845e-02, -2.1630e-02],\n",
      "          [-4.3424e-02, -2.8858e-02, -4.5611e-02,  ..., -2.8610e-02,\n",
      "            1.9203e-02,  3.5955e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9364e-02,  4.2141e-02,  4.0200e-02,  ..., -3.8633e-02,\n",
      "           -2.1460e-02,  1.7092e-02],\n",
      "          [-3.6369e-02,  3.0141e-02,  3.6154e-02,  ..., -3.8126e-02,\n",
      "           -2.5286e-02, -4.0686e-02],\n",
      "          [ 3.7670e-03,  4.9582e-02,  2.4662e-02,  ..., -2.7635e-03,\n",
      "           -3.3313e-02,  1.0015e-02],\n",
      "          ...,\n",
      "          [-3.0335e-02,  6.4802e-03, -3.1514e-02,  ...,  1.6024e-02,\n",
      "            3.4801e-02,  1.9161e-02],\n",
      "          [-1.8367e-02, -5.3024e-03, -1.3338e-02,  ...,  1.6142e-02,\n",
      "           -4.9211e-03,  1.9964e-02],\n",
      "          [-1.8680e-02, -4.1548e-02, -3.6491e-02,  ..., -2.9147e-02,\n",
      "            1.0013e-02, -3.4131e-03]],\n",
      "\n",
      "         [[-4.8250e-02,  1.0143e-02,  3.3095e-02,  ...,  4.8155e-02,\n",
      "            7.2950e-03,  2.5413e-02],\n",
      "          [ 5.0409e-02,  2.9813e-02,  8.0100e-03,  ...,  5.0159e-02,\n",
      "           -4.8897e-02,  2.3845e-02],\n",
      "          [-2.2538e-03, -1.5599e-02, -2.7020e-02,  ..., -2.2682e-02,\n",
      "           -2.0691e-02, -3.9110e-02],\n",
      "          ...,\n",
      "          [-2.8869e-02, -4.9589e-02, -4.9445e-02,  ..., -4.8670e-02,\n",
      "           -4.2811e-02, -2.9717e-02],\n",
      "          [-2.5981e-02,  9.5823e-03, -1.3377e-02,  ..., -1.0489e-02,\n",
      "            2.0921e-02,  2.0759e-02],\n",
      "          [-4.2275e-02,  2.9450e-02,  5.1500e-02,  ..., -2.0236e-02,\n",
      "            3.0712e-02, -3.0882e-02]],\n",
      "\n",
      "         [[-1.0407e-02, -1.8796e-04, -3.5839e-02,  ..., -4.4836e-02,\n",
      "           -5.1094e-02,  4.1658e-02],\n",
      "          [-9.6805e-03, -3.3629e-03, -1.2495e-02,  ...,  1.8973e-02,\n",
      "           -1.8636e-02,  1.4991e-02],\n",
      "          [-3.2043e-02,  3.2453e-02, -6.9082e-03,  ..., -4.1497e-02,\n",
      "            2.4233e-02, -3.0138e-02],\n",
      "          ...,\n",
      "          [-4.9942e-02, -8.5301e-03,  1.2927e-02,  ...,  1.8711e-02,\n",
      "            2.1382e-04, -5.3545e-03],\n",
      "          [-3.5630e-02,  1.2081e-02, -5.8351e-03,  ..., -1.8329e-02,\n",
      "            3.7200e-03, -4.6443e-02],\n",
      "          [ 2.3254e-02, -2.6155e-02, -9.7885e-04,  ...,  1.3418e-02,\n",
      "           -1.2320e-03, -2.3117e-02]]]])), ('convolution_block1.0.bias', tensor([-0.0022, -0.0501, -0.0244, -0.0006,  0.0337,  0.0395, -0.0295, -0.0063,\n",
      "         0.0023,  0.0163,  0.0455, -0.0387, -0.0459,  0.0342, -0.0018,  0.0340,\n",
      "         0.0268,  0.0416,  0.0511, -0.0023,  0.0068, -0.0182,  0.0160, -0.0420,\n",
      "         0.0069,  0.0351,  0.0523,  0.0383,  0.0172, -0.0354,  0.0475, -0.0469,\n",
      "         0.0174, -0.0406, -0.0252,  0.0195,  0.0062, -0.0125, -0.0512,  0.0085,\n",
      "        -0.0175,  0.0077,  0.0511, -0.0517,  0.0234, -0.0300,  0.0479,  0.0320,\n",
      "        -0.0250, -0.0508,  0.0191,  0.0339,  0.0335, -0.0147,  0.0418,  0.0308,\n",
      "        -0.0103,  0.0066,  0.0038, -0.0477,  0.0331,  0.0021,  0.0084, -0.0160,\n",
      "        -0.0403, -0.0036, -0.0236,  0.0149, -0.0163,  0.0085,  0.0083,  0.0168,\n",
      "        -0.0273,  0.0051,  0.0271, -0.0213, -0.0122, -0.0064,  0.0336,  0.0470,\n",
      "        -0.0471,  0.0423, -0.0328,  0.0186, -0.0162,  0.0462, -0.0146,  0.0251,\n",
      "        -0.0145, -0.0097, -0.0301, -0.0158, -0.0369,  0.0186,  0.0131, -0.0119])), ('convolution_block1.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])), ('convolution_block1.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block1.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block1.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])), ('convolution_block1.1.num_batches_tracked', tensor(0)), ('convolution_block2.0.weight', tensor([[[[-5.8995e-03,  1.7745e-02, -1.9796e-02, -2.2652e-03,  9.3750e-03],\n",
      "          [-1.4182e-02,  3.7334e-03,  1.0750e-03, -6.4236e-03,  8.6997e-03],\n",
      "          [ 2.4028e-04,  7.6632e-03, -8.0448e-06, -5.4244e-03,  5.1016e-03],\n",
      "          [-1.8367e-02, -1.1983e-02, -1.6459e-02, -1.5609e-02, -1.5472e-02],\n",
      "          [ 8.8549e-03, -1.9789e-02,  1.9675e-02, -1.8711e-02, -1.6233e-02]],\n",
      "\n",
      "         [[-1.4164e-03, -3.6966e-03,  1.0860e-02, -1.2462e-02, -2.6019e-03],\n",
      "          [-1.0838e-02, -8.0067e-03, -2.9248e-03, -1.7065e-02,  1.7375e-03],\n",
      "          [-1.5808e-02, -9.8772e-03,  1.2759e-03,  1.3149e-02,  1.7617e-02],\n",
      "          [-1.2575e-02, -2.2302e-03, -7.8082e-04,  7.4496e-03, -6.2777e-03],\n",
      "          [ 1.0063e-02, -1.6035e-02, -1.0709e-02,  1.9935e-02, -1.3604e-02]],\n",
      "\n",
      "         [[ 1.8640e-03,  1.9275e-02, -3.9567e-03, -1.9971e-02,  1.4328e-02],\n",
      "          [-2.0077e-02,  1.8231e-02, -4.4424e-03, -1.8627e-03,  1.0581e-02],\n",
      "          [ 5.5200e-03, -6.0716e-03, -1.2057e-02,  1.0257e-02, -1.1248e-03],\n",
      "          [-1.4542e-02,  1.1094e-03,  1.9810e-02, -5.1729e-03, -1.5775e-02],\n",
      "          [-1.1861e-02, -4.3879e-03,  1.2662e-02,  1.1355e-02, -1.0980e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6806e-02, -3.1319e-03, -4.1863e-03, -1.9255e-02, -1.3756e-03],\n",
      "          [-1.4081e-02, -7.5199e-03,  1.3240e-02,  1.3036e-02, -7.3949e-03],\n",
      "          [-1.8687e-03, -1.0189e-02, -1.0944e-02, -1.2858e-02,  2.5658e-03],\n",
      "          [ 6.3203e-03,  1.8773e-02, -1.5399e-02,  6.2749e-03, -1.3015e-02],\n",
      "          [-2.0181e-02, -4.5065e-03,  1.3628e-02, -1.7110e-02, -9.9677e-03]],\n",
      "\n",
      "         [[-1.9494e-02, -1.5763e-02,  7.3649e-03,  1.9730e-02, -1.4447e-02],\n",
      "          [-1.0520e-02, -1.6445e-02, -1.3193e-02,  1.1892e-02,  5.6310e-03],\n",
      "          [-1.7531e-02,  6.9183e-03, -1.2388e-02,  1.1569e-02,  4.1087e-03],\n",
      "          [ 1.9010e-02,  6.0469e-03,  3.0206e-03, -4.9678e-03, -4.0839e-03],\n",
      "          [-1.4938e-02, -5.7855e-03, -1.2081e-02,  1.9523e-02,  8.3871e-03]],\n",
      "\n",
      "         [[-3.6772e-03, -6.6036e-03,  1.2369e-02, -1.3572e-02, -9.5040e-03],\n",
      "          [ 1.3965e-02, -2.4534e-03, -1.1762e-02, -1.5221e-02, -1.7591e-03],\n",
      "          [-8.9433e-03,  8.7217e-03,  2.0324e-02,  1.9514e-02, -8.4541e-03],\n",
      "          [ 7.1042e-03,  2.5543e-03,  6.0259e-03, -1.3638e-03, -7.1131e-03],\n",
      "          [ 1.8064e-02, -2.0387e-02, -3.1880e-03, -1.3831e-03,  5.9020e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1909e-02, -1.8709e-02,  1.9646e-02,  6.6062e-03,  1.7525e-02],\n",
      "          [ 1.3142e-02, -3.1653e-03,  1.7269e-02,  6.0241e-03, -7.4494e-03],\n",
      "          [-3.9877e-03, -1.5547e-02,  1.3556e-02, -1.2045e-02, -1.0042e-02],\n",
      "          [-8.9786e-03, -6.3310e-03,  5.7733e-03, -1.6369e-04, -1.5710e-02],\n",
      "          [-5.0242e-03, -1.6227e-03, -1.9822e-02, -1.2120e-02,  1.3985e-02]],\n",
      "\n",
      "         [[ 1.7985e-02,  1.1942e-02,  7.2402e-03, -1.2305e-02,  6.0229e-03],\n",
      "          [ 1.4273e-02, -5.0404e-03, -1.1872e-02,  1.7889e-02,  5.9169e-03],\n",
      "          [ 1.5335e-02, -4.4606e-03,  3.5396e-03, -5.9891e-04, -5.8580e-03],\n",
      "          [ 1.0593e-02, -2.3924e-04,  2.0086e-02, -5.4705e-03, -1.5894e-02],\n",
      "          [ 7.9337e-04,  1.9043e-02,  1.8395e-02, -1.7536e-02,  8.7437e-03]],\n",
      "\n",
      "         [[ 1.2822e-02, -1.5525e-02,  8.8070e-03, -1.0134e-03, -5.0915e-03],\n",
      "          [ 1.2674e-02,  1.8487e-02,  1.2314e-02,  5.9325e-03, -4.8130e-03],\n",
      "          [ 6.6900e-03,  1.2895e-02, -8.1493e-03, -1.2435e-02, -1.0640e-02],\n",
      "          [-1.9969e-02,  1.0447e-02,  1.3474e-02,  1.8157e-02, -5.2353e-03],\n",
      "          [ 1.3128e-03,  1.2803e-02,  1.8711e-02,  7.6861e-03, -4.5138e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2436e-03, -2.0362e-02,  1.5415e-02, -1.3100e-02, -5.2410e-03],\n",
      "          [ 1.4843e-02, -2.6055e-03, -1.3991e-02, -5.3708e-03,  2.0701e-03],\n",
      "          [ 1.3246e-02,  1.7512e-03,  1.2432e-02, -9.8657e-03,  4.6197e-03],\n",
      "          [-1.9866e-02, -2.0388e-03,  1.1165e-03, -1.9690e-02, -1.6459e-02],\n",
      "          [-1.0208e-02,  3.8183e-03, -2.0168e-02, -1.1864e-02,  1.6335e-02]],\n",
      "\n",
      "         [[-5.1409e-04,  1.1032e-02, -1.7701e-02, -1.2002e-02,  1.0364e-02],\n",
      "          [-1.1449e-02,  2.4919e-03, -1.4988e-02,  4.4685e-03, -1.9256e-02],\n",
      "          [-2.8258e-03, -6.9311e-03, -1.6430e-02, -1.6494e-02,  9.2025e-03],\n",
      "          [-5.5916e-03,  5.4505e-03, -1.6334e-02, -1.4342e-02,  1.9899e-02],\n",
      "          [-1.8617e-02, -1.4223e-02, -7.5151e-03, -8.1097e-03,  1.9266e-02]],\n",
      "\n",
      "         [[-1.0174e-04,  1.5481e-02,  5.1964e-04, -7.3444e-03,  7.0825e-04],\n",
      "          [-8.8045e-03, -2.3867e-03, -8.3098e-03, -1.7678e-02,  1.4955e-03],\n",
      "          [ 1.7809e-02,  1.6814e-02, -1.6722e-02,  9.3907e-03,  1.7956e-02],\n",
      "          [-3.1868e-03, -5.8319e-03, -8.0927e-03,  1.4730e-02,  8.9055e-05],\n",
      "          [ 1.7018e-03, -1.7518e-03,  1.9022e-02, -1.0450e-02, -1.8028e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3355e-02,  1.1002e-02,  1.2326e-02, -1.1559e-02,  1.6860e-02],\n",
      "          [-4.9866e-03,  7.8455e-04, -1.2824e-02, -1.8730e-02,  1.3460e-03],\n",
      "          [ 4.4084e-03, -6.0096e-03,  1.5030e-02, -1.8891e-02, -1.6964e-02],\n",
      "          [ 8.1915e-03, -1.2900e-02, -1.2584e-02,  1.2521e-02, -8.1930e-03],\n",
      "          [-1.8283e-02, -2.0346e-02,  3.4578e-03,  1.9566e-02, -1.8860e-02]],\n",
      "\n",
      "         [[ 3.9546e-03,  1.8101e-02,  2.0160e-02, -1.9816e-02,  1.4549e-02],\n",
      "          [ 4.7582e-03,  3.2480e-03,  1.2075e-02, -8.9066e-03,  9.6088e-03],\n",
      "          [ 1.5106e-02,  1.5182e-02,  7.4033e-03,  1.8599e-02,  1.1547e-02],\n",
      "          [-1.9584e-02,  1.5184e-02,  1.7495e-02,  2.6038e-04, -1.9528e-02],\n",
      "          [-6.2579e-04,  2.6123e-04, -1.6104e-02, -3.1667e-03,  7.7984e-03]],\n",
      "\n",
      "         [[ 7.0366e-03, -1.0190e-02, -8.2857e-03,  1.6673e-02, -1.9154e-02],\n",
      "          [-8.7284e-03, -2.5879e-03, -1.5087e-02, -1.9768e-02, -7.2384e-03],\n",
      "          [ 4.3473e-03, -1.0030e-02, -7.3882e-04, -1.9900e-02,  1.0024e-02],\n",
      "          [-4.3478e-03,  1.4134e-02,  1.8555e-02, -1.3529e-02,  1.7305e-02],\n",
      "          [-1.8986e-02,  1.6776e-02, -1.9615e-02, -7.2653e-03, -8.4433e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2529e-02, -1.9538e-02,  9.0973e-03,  5.8400e-03,  1.1499e-03],\n",
      "          [ 5.3738e-03,  8.4906e-03, -1.6274e-02,  1.3106e-02, -7.2993e-03],\n",
      "          [ 1.1293e-02,  5.7663e-03,  1.3786e-02, -5.8515e-03,  5.4265e-03],\n",
      "          [ 1.9684e-02, -1.7327e-02,  1.5586e-02,  1.3043e-02, -1.7116e-02],\n",
      "          [ 9.9055e-03, -1.2362e-02,  5.8185e-03,  1.0694e-02, -1.0875e-02]],\n",
      "\n",
      "         [[-1.3498e-02, -1.4970e-02, -3.6822e-03,  1.2771e-02,  1.2538e-02],\n",
      "          [-1.6550e-02, -2.1130e-03, -2.0349e-02, -1.3060e-02,  3.1175e-03],\n",
      "          [-2.9388e-03,  1.2602e-02, -1.8544e-03, -3.7106e-03, -1.1963e-02],\n",
      "          [ 8.0320e-03,  6.8135e-03,  1.8355e-02,  1.0715e-02,  1.5293e-02],\n",
      "          [-2.0324e-02, -2.9933e-03, -5.3933e-03,  1.8923e-02, -1.3324e-02]],\n",
      "\n",
      "         [[-6.5560e-03, -1.5627e-03, -1.4113e-02, -1.1531e-02,  1.1201e-02],\n",
      "          [ 1.0521e-02,  1.4617e-02, -1.7406e-02,  1.3378e-02,  2.0111e-02],\n",
      "          [-7.8262e-03, -1.4344e-04,  9.0802e-03, -7.7776e-03,  1.5388e-02],\n",
      "          [-6.0835e-04, -1.1606e-02,  1.4698e-02,  1.0385e-02,  4.6988e-03],\n",
      "          [-1.6570e-02,  1.6385e-02, -1.3822e-02,  6.0122e-03, -1.6209e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.4080e-03, -1.9242e-02,  5.5104e-03,  7.2368e-03, -1.5162e-02],\n",
      "          [ 1.3573e-02,  3.2187e-03, -1.3980e-02, -2.3855e-03, -1.3528e-02],\n",
      "          [ 1.2372e-02, -4.2891e-03, -1.4552e-02,  1.2625e-02, -4.4941e-03],\n",
      "          [ 2.2809e-03,  8.1674e-03,  3.4777e-03,  1.3042e-02,  5.5880e-03],\n",
      "          [ 5.6630e-03, -1.2692e-02,  1.3838e-02, -8.7143e-03, -8.8568e-03]],\n",
      "\n",
      "         [[ 4.9347e-03, -4.8353e-03,  1.1585e-02, -1.9864e-02,  6.6470e-03],\n",
      "          [ 2.2358e-03, -4.5438e-03,  5.4793e-03,  2.8468e-03, -9.1214e-03],\n",
      "          [-1.3549e-02, -9.8790e-03,  9.1161e-03, -1.1488e-03, -4.9716e-03],\n",
      "          [-7.4777e-03,  4.3998e-04,  8.5009e-03,  1.1196e-02, -2.9522e-03],\n",
      "          [-5.9849e-03, -4.1624e-03,  1.5278e-02, -4.8690e-03,  1.0021e-02]],\n",
      "\n",
      "         [[-2.3270e-04, -1.0316e-04, -1.7801e-03,  6.6025e-03,  1.1554e-02],\n",
      "          [ 8.0358e-03, -6.7643e-03, -1.6490e-02,  3.3492e-03,  5.2036e-03],\n",
      "          [ 3.3870e-03, -4.0568e-03,  6.8782e-03,  1.0219e-02,  2.2755e-03],\n",
      "          [-3.5997e-03,  1.4839e-02, -1.9073e-04,  4.3718e-03, -1.8470e-02],\n",
      "          [-1.8376e-02,  9.8476e-04, -1.7269e-02,  1.6958e-02,  1.9118e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1181e-03, -1.2612e-02,  7.1404e-03,  2.5930e-03,  1.2767e-02],\n",
      "          [ 2.0883e-03,  1.6034e-02, -6.0970e-03, -1.0747e-02,  1.6493e-02],\n",
      "          [-1.3836e-02, -8.5384e-03, -1.8921e-02,  1.3431e-02, -9.4234e-03],\n",
      "          [-2.2046e-03, -1.8872e-02,  9.7135e-03, -1.8278e-02,  1.4052e-02],\n",
      "          [ 4.0035e-03, -1.0931e-02, -1.8662e-03, -1.6695e-02,  3.8640e-03]],\n",
      "\n",
      "         [[-7.9821e-03, -1.6043e-02,  7.4022e-03, -8.4009e-03, -2.3296e-03],\n",
      "          [ 2.6407e-03, -1.5057e-03, -1.4890e-02, -2.7992e-03,  4.7273e-03],\n",
      "          [ 4.2677e-03, -4.5911e-03,  1.1637e-02,  2.4023e-03, -1.5680e-02],\n",
      "          [-5.0387e-03, -1.5435e-02,  1.1760e-02, -6.4779e-03, -8.8147e-03],\n",
      "          [ 7.4220e-03, -9.3086e-03, -1.5569e-02,  1.4920e-02,  1.3315e-02]],\n",
      "\n",
      "         [[-7.2112e-03, -1.3019e-02,  1.1849e-02, -1.9238e-03,  5.8642e-03],\n",
      "          [-1.2577e-02, -6.0211e-03,  4.2457e-03, -6.2542e-03,  1.4634e-02],\n",
      "          [ 4.7152e-03, -1.2141e-02,  1.8222e-02,  1.2591e-02,  1.6027e-02],\n",
      "          [-3.6232e-03, -1.4385e-02,  7.1587e-03, -6.1405e-03,  1.8532e-04],\n",
      "          [ 1.3137e-02,  3.7763e-03, -1.9234e-02, -7.5259e-03, -6.1210e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0872e-02,  1.2053e-02,  8.4765e-03, -1.3961e-02, -9.7238e-03],\n",
      "          [-9.4850e-03,  6.8077e-03,  1.0415e-02, -1.1789e-02, -1.6791e-02],\n",
      "          [-6.6398e-03,  3.2381e-03, -1.5317e-02,  1.6559e-02,  5.2996e-03],\n",
      "          [-8.1488e-03, -1.9372e-02,  8.9775e-03,  1.8234e-02, -1.8024e-02],\n",
      "          [-1.8206e-02, -1.1851e-04, -3.3921e-03,  8.2859e-03, -1.7962e-02]],\n",
      "\n",
      "         [[ 1.8254e-02, -4.7722e-03, -2.4664e-03,  9.9810e-03,  1.5727e-02],\n",
      "          [ 1.5432e-02,  5.5998e-03,  6.9852e-03,  8.5130e-03, -3.6352e-03],\n",
      "          [ 4.5592e-03, -4.6485e-03, -1.4415e-02, -9.2690e-03,  1.8651e-02],\n",
      "          [-1.1404e-02, -1.3635e-02,  3.3887e-03,  1.9501e-02, -1.8404e-03],\n",
      "          [ 7.5751e-03,  1.1164e-02,  2.8559e-03, -2.4562e-03, -4.9438e-03]],\n",
      "\n",
      "         [[-1.7946e-02,  1.4003e-02,  9.1743e-03,  1.7430e-02, -1.6113e-02],\n",
      "          [ 8.1991e-03, -1.9222e-02,  5.7190e-03, -2.6328e-03, -5.8602e-03],\n",
      "          [-1.4940e-02,  2.0128e-03, -6.2704e-03,  1.6696e-03,  8.1231e-04],\n",
      "          [-8.8396e-03, -7.9445e-03, -4.3713e-03,  4.7693e-03,  1.4900e-02],\n",
      "          [ 3.1257e-03, -1.0825e-02, -4.1729e-03, -2.0074e-02, -1.4227e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.3734e-03, -9.4936e-04,  8.0803e-03, -1.9351e-02, -2.0043e-02],\n",
      "          [-1.8251e-02, -1.1507e-02,  1.9923e-02, -1.2263e-02,  1.5764e-02],\n",
      "          [ 1.0475e-02,  4.7749e-03, -1.7965e-02,  2.0176e-02,  1.7021e-03],\n",
      "          [ 7.6908e-04, -1.6699e-02,  2.0187e-02,  1.8288e-02,  3.1997e-03],\n",
      "          [-9.2322e-03, -1.4125e-02, -1.3476e-02, -1.3739e-02,  6.9260e-03]],\n",
      "\n",
      "         [[ 1.7368e-02, -9.5145e-03,  1.1197e-02, -9.0570e-03, -1.6689e-02],\n",
      "          [ 1.5901e-02, -1.9636e-02, -1.7404e-02, -5.9415e-03,  3.6865e-03],\n",
      "          [-1.9676e-02,  1.9905e-02,  1.1228e-02,  1.3430e-02,  5.0412e-03],\n",
      "          [-5.9080e-03,  1.9467e-02, -9.7720e-03,  5.5588e-03,  1.3923e-02],\n",
      "          [ 1.3734e-02,  1.9533e-02,  1.3206e-02, -1.2273e-02, -4.1665e-03]],\n",
      "\n",
      "         [[-8.8294e-03,  1.0717e-02, -1.0703e-02,  1.3817e-04,  1.6770e-03],\n",
      "          [ 5.9065e-03,  1.9838e-02, -2.5337e-03, -1.2864e-02,  6.5487e-03],\n",
      "          [ 1.7254e-02,  2.6363e-04, -1.3928e-02, -1.7087e-02,  1.9800e-03],\n",
      "          [ 1.8900e-02, -3.5718e-04, -1.4905e-02, -7.3262e-03,  1.3470e-02],\n",
      "          [-1.2431e-02, -1.4038e-02,  1.2093e-02,  1.8271e-02,  1.8159e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.6881e-03,  1.4773e-03,  1.4862e-02,  7.4443e-03,  3.1029e-04],\n",
      "          [ 1.2675e-02,  1.4728e-02, -5.1046e-03, -1.3209e-02, -1.1630e-02],\n",
      "          [-4.2451e-03, -7.2814e-03, -5.7888e-03, -7.8424e-03,  1.8080e-02],\n",
      "          [-4.6196e-03, -1.0048e-02, -1.5884e-02, -9.5661e-03, -6.1086e-03],\n",
      "          [ 2.0376e-02,  3.7576e-03,  3.1997e-04,  2.8164e-03,  1.6705e-02]],\n",
      "\n",
      "         [[ 1.0078e-02,  2.9675e-03,  1.9412e-02, -1.0118e-02,  8.5451e-03],\n",
      "          [ 8.4104e-03, -1.9949e-02, -2.1612e-03,  4.2157e-03, -5.1801e-03],\n",
      "          [-1.8659e-02, -1.2637e-02,  1.1453e-02,  1.9136e-02, -6.9436e-04],\n",
      "          [ 1.7033e-02,  1.3916e-03, -5.8627e-03, -6.0973e-04,  1.1487e-02],\n",
      "          [ 1.4396e-02, -1.5770e-02,  1.9792e-02, -9.6225e-03,  8.0253e-03]],\n",
      "\n",
      "         [[ 6.0806e-03,  2.0237e-02, -9.8385e-03, -5.3777e-03,  7.5123e-03],\n",
      "          [ 3.0658e-03, -3.1610e-03,  2.0045e-02,  4.6145e-03,  1.5077e-02],\n",
      "          [ 2.0057e-02,  5.6459e-03, -2.0408e-02, -1.4820e-03,  1.0754e-02],\n",
      "          [ 1.4065e-02,  1.8608e-02, -1.1108e-02,  5.6968e-03, -1.6223e-02],\n",
      "          [ 1.9993e-02, -8.2472e-03, -1.6916e-02, -1.4459e-02, -1.2958e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9970e-02,  2.6785e-03,  7.1593e-03,  3.5671e-03, -4.7479e-03],\n",
      "          [-1.4806e-02,  1.5361e-02,  6.4765e-03,  1.8843e-02, -5.9193e-04],\n",
      "          [ 1.4601e-02,  5.7580e-03, -5.7024e-03,  7.8857e-03,  1.7656e-02],\n",
      "          [-1.2009e-02,  3.1877e-03,  8.2864e-04, -9.6135e-03, -9.9339e-03],\n",
      "          [ 2.6712e-03,  1.4203e-02, -1.9321e-02, -1.4048e-04, -4.3774e-03]],\n",
      "\n",
      "         [[ 1.7013e-02, -6.1075e-03,  6.9135e-03, -1.3796e-02,  1.5797e-02],\n",
      "          [-1.1426e-02, -3.4639e-03, -1.5690e-02, -1.6082e-02,  3.7482e-03],\n",
      "          [-1.6082e-02,  1.5423e-03, -4.9139e-04, -1.7921e-02, -1.3174e-03],\n",
      "          [-9.4209e-03, -1.0730e-02, -5.3270e-04, -4.3056e-03, -1.5313e-02],\n",
      "          [ 4.2043e-03, -1.3969e-03, -2.1755e-03,  6.7962e-03,  1.2761e-03]],\n",
      "\n",
      "         [[-8.1513e-03, -6.2867e-03,  2.9517e-03, -1.4600e-02,  8.1129e-03],\n",
      "          [ 1.9518e-02, -2.0169e-02, -1.0607e-02, -1.8351e-02, -5.4701e-03],\n",
      "          [-3.2709e-03,  1.9773e-02, -1.0966e-02, -1.2478e-03, -9.7760e-03],\n",
      "          [-2.6841e-03, -1.8897e-02,  1.7336e-02, -6.9792e-03, -8.1589e-03],\n",
      "          [ 7.5486e-03,  1.2815e-02,  1.9195e-03,  1.2042e-02,  8.7613e-03]]]])), ('convolution_block2.0.bias', tensor([ 8.8955e-04, -1.4456e-02,  3.9421e-03,  1.2821e-02,  1.2758e-03,\n",
      "         1.3924e-02,  1.7049e-02,  8.6966e-03, -7.3557e-03,  2.0022e-02,\n",
      "         3.9092e-03,  2.7058e-03, -3.7768e-03,  1.2734e-02,  1.3817e-02,\n",
      "        -3.8824e-03, -3.0609e-05,  8.9185e-03,  2.0548e-03, -1.5666e-03,\n",
      "        -1.5545e-03,  7.9092e-03,  2.8099e-03, -4.3153e-03,  1.6773e-02,\n",
      "         8.6119e-03,  1.3304e-02,  6.5194e-04,  7.0035e-03, -7.0373e-03,\n",
      "        -1.9697e-02, -1.4998e-02, -4.9219e-03, -6.8519e-03,  3.7452e-03,\n",
      "         1.2304e-02, -2.9223e-03,  2.4555e-03,  4.5740e-03, -1.7208e-02,\n",
      "        -1.5441e-02,  7.4741e-03,  2.0062e-03, -1.3294e-03,  1.0236e-02,\n",
      "        -9.5122e-03, -2.4303e-03,  5.1304e-03,  5.0145e-03, -9.2241e-03,\n",
      "         1.0300e-02,  1.3373e-02, -5.9573e-03,  1.2461e-02, -1.8112e-02,\n",
      "        -1.4796e-02,  1.9266e-02,  5.8333e-04,  1.1066e-02, -1.7529e-02,\n",
      "        -8.6556e-03, -7.7966e-04,  1.6066e-02, -5.7473e-03,  1.8285e-02,\n",
      "         1.6021e-02,  3.6597e-03, -6.6692e-03, -1.6239e-02, -1.0838e-02,\n",
      "         8.2438e-03,  1.7809e-02,  1.0754e-02,  1.3928e-02, -1.2365e-02,\n",
      "        -1.4219e-02, -1.2918e-02,  6.2746e-03,  4.8596e-03, -1.3074e-02,\n",
      "        -1.7433e-02,  1.4660e-02, -5.4223e-03, -4.3283e-03, -1.0852e-02,\n",
      "        -3.8473e-03, -1.8820e-02,  7.3710e-03, -6.2975e-03,  1.3887e-04,\n",
      "        -1.5606e-02,  5.3856e-04,  1.8033e-02, -1.5560e-02, -4.3799e-03,\n",
      "        -2.4489e-04,  1.1844e-02, -2.3209e-03,  2.8124e-03,  1.4756e-02,\n",
      "        -1.3080e-02,  1.6076e-02, -1.5888e-02, -1.3571e-02,  1.1614e-02,\n",
      "        -1.4617e-03, -9.8419e-03,  1.9497e-02,  3.4204e-03, -6.2195e-03,\n",
      "        -1.1703e-02,  1.0771e-02,  1.4216e-03,  6.0009e-03, -3.1646e-03,\n",
      "         1.8983e-02,  6.6929e-03, -8.0613e-03,  5.6944e-03,  4.2585e-03,\n",
      "         1.3377e-02, -1.1292e-02, -1.2086e-02,  1.2654e-02, -9.9007e-03,\n",
      "         9.5526e-03, -1.8746e-02,  1.0536e-02,  1.2263e-02, -7.8876e-03,\n",
      "         1.9059e-02, -6.3496e-03, -1.2008e-02,  1.9046e-02, -3.6897e-05,\n",
      "         2.0139e-02,  1.2427e-02,  8.5057e-03,  6.7222e-03,  1.1114e-02,\n",
      "         6.6826e-03,  1.7330e-02, -1.0734e-02, -1.3204e-02,  1.4214e-02,\n",
      "        -1.7807e-02,  9.2199e-03,  1.3382e-02,  5.6162e-03,  6.2081e-03,\n",
      "         1.6186e-02, -3.9120e-03,  1.1701e-02,  1.0735e-02, -2.0750e-03,\n",
      "        -1.4694e-02, -1.6499e-02, -1.8410e-02,  6.5345e-03, -1.7716e-02,\n",
      "         1.6417e-02,  1.9761e-02, -5.2496e-03,  1.9269e-02, -9.9213e-03,\n",
      "        -1.9433e-02, -1.2302e-02,  1.8240e-04,  4.8017e-03, -1.5708e-02,\n",
      "        -1.0915e-02, -2.1730e-03, -1.4442e-02,  2.4600e-03,  1.8693e-02,\n",
      "         8.9330e-03,  9.5488e-03,  2.0383e-03,  1.0678e-02,  6.4511e-03,\n",
      "        -1.9125e-02, -1.5487e-02,  5.4909e-03,  1.1385e-02,  5.2281e-03,\n",
      "        -1.5892e-02, -4.0563e-03,  1.3436e-02,  1.0737e-02,  1.2581e-02,\n",
      "        -2.0166e-02, -3.9734e-03,  1.3707e-02, -8.8710e-03, -1.0715e-02,\n",
      "         1.8350e-02, -1.8595e-02,  5.9212e-03,  1.1589e-02,  9.0329e-03,\n",
      "        -1.8007e-02,  5.2651e-03, -1.9026e-02, -3.0845e-03,  1.3567e-02,\n",
      "         2.0012e-02,  1.7052e-02, -2.0340e-02, -1.2351e-02, -3.9505e-03,\n",
      "         1.0906e-02,  3.5869e-03, -1.4475e-02, -1.4737e-02,  1.0959e-02,\n",
      "         8.9516e-03, -1.9685e-02,  2.1335e-03,  7.9417e-03, -6.0656e-03,\n",
      "        -4.7727e-03, -1.6045e-02,  1.3300e-02, -4.2907e-03,  6.6969e-03,\n",
      "        -1.4035e-02, -1.5377e-02,  1.1892e-02,  2.6345e-03,  1.3041e-02,\n",
      "        -6.9051e-03,  8.0080e-03,  1.0866e-02, -8.3195e-03,  4.3661e-03,\n",
      "         1.3101e-02, -9.5563e-04, -3.4556e-03,  1.9888e-02,  1.9421e-02,\n",
      "        -2.9061e-03, -1.8067e-03, -1.1733e-02, -2.5959e-03, -1.7671e-02,\n",
      "        -1.6414e-02,  1.3504e-02,  1.4824e-02, -1.0751e-02, -7.3022e-03,\n",
      "         1.9139e-02, -5.0249e-03,  8.4615e-03,  1.8445e-02,  1.3340e-02,\n",
      "        -1.3790e-02])), ('convolution_block2.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])), ('convolution_block2.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block2.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block2.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])), ('convolution_block2.1.num_batches_tracked', tensor(0)), ('convolution_block3.0.weight', tensor([[[[ 0.0018, -0.0034, -0.0202],\n",
      "          [-0.0166,  0.0152, -0.0103],\n",
      "          [ 0.0177,  0.0171, -0.0022]],\n",
      "\n",
      "         [[ 0.0079, -0.0141, -0.0059],\n",
      "          [-0.0007, -0.0183, -0.0115],\n",
      "          [-0.0159, -0.0151,  0.0063]],\n",
      "\n",
      "         [[ 0.0129,  0.0132,  0.0179],\n",
      "          [ 0.0054,  0.0027, -0.0085],\n",
      "          [-0.0126, -0.0064, -0.0061]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0091,  0.0029, -0.0132],\n",
      "          [-0.0166,  0.0162, -0.0102],\n",
      "          [-0.0007,  0.0143,  0.0111]],\n",
      "\n",
      "         [[ 0.0163,  0.0188, -0.0126],\n",
      "          [-0.0131, -0.0142,  0.0154],\n",
      "          [ 0.0015, -0.0145, -0.0088]],\n",
      "\n",
      "         [[-0.0101,  0.0079,  0.0107],\n",
      "          [ 0.0142, -0.0048, -0.0041],\n",
      "          [ 0.0009, -0.0010,  0.0043]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0038,  0.0133,  0.0072],\n",
      "          [-0.0076, -0.0116,  0.0159],\n",
      "          [ 0.0014, -0.0039, -0.0049]],\n",
      "\n",
      "         [[-0.0170, -0.0011, -0.0081],\n",
      "          [ 0.0155,  0.0098,  0.0060],\n",
      "          [ 0.0048, -0.0092, -0.0116]],\n",
      "\n",
      "         [[-0.0147, -0.0028, -0.0133],\n",
      "          [ 0.0023, -0.0156,  0.0200],\n",
      "          [ 0.0101,  0.0131, -0.0205]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0008,  0.0017, -0.0149],\n",
      "          [-0.0130,  0.0137,  0.0208],\n",
      "          [ 0.0139,  0.0131, -0.0053]],\n",
      "\n",
      "         [[-0.0159,  0.0062,  0.0145],\n",
      "          [-0.0073,  0.0142, -0.0033],\n",
      "          [-0.0011, -0.0041,  0.0192]],\n",
      "\n",
      "         [[ 0.0087,  0.0061, -0.0188],\n",
      "          [ 0.0092,  0.0096, -0.0075],\n",
      "          [ 0.0099,  0.0166,  0.0123]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0130,  0.0091,  0.0163],\n",
      "          [-0.0070, -0.0063, -0.0015],\n",
      "          [ 0.0065, -0.0152,  0.0034]],\n",
      "\n",
      "         [[-0.0099,  0.0042, -0.0031],\n",
      "          [ 0.0072,  0.0038,  0.0099],\n",
      "          [ 0.0194, -0.0113, -0.0009]],\n",
      "\n",
      "         [[-0.0017, -0.0165, -0.0094],\n",
      "          [-0.0021,  0.0023, -0.0090],\n",
      "          [-0.0056, -0.0068, -0.0157]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0158,  0.0116,  0.0125],\n",
      "          [ 0.0176,  0.0096,  0.0157],\n",
      "          [-0.0182,  0.0013,  0.0137]],\n",
      "\n",
      "         [[ 0.0111, -0.0005, -0.0170],\n",
      "          [ 0.0201, -0.0191,  0.0136],\n",
      "          [ 0.0117, -0.0043,  0.0142]],\n",
      "\n",
      "         [[ 0.0170,  0.0065,  0.0147],\n",
      "          [-0.0038, -0.0093,  0.0123],\n",
      "          [ 0.0033, -0.0098, -0.0116]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0084, -0.0004, -0.0169],\n",
      "          [-0.0132,  0.0118, -0.0170],\n",
      "          [-0.0068,  0.0206, -0.0176]],\n",
      "\n",
      "         [[-0.0133,  0.0194,  0.0068],\n",
      "          [-0.0083,  0.0197,  0.0144],\n",
      "          [-0.0024,  0.0180,  0.0195]],\n",
      "\n",
      "         [[-0.0074, -0.0001,  0.0160],\n",
      "          [ 0.0109, -0.0176, -0.0156],\n",
      "          [ 0.0070,  0.0018,  0.0056]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0016,  0.0124, -0.0152],\n",
      "          [-0.0001,  0.0146,  0.0052],\n",
      "          [-0.0175,  0.0033, -0.0011]],\n",
      "\n",
      "         [[ 0.0155, -0.0023, -0.0050],\n",
      "          [ 0.0002, -0.0068, -0.0162],\n",
      "          [-0.0023,  0.0059,  0.0153]],\n",
      "\n",
      "         [[-0.0100, -0.0024,  0.0066],\n",
      "          [-0.0044, -0.0003,  0.0007],\n",
      "          [ 0.0076,  0.0089,  0.0190]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0204,  0.0140,  0.0023],\n",
      "          [-0.0077, -0.0175, -0.0120],\n",
      "          [-0.0120, -0.0172,  0.0058]],\n",
      "\n",
      "         [[-0.0203, -0.0119,  0.0100],\n",
      "          [ 0.0202, -0.0081,  0.0176],\n",
      "          [ 0.0154,  0.0150, -0.0140]],\n",
      "\n",
      "         [[ 0.0169, -0.0133, -0.0017],\n",
      "          [-0.0017, -0.0137,  0.0152],\n",
      "          [-0.0082,  0.0139, -0.0081]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0190,  0.0148,  0.0005],\n",
      "          [-0.0054, -0.0085, -0.0116],\n",
      "          [-0.0164,  0.0205,  0.0048]],\n",
      "\n",
      "         [[-0.0176, -0.0139, -0.0095],\n",
      "          [ 0.0185, -0.0124,  0.0115],\n",
      "          [ 0.0064, -0.0036, -0.0146]],\n",
      "\n",
      "         [[ 0.0166,  0.0136,  0.0125],\n",
      "          [-0.0016, -0.0122,  0.0090],\n",
      "          [-0.0086, -0.0145, -0.0093]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0155,  0.0079,  0.0012],\n",
      "          [ 0.0114, -0.0051, -0.0088],\n",
      "          [-0.0053, -0.0011,  0.0132]],\n",
      "\n",
      "         [[ 0.0046,  0.0188, -0.0046],\n",
      "          [ 0.0046, -0.0149, -0.0115],\n",
      "          [ 0.0046, -0.0194,  0.0091]],\n",
      "\n",
      "         [[ 0.0167, -0.0199,  0.0205],\n",
      "          [-0.0138, -0.0206,  0.0048],\n",
      "          [-0.0097, -0.0187, -0.0039]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0025, -0.0084, -0.0195],\n",
      "          [-0.0122, -0.0044,  0.0070],\n",
      "          [ 0.0015, -0.0053,  0.0114]],\n",
      "\n",
      "         [[-0.0204,  0.0071, -0.0153],\n",
      "          [-0.0010, -0.0004,  0.0061],\n",
      "          [ 0.0042, -0.0031, -0.0120]],\n",
      "\n",
      "         [[-0.0101,  0.0198,  0.0078],\n",
      "          [-0.0039,  0.0010, -0.0126],\n",
      "          [ 0.0001,  0.0021,  0.0021]]]])), ('convolution_block3.0.bias', tensor([ 5.0024e-03,  8.2690e-03, -1.8834e-02, -1.6108e-02, -3.0191e-03,\n",
      "        -3.5677e-03, -8.5608e-03, -1.7142e-02, -2.4423e-03,  1.4625e-02,\n",
      "         5.7014e-03, -1.9536e-02,  1.7143e-02, -1.6199e-02,  2.9277e-03,\n",
      "        -4.6128e-03, -1.9783e-02, -1.4200e-02, -6.9831e-03, -1.3220e-03,\n",
      "         1.6237e-02,  1.0855e-02, -9.5636e-03,  2.7862e-03, -1.0397e-02,\n",
      "         9.8325e-03,  1.2928e-02,  1.9052e-02, -2.6508e-03,  7.1071e-03,\n",
      "        -1.8614e-02, -1.0314e-02,  1.0940e-02,  1.5528e-02, -1.0612e-02,\n",
      "         1.5982e-03, -2.7797e-03, -1.0055e-02,  1.2730e-02,  8.0319e-03,\n",
      "        -2.9756e-03,  5.5260e-03, -1.5401e-03, -1.3407e-02,  5.9892e-03,\n",
      "        -7.5208e-03,  1.3748e-02,  1.9468e-02, -1.2208e-03, -3.6379e-03,\n",
      "         1.4232e-02,  5.6619e-03, -2.2807e-03,  1.5021e-02, -2.3292e-03,\n",
      "        -1.5997e-02,  6.4292e-03, -1.2557e-02, -1.1311e-02, -7.1666e-03,\n",
      "         6.2747e-03, -1.2117e-02, -1.4563e-02, -2.0228e-02,  1.8198e-02,\n",
      "         1.9502e-02, -6.1074e-03, -3.0401e-03,  9.1146e-03,  1.9726e-03,\n",
      "        -1.8536e-02,  3.4673e-03, -1.8594e-02,  3.0935e-03,  1.4063e-02,\n",
      "        -2.1775e-03, -1.0848e-02,  1.3282e-02,  4.9568e-03,  7.9298e-03,\n",
      "        -3.3097e-03,  2.4841e-03,  8.0370e-03, -3.1157e-03, -2.9557e-03,\n",
      "         1.6598e-02, -1.8541e-02,  1.8998e-02, -1.6608e-02,  2.0817e-02,\n",
      "         1.7267e-02,  4.8153e-03, -1.0032e-02, -8.2636e-03, -1.2683e-02,\n",
      "         1.6130e-03, -1.6552e-02, -1.4056e-02, -6.1969e-03,  1.3999e-02,\n",
      "         1.5895e-02, -1.6268e-02, -6.8995e-03, -1.5974e-02, -1.7479e-02,\n",
      "         7.2948e-03,  8.6613e-03, -1.7423e-02, -2.1328e-03, -2.0218e-02,\n",
      "         4.8310e-03, -1.1258e-02,  5.2139e-03,  1.0914e-02,  4.6992e-03,\n",
      "         1.0094e-02,  1.2774e-03,  4.9985e-03, -1.9267e-02, -2.0732e-02,\n",
      "         4.8621e-03,  1.4156e-02, -1.4521e-02, -7.2028e-03, -1.5749e-02,\n",
      "         1.1134e-03,  1.2138e-02, -3.4037e-03,  1.3919e-02, -7.4191e-03,\n",
      "        -1.4787e-02, -7.3658e-03,  8.0264e-03,  1.9216e-02,  1.0863e-02,\n",
      "         1.5437e-02,  9.1660e-03, -1.5646e-02, -7.7491e-03, -8.6198e-03,\n",
      "        -7.1765e-03, -1.9429e-02,  1.2575e-02,  1.2844e-02,  2.5011e-03,\n",
      "        -2.0507e-02, -1.0357e-02,  1.8752e-02, -3.2251e-03,  1.4030e-02,\n",
      "        -1.2364e-02, -1.0340e-02, -1.4289e-02,  1.5223e-02,  1.6282e-02,\n",
      "        -7.6280e-03,  1.5644e-02, -1.9488e-02, -1.8865e-02,  1.9901e-02,\n",
      "         1.9490e-02, -8.3677e-03,  4.9956e-03, -1.8572e-02, -1.2053e-03,\n",
      "        -5.0031e-03,  1.3595e-02, -1.6454e-02,  1.1700e-02, -3.0607e-03,\n",
      "        -1.6316e-02, -1.5347e-02,  7.2444e-03, -1.4600e-02, -1.6914e-02,\n",
      "        -7.0318e-03,  1.6238e-02, -9.7075e-03, -1.5131e-02,  8.9005e-03,\n",
      "         1.0331e-04,  1.6331e-02,  1.8836e-02,  1.8471e-02,  1.5492e-02,\n",
      "         1.4209e-02,  2.0506e-02,  1.5846e-03, -3.6368e-03, -8.1530e-03,\n",
      "         6.2869e-03,  1.8924e-02,  1.0068e-02, -2.0068e-02, -4.5707e-03,\n",
      "         1.1560e-03, -7.9203e-03,  1.2802e-02,  8.2692e-03,  9.0286e-03,\n",
      "         7.9084e-03, -1.5702e-02, -1.8635e-02, -1.3254e-02,  5.6844e-03,\n",
      "        -1.3457e-02,  1.5285e-02,  1.2472e-02, -3.3306e-04, -1.5113e-04,\n",
      "         2.6680e-03, -1.6729e-02,  4.4886e-03, -1.1012e-03, -4.3123e-03,\n",
      "        -7.4197e-03,  1.8064e-02, -1.3971e-02, -1.5820e-02,  6.5635e-03,\n",
      "         2.7709e-03, -3.6571e-03, -1.8228e-02, -1.9825e-02,  2.8703e-03,\n",
      "        -8.5367e-03,  1.8127e-02,  1.0734e-02, -1.1488e-02,  2.2191e-03,\n",
      "        -2.0156e-03, -2.7502e-03,  1.5687e-02, -3.3874e-03, -1.1326e-02,\n",
      "         6.6108e-03, -1.6736e-02,  2.6114e-03, -1.8758e-02, -5.6533e-03,\n",
      "         1.7219e-02,  9.1644e-03, -1.5282e-02, -3.2606e-03, -1.6007e-02,\n",
      "         2.0355e-02,  2.2866e-03,  7.2550e-03, -3.9082e-03, -1.3813e-02,\n",
      "        -1.5625e-03, -1.0623e-02, -1.1590e-02, -6.0799e-03, -6.7886e-03,\n",
      "        -1.4053e-02, -1.3170e-03, -7.0226e-03, -1.3935e-03, -4.2432e-03,\n",
      "         1.8792e-02,  9.7339e-03,  1.3429e-02, -7.6262e-05,  2.0267e-02,\n",
      "        -1.0856e-03,  1.0247e-02, -8.0761e-03, -1.3962e-02, -4.1715e-03,\n",
      "        -2.0024e-02, -5.6534e-03,  3.9912e-03,  1.7039e-02, -1.5189e-02,\n",
      "        -6.8155e-03, -3.1041e-03,  1.7763e-02, -3.7929e-03, -6.3050e-03,\n",
      "        -9.7143e-03, -1.3603e-02, -1.0267e-02,  1.1886e-02,  1.8694e-02,\n",
      "         1.4418e-02,  1.9523e-02, -5.5516e-03,  5.4430e-03,  3.3731e-03,\n",
      "        -9.3907e-03, -4.1763e-04,  1.0880e-02,  7.5125e-03,  8.8459e-03,\n",
      "        -3.9886e-03,  8.3176e-03,  1.9668e-02, -1.4011e-02,  1.5598e-02,\n",
      "         1.2811e-02,  2.5629e-03, -9.9077e-04,  1.9079e-02, -7.1599e-03,\n",
      "        -1.1152e-02,  2.9889e-03, -4.1965e-03, -1.0994e-02, -1.5778e-02,\n",
      "        -1.6338e-02, -1.2647e-02,  1.7342e-02, -7.7990e-03,  2.0094e-02,\n",
      "         9.6843e-03, -7.0623e-03, -3.0009e-04, -2.0623e-02,  6.1753e-04,\n",
      "         2.0836e-04, -6.6196e-03, -1.7166e-02, -1.4865e-02,  7.0278e-03,\n",
      "        -9.1643e-03,  7.8363e-03,  1.2265e-02,  1.5027e-02,  3.2186e-03,\n",
      "         5.7776e-03,  1.7297e-02, -7.3991e-04, -8.0151e-03,  5.6317e-03,\n",
      "        -6.7692e-03, -8.2989e-03,  9.1604e-03, -1.4178e-02, -1.7516e-02,\n",
      "        -5.1872e-03, -1.5230e-02, -6.4651e-03,  6.2862e-03, -1.8750e-02,\n",
      "        -6.1453e-03, -1.8785e-02, -3.2276e-03,  1.9423e-02, -9.9596e-03,\n",
      "         4.6812e-03,  1.1334e-02,  1.0961e-02, -6.2260e-03,  4.2775e-03,\n",
      "        -1.8764e-02,  1.8959e-02, -8.7451e-03, -9.1195e-03, -1.5304e-02,\n",
      "         1.8746e-03, -4.3291e-03, -1.3945e-02,  1.8016e-02,  1.4425e-02,\n",
      "         1.9829e-02,  9.7906e-04, -6.7991e-03,  9.1947e-03,  8.5244e-03,\n",
      "        -4.7528e-03,  8.6767e-03,  7.2518e-03, -1.5893e-02,  1.7251e-02,\n",
      "        -1.7618e-02,  7.9538e-03,  5.5920e-03,  6.6329e-03,  1.5656e-02,\n",
      "         2.3680e-03,  8.9613e-03, -1.0382e-02, -2.8440e-03])), ('convolution_block3.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])), ('convolution_block3.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block3.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block3.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])), ('convolution_block3.1.num_batches_tracked', tensor(0)), ('convolution_block4.0.weight', tensor([[[[ 1.3298e-02, -1.2481e-02, -2.3400e-03],\n",
      "          [ 9.0692e-03,  4.2457e-03,  1.2696e-03],\n",
      "          [-8.7206e-03, -1.3582e-02, -1.2700e-02]],\n",
      "\n",
      "         [[ 7.4791e-04, -1.4823e-02, -1.6442e-02],\n",
      "          [-5.7422e-03, -6.0295e-03, -5.4686e-03],\n",
      "          [ 1.2464e-02,  1.1525e-02, -9.9022e-03]],\n",
      "\n",
      "         [[ 1.4862e-02, -3.3105e-03,  1.3042e-02],\n",
      "          [ 1.6845e-02,  5.5602e-03,  1.6749e-02],\n",
      "          [ 7.2909e-03,  3.6013e-03, -1.3702e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3167e-02, -1.3783e-02,  3.9527e-04],\n",
      "          [ 4.0736e-03,  3.4141e-03,  6.1272e-03],\n",
      "          [-3.3785e-03,  6.0884e-03,  1.5362e-02]],\n",
      "\n",
      "         [[-2.2568e-03,  6.8913e-03, -1.2043e-02],\n",
      "          [ 5.3037e-03, -3.6221e-03, -2.1637e-04],\n",
      "          [ 1.2059e-02,  1.1353e-02, -6.8030e-03]],\n",
      "\n",
      "         [[ 1.2005e-02,  1.2849e-02, -4.7192e-03],\n",
      "          [-3.4771e-03,  7.4634e-03, -1.5599e-02],\n",
      "          [-1.6371e-02, -1.4211e-02, -1.0289e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5719e-02, -1.2165e-02, -1.1640e-02],\n",
      "          [ 1.5465e-02,  4.2665e-03,  7.2987e-03],\n",
      "          [ 9.7468e-03,  1.0646e-03, -1.1011e-02]],\n",
      "\n",
      "         [[ 1.5361e-02,  5.6135e-03,  8.1236e-03],\n",
      "          [ 1.5658e-02,  7.3387e-03, -8.2778e-03],\n",
      "          [-1.1617e-02,  8.5706e-03, -1.1401e-02]],\n",
      "\n",
      "         [[ 5.2494e-03,  1.1489e-02, -1.2981e-02],\n",
      "          [-5.8050e-03,  5.3958e-03,  6.7612e-03],\n",
      "          [-1.3380e-02, -1.3978e-03,  9.9544e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.3153e-04,  1.1507e-03,  9.0375e-03],\n",
      "          [-1.5870e-02,  8.5756e-03,  5.2716e-04],\n",
      "          [ 1.2499e-02, -1.6843e-02, -9.9216e-03]],\n",
      "\n",
      "         [[-1.1703e-02, -4.0569e-03,  2.8252e-03],\n",
      "          [ 9.2499e-03,  1.0339e-02, -1.6477e-02],\n",
      "          [ 7.5209e-03,  7.5858e-03, -5.6360e-03]],\n",
      "\n",
      "         [[-2.7529e-03,  1.5664e-02, -1.4114e-02],\n",
      "          [-2.3602e-03, -1.7600e-03,  3.7205e-03],\n",
      "          [ 1.6270e-02,  1.6405e-02, -1.0773e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5517e-02,  1.4034e-02,  2.2193e-03],\n",
      "          [-5.8323e-03,  1.3428e-02,  2.1111e-03],\n",
      "          [ 2.3558e-03, -4.0852e-03,  2.2376e-03]],\n",
      "\n",
      "         [[-6.8639e-04, -8.4020e-03,  1.0264e-03],\n",
      "          [-1.5866e-02, -2.9862e-03,  5.9157e-03],\n",
      "          [ 1.1751e-02,  7.3461e-03, -5.8535e-03]],\n",
      "\n",
      "         [[ 1.1086e-02,  4.1166e-03, -1.1296e-03],\n",
      "          [ 7.8595e-03, -2.0272e-03, -1.6881e-02],\n",
      "          [ 8.1440e-03, -1.6576e-02,  1.5346e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0506e-02, -5.7265e-03,  6.0176e-03],\n",
      "          [-3.8477e-04, -2.4228e-03,  1.6946e-02],\n",
      "          [-1.5968e-02, -1.2872e-02,  1.1882e-02]],\n",
      "\n",
      "         [[ 6.2250e-03, -4.3644e-03,  1.3707e-02],\n",
      "          [ 1.1833e-02, -1.5348e-02, -1.9151e-03],\n",
      "          [-1.6978e-02, -1.7402e-03, -2.6197e-03]],\n",
      "\n",
      "         [[-4.7611e-04,  1.4130e-03,  1.4269e-02],\n",
      "          [ 1.5377e-02,  1.7783e-03, -6.7519e-03],\n",
      "          [-1.5353e-03,  1.6121e-03, -1.5325e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.9940e-03, -3.5479e-03, -1.6168e-02],\n",
      "          [ 1.1118e-02,  4.0299e-03, -8.9410e-03],\n",
      "          [-8.9616e-03, -1.2343e-02,  2.6332e-05]],\n",
      "\n",
      "         [[ 5.1509e-03, -1.4964e-02,  4.4971e-03],\n",
      "          [ 1.2902e-02, -1.2082e-02,  1.2348e-02],\n",
      "          [-6.0553e-04, -1.3683e-02, -1.6969e-02]],\n",
      "\n",
      "         [[-3.1370e-03,  1.4263e-02,  1.6763e-03],\n",
      "          [-6.3172e-03, -2.0262e-03, -1.6322e-02],\n",
      "          [ 7.9113e-03, -5.9621e-03, -9.0020e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.4589e-03, -1.1662e-02, -9.7715e-03],\n",
      "          [ 1.2710e-03,  6.9020e-03, -1.5001e-03],\n",
      "          [-7.2053e-04,  1.0470e-02,  6.1551e-03]],\n",
      "\n",
      "         [[ 1.0855e-02,  6.7920e-03, -1.6585e-02],\n",
      "          [-1.2059e-02, -1.1914e-02,  1.3153e-02],\n",
      "          [-1.2550e-02,  1.6696e-02, -6.5388e-03]],\n",
      "\n",
      "         [[ 1.5985e-02, -6.1671e-03, -1.0209e-02],\n",
      "          [-4.5943e-03, -9.9781e-03,  9.4783e-03],\n",
      "          [-9.0642e-03, -1.3854e-02, -8.8726e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4564e-03, -5.1345e-03, -1.4723e-02],\n",
      "          [-1.2440e-02,  2.2951e-03,  4.2500e-03],\n",
      "          [-2.0907e-03, -4.1128e-03, -8.4409e-03]],\n",
      "\n",
      "         [[ 1.1987e-02, -8.9483e-03,  7.0753e-03],\n",
      "          [-1.3379e-02, -7.6883e-04,  5.0518e-03],\n",
      "          [-4.9047e-03, -1.4598e-02,  1.2524e-02]],\n",
      "\n",
      "         [[ 8.4604e-03, -4.7130e-03,  1.6081e-02],\n",
      "          [-6.3982e-03, -5.2592e-03,  7.3313e-03],\n",
      "          [ 1.6666e-02, -1.2910e-03, -1.1510e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.1346e-04,  1.5430e-02, -9.1687e-03],\n",
      "          [-1.6182e-02,  1.0438e-02,  1.5732e-02],\n",
      "          [-5.8296e-03, -6.9416e-03, -8.4835e-03]],\n",
      "\n",
      "         [[ 2.9768e-04,  1.4227e-02, -1.3520e-02],\n",
      "          [ 1.4829e-03,  1.2077e-02, -1.0608e-02],\n",
      "          [-1.4169e-02,  9.7824e-04, -1.4246e-03]],\n",
      "\n",
      "         [[-9.7004e-03,  1.3851e-02,  1.2616e-02],\n",
      "          [ 1.2586e-02,  1.3485e-02, -3.3347e-03],\n",
      "          [ 1.5650e-02,  1.2408e-02, -1.3431e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1973e-02,  1.3445e-02, -8.6873e-03],\n",
      "          [ 1.6528e-02, -1.2908e-02, -2.1038e-03],\n",
      "          [-9.0850e-03, -7.2952e-03, -1.6956e-02]],\n",
      "\n",
      "         [[ 7.5698e-03, -5.2069e-03,  1.1625e-02],\n",
      "          [-4.4122e-03, -4.2090e-03,  6.6386e-03],\n",
      "          [ 4.6371e-03, -1.5254e-02,  8.8173e-04]],\n",
      "\n",
      "         [[-2.1261e-03,  2.9086e-03, -1.4232e-02],\n",
      "          [-1.4546e-02, -3.4932e-03, -1.6256e-03],\n",
      "          [-1.4374e-02,  9.2813e-03,  9.0241e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2485e-02,  1.6053e-02,  8.0390e-03],\n",
      "          [ 1.9139e-03,  3.4795e-03, -9.0749e-03],\n",
      "          [ 8.2556e-03,  9.5903e-03,  5.3395e-03]],\n",
      "\n",
      "         [[-7.3122e-03,  1.2805e-02, -4.2311e-03],\n",
      "          [ 1.0466e-02, -1.0281e-02,  1.5432e-02],\n",
      "          [-9.8626e-03,  1.0307e-02, -2.4395e-03]],\n",
      "\n",
      "         [[ 9.4666e-03, -5.5219e-03, -9.5108e-03],\n",
      "          [ 9.9401e-03,  1.7476e-03,  1.3421e-02],\n",
      "          [ 1.2343e-02, -6.9763e-03,  8.5954e-04]]]])), ('convolution_block4.0.bias', tensor([ 1.0481e-02,  1.3055e-02, -6.4566e-03,  9.1067e-03, -9.7082e-03,\n",
      "        -1.4153e-02,  5.7813e-03,  7.5341e-03,  9.2516e-03,  1.4808e-02,\n",
      "         5.2356e-03,  1.5227e-02, -1.5798e-02,  1.1200e-02,  6.2540e-03,\n",
      "         2.7174e-03,  9.6005e-03,  3.6615e-03,  4.2706e-03, -1.5744e-02,\n",
      "         1.4504e-02, -1.6049e-02,  1.6586e-02, -3.1656e-03,  5.4879e-03,\n",
      "        -1.0272e-02, -6.2138e-03, -1.0230e-03, -2.3524e-03,  1.0355e-02,\n",
      "        -8.5588e-03,  1.0462e-02, -9.6542e-04,  5.4085e-03,  1.5181e-02,\n",
      "         7.6006e-03, -1.2292e-02, -9.6991e-04,  5.4202e-03,  9.4854e-04,\n",
      "        -6.5474e-03, -1.1841e-02, -1.2777e-02,  1.2724e-02,  1.4134e-02,\n",
      "         1.6404e-02,  1.3562e-02, -5.4467e-03, -5.4927e-03, -1.2042e-02,\n",
      "        -3.0995e-03, -1.3364e-02,  6.3110e-03,  1.5717e-02,  7.2987e-03,\n",
      "         1.3752e-03,  1.2479e-03, -3.5090e-03, -4.4145e-03,  1.2053e-02,\n",
      "         8.2537e-04,  1.3752e-02, -7.5462e-03, -8.8909e-03,  5.5990e-03,\n",
      "         6.5012e-03,  8.6535e-03,  2.8419e-03,  5.1272e-03,  3.5867e-03,\n",
      "        -2.2782e-03, -4.9200e-03,  4.0933e-03,  4.2731e-04, -1.5299e-02,\n",
      "         1.9056e-03, -1.2190e-02, -1.6801e-02,  5.5531e-03,  1.5995e-03,\n",
      "        -3.7939e-03, -1.4318e-02,  8.0818e-03, -1.2856e-02,  9.2027e-04,\n",
      "        -7.1284e-03, -1.3681e-03,  1.3687e-02,  5.6803e-03,  2.5650e-03,\n",
      "        -7.0611e-03, -7.7339e-03, -2.2363e-04,  6.7504e-04,  1.3964e-02,\n",
      "        -1.5229e-02, -6.0931e-03, -1.3047e-02,  4.6224e-03,  1.4379e-03,\n",
      "        -5.9196e-03, -1.0683e-02, -1.4158e-02,  1.1244e-02, -1.6979e-02,\n",
      "         7.2652e-03,  5.4312e-03,  3.9996e-03,  7.0225e-03,  8.8387e-03,\n",
      "        -1.3428e-02,  7.4364e-04,  1.0556e-02,  3.1549e-03,  5.6235e-03,\n",
      "        -1.8845e-04, -3.3438e-03, -2.7660e-03,  7.0616e-03,  1.0483e-02,\n",
      "         1.6742e-02,  1.4338e-02, -4.7013e-03,  1.4198e-02, -1.4068e-02,\n",
      "        -1.4030e-02,  1.3096e-03,  1.6674e-03, -5.1883e-03, -1.2421e-02,\n",
      "         1.6977e-03, -6.5443e-03, -6.8077e-03,  6.5279e-03, -6.9422e-03,\n",
      "         8.3781e-03,  4.1464e-03,  8.7979e-03, -9.5537e-05, -4.1667e-03,\n",
      "        -2.4056e-04,  2.6966e-03, -1.3734e-02,  1.6985e-02, -9.4699e-03,\n",
      "         3.6290e-03, -1.4788e-02, -3.4884e-03, -7.2958e-04, -1.1452e-02,\n",
      "        -1.5144e-02, -4.5350e-03,  1.4771e-02,  3.8342e-03,  1.1737e-03,\n",
      "         8.8293e-04,  8.4167e-03,  1.2730e-02,  3.5315e-03,  1.2672e-02,\n",
      "        -1.0638e-02,  1.5979e-02,  1.8146e-03, -2.1490e-03,  1.6711e-02,\n",
      "         1.4467e-02,  4.1248e-03,  1.4358e-02,  1.3611e-02, -1.4947e-02,\n",
      "        -1.4009e-02,  1.5401e-02,  1.6756e-03, -1.6685e-02,  1.2556e-02,\n",
      "        -3.2794e-03,  3.5235e-04, -1.4864e-02,  1.5291e-02,  4.0342e-03,\n",
      "        -9.7034e-04, -1.5978e-02, -6.0224e-03,  1.0170e-03,  1.6432e-02,\n",
      "         7.5147e-03,  1.3197e-02, -1.6866e-02,  6.8274e-03, -1.4007e-02,\n",
      "        -3.2886e-03,  1.4544e-02, -1.3811e-02, -1.6659e-02,  6.2204e-03,\n",
      "        -1.6288e-02, -1.6346e-02, -2.6988e-04, -1.1069e-02, -6.9381e-03,\n",
      "         8.2694e-04,  2.4630e-03, -7.9888e-03,  1.0279e-02, -1.5960e-02,\n",
      "        -1.9954e-03,  2.7353e-03, -1.6231e-02,  5.7262e-03, -1.5252e-02,\n",
      "         4.0605e-03, -9.0179e-03,  3.0216e-03,  7.9861e-03,  4.1274e-03,\n",
      "         1.6468e-02, -6.9705e-03,  1.1226e-02, -1.0330e-02, -4.6767e-03,\n",
      "         7.3000e-03,  1.3893e-02, -6.4175e-04,  5.7255e-03,  1.6379e-02,\n",
      "         1.0522e-02,  4.5005e-04, -1.4129e-02,  5.9370e-03, -5.7622e-03,\n",
      "        -1.5437e-03,  2.2328e-03, -5.7645e-03, -3.6837e-03, -1.4224e-02,\n",
      "         1.0646e-02,  5.5383e-03,  1.5866e-02, -2.2139e-03,  1.1603e-02,\n",
      "         4.2545e-03, -9.3069e-03, -9.6733e-03, -3.5331e-03,  1.4360e-03,\n",
      "         5.9734e-03,  1.3674e-02, -5.3158e-03,  3.0621e-03,  9.3053e-03,\n",
      "         1.1648e-02, -1.4216e-02, -2.1787e-03,  4.5467e-03,  9.9980e-03,\n",
      "        -4.8440e-03, -1.1510e-02,  1.0361e-02, -1.6142e-02,  8.8419e-04,\n",
      "         8.6607e-03, -1.2070e-02,  1.0370e-02, -6.9804e-04,  9.7067e-03,\n",
      "        -1.2360e-02,  1.5928e-02, -1.3852e-02,  1.2089e-02,  9.3015e-03,\n",
      "        -1.2837e-02, -8.5473e-03,  1.3927e-02,  7.5667e-03,  1.6778e-02,\n",
      "         1.1106e-03,  1.7357e-03, -7.2830e-03, -1.4982e-02, -1.2518e-02,\n",
      "        -6.7440e-03,  1.2104e-02, -1.2956e-02, -6.2108e-03, -7.4948e-03,\n",
      "         1.3375e-02,  5.5159e-04,  5.7802e-03,  4.3211e-03, -2.4756e-03,\n",
      "        -9.5100e-03,  5.5701e-03, -1.4216e-03, -1.1956e-02, -8.4622e-03,\n",
      "        -1.5385e-02,  3.5926e-03,  9.9284e-03,  1.1173e-02, -3.1958e-03,\n",
      "         1.4817e-02,  3.2869e-03,  1.6660e-02,  3.1594e-03,  1.9529e-03,\n",
      "         1.2318e-02, -1.3456e-02,  1.1829e-02,  8.7090e-04,  1.0062e-02,\n",
      "         5.2866e-03,  1.2323e-02,  1.6155e-03,  6.1239e-03, -6.2052e-03,\n",
      "         1.1039e-02, -4.4297e-03, -5.8487e-03,  4.6463e-03, -1.1803e-02,\n",
      "        -6.5883e-04, -4.9738e-03, -1.4110e-02, -1.6511e-02,  7.5640e-03,\n",
      "         1.6774e-02,  5.8934e-03,  1.2750e-02,  3.4836e-03,  9.6993e-03,\n",
      "        -7.6136e-03,  1.6331e-02, -7.6537e-03, -3.8982e-03, -1.1426e-03,\n",
      "        -1.9637e-03, -5.3016e-03,  1.4425e-02,  1.0831e-02,  6.5791e-03,\n",
      "         1.0481e-02, -9.5420e-03, -9.4418e-03, -1.3595e-02,  1.6995e-02,\n",
      "        -1.3376e-03, -2.1341e-03,  1.1407e-02, -1.3332e-02, -4.5163e-03,\n",
      "         3.3127e-03,  1.6823e-02, -4.4087e-03,  6.7545e-03, -6.7807e-03,\n",
      "        -1.5256e-02, -1.0494e-03, -5.9333e-03, -3.5824e-03, -4.7482e-03,\n",
      "        -1.1095e-02, -6.4167e-03,  1.6414e-02,  1.1205e-02, -1.1982e-02,\n",
      "        -5.0136e-03, -4.5180e-03, -1.6058e-02,  1.0916e-02, -9.6175e-03,\n",
      "        -1.5256e-02, -1.6779e-02, -5.9600e-03,  5.9482e-03, -1.1451e-02,\n",
      "        -5.0620e-03, -1.1476e-04, -1.0540e-02,  3.7728e-03, -1.5065e-02,\n",
      "        -8.6108e-03,  7.1744e-03, -8.8793e-04, -8.3169e-03])), ('convolution_block4.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])), ('convolution_block4.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block4.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block4.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.])), ('convolution_block4.1.num_batches_tracked', tensor(0)), ('convolution_block5.0.weight', tensor([[[[ 4.2357e-03,  9.9245e-03, -1.1427e-02],\n",
      "          [ 1.5095e-02,  6.9580e-03,  9.7315e-03],\n",
      "          [ 3.6056e-03,  1.4170e-02, -3.3464e-03]],\n",
      "\n",
      "         [[ 1.4929e-02,  5.1219e-03,  1.1040e-02],\n",
      "          [ 1.2231e-02, -5.9789e-03,  6.3691e-03],\n",
      "          [-1.3473e-02, -1.4965e-02,  1.1838e-02]],\n",
      "\n",
      "         [[ 2.3267e-03, -1.4544e-03, -1.3102e-02],\n",
      "          [ 4.4556e-03, -6.5535e-04,  1.1537e-02],\n",
      "          [-1.8050e-04, -6.9351e-03,  1.6035e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7693e-03,  9.2791e-03, -3.9094e-03],\n",
      "          [-1.6456e-02,  2.6343e-03,  1.1584e-02],\n",
      "          [-8.0061e-03, -4.5186e-03, -8.6244e-03]],\n",
      "\n",
      "         [[ 1.0974e-02, -5.5897e-03,  1.1551e-02],\n",
      "          [-4.0970e-03, -3.4599e-03, -1.5876e-02],\n",
      "          [-1.2880e-02, -1.0851e-02, -1.2384e-02]],\n",
      "\n",
      "         [[ 1.0357e-02, -1.1041e-02,  4.1111e-03],\n",
      "          [ 3.1858e-03, -5.6668e-03,  9.4055e-04],\n",
      "          [ 3.8830e-03,  1.6526e-03,  1.6363e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1834e-03,  6.3218e-03,  1.6372e-02],\n",
      "          [ 5.6106e-03, -4.1383e-03, -1.3629e-02],\n",
      "          [-4.4797e-06,  9.2490e-03, -3.7628e-04]],\n",
      "\n",
      "         [[-1.3320e-02,  3.7033e-03, -1.6528e-02],\n",
      "          [ 1.0175e-02,  5.1198e-03, -1.5834e-02],\n",
      "          [ 1.6478e-02, -9.6634e-03, -1.2408e-02]],\n",
      "\n",
      "         [[-1.7918e-03, -1.5882e-02,  9.8914e-03],\n",
      "          [-9.6412e-03, -2.0531e-03,  1.5153e-02],\n",
      "          [ 1.6268e-02, -1.2444e-02, -1.2007e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4439e-02,  8.2581e-03, -3.7362e-03],\n",
      "          [-1.2529e-02,  1.5968e-02, -1.5807e-02],\n",
      "          [ 2.7902e-03,  1.5727e-02,  1.4292e-04]],\n",
      "\n",
      "         [[ 1.3345e-02,  4.6180e-03,  8.1650e-03],\n",
      "          [-2.6788e-03, -7.0802e-03,  1.2744e-03],\n",
      "          [-9.0757e-03, -7.8020e-03, -9.7961e-03]],\n",
      "\n",
      "         [[ 7.3589e-03, -3.8754e-03,  1.0790e-02],\n",
      "          [ 8.8365e-03, -6.3157e-03,  9.3215e-03],\n",
      "          [-6.5796e-03, -1.3626e-02, -5.9418e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6971e-03, -9.8314e-03, -9.9649e-03],\n",
      "          [-1.2916e-02, -4.6882e-03,  4.4806e-03],\n",
      "          [ 1.3943e-03, -9.2914e-03,  8.0165e-03]],\n",
      "\n",
      "         [[ 4.3685e-03,  5.0139e-03,  1.1839e-02],\n",
      "          [ 1.5202e-02, -1.0170e-04,  9.8657e-03],\n",
      "          [ 8.8040e-03,  1.0706e-03, -1.1808e-02]],\n",
      "\n",
      "         [[-1.5537e-02, -2.5384e-03, -1.4293e-02],\n",
      "          [ 1.5351e-02, -8.7090e-04, -1.5108e-02],\n",
      "          [ 4.5791e-04, -3.1532e-03, -9.0245e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.6383e-03,  1.2780e-02, -7.4584e-03],\n",
      "          [-1.3738e-02,  2.7960e-03,  2.6396e-03],\n",
      "          [ 5.6701e-03,  1.2273e-02,  1.4417e-02]],\n",
      "\n",
      "         [[-9.5533e-03, -3.2525e-03, -9.7509e-04],\n",
      "          [ 2.3559e-03, -7.7850e-03, -1.0958e-02],\n",
      "          [ 3.5871e-03, -8.6982e-03,  1.1888e-02]],\n",
      "\n",
      "         [[-1.7548e-03,  8.2174e-03,  1.6397e-03],\n",
      "          [ 9.9150e-03, -1.3500e-02, -1.6878e-02],\n",
      "          [ 9.3384e-03,  1.3421e-02, -8.5019e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.6889e-03, -1.2083e-02, -1.4652e-02],\n",
      "          [ 1.1157e-02, -5.7367e-03, -3.0387e-03],\n",
      "          [ 1.2024e-02, -2.3134e-03, -1.1393e-02]],\n",
      "\n",
      "         [[-5.1690e-03, -3.4082e-03,  1.3771e-02],\n",
      "          [ 7.6726e-03, -4.6059e-03,  6.6284e-03],\n",
      "          [ 9.4455e-03,  2.1467e-04,  6.0415e-03]],\n",
      "\n",
      "         [[ 9.2324e-03, -1.6123e-02, -7.0341e-03],\n",
      "          [ 5.9057e-03,  2.1782e-03,  1.5830e-02],\n",
      "          [-4.7269e-03, -6.8487e-03, -8.9863e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4492e-03,  1.0071e-03,  1.3189e-02],\n",
      "          [ 7.4654e-03,  1.6417e-02,  1.0231e-02],\n",
      "          [ 1.2293e-02, -8.4420e-04,  1.4138e-02]],\n",
      "\n",
      "         [[ 8.0490e-03,  6.9294e-03, -1.0790e-02],\n",
      "          [ 8.8504e-03,  1.7068e-03, -6.7182e-04],\n",
      "          [-3.7619e-03, -3.8304e-03,  6.5553e-03]],\n",
      "\n",
      "         [[-1.0719e-02,  8.6885e-03,  1.0517e-02],\n",
      "          [-1.6294e-02, -1.3092e-02, -1.2236e-02],\n",
      "          [-1.5266e-02,  1.5832e-02, -9.2347e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.2046e-03,  6.6618e-03, -1.0517e-02],\n",
      "          [-3.2751e-03, -9.4117e-03,  1.0378e-02],\n",
      "          [ 1.8422e-03, -1.3407e-02, -6.8395e-03]],\n",
      "\n",
      "         [[ 2.3673e-03,  1.6688e-02, -8.5509e-03],\n",
      "          [-1.1305e-02, -1.7492e-03,  2.8399e-03],\n",
      "          [ 6.2694e-03, -3.3675e-04,  5.9792e-03]],\n",
      "\n",
      "         [[ 4.8216e-03, -9.0967e-03, -2.2308e-03],\n",
      "          [ 1.2646e-03,  1.9543e-03,  1.2145e-02],\n",
      "          [-3.8371e-03, -1.1301e-02, -9.6393e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0821e-02,  7.9373e-03, -2.0705e-03],\n",
      "          [-3.0781e-03, -7.5645e-03, -1.0670e-02],\n",
      "          [-1.4357e-02,  8.8666e-03, -1.2380e-02]],\n",
      "\n",
      "         [[ 1.4691e-02,  1.4244e-02, -1.1806e-02],\n",
      "          [ 1.0443e-03,  7.0369e-03, -7.7453e-03],\n",
      "          [ 1.6754e-02,  6.7756e-03, -3.5758e-03]],\n",
      "\n",
      "         [[-8.3287e-03, -1.6687e-02, -1.5615e-02],\n",
      "          [-9.9685e-03,  3.0357e-03,  1.3488e-03],\n",
      "          [ 1.6532e-02, -6.3634e-04,  1.1899e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5703e-03,  8.0448e-03,  1.0250e-02],\n",
      "          [ 1.6282e-02,  6.1664e-03, -1.4547e-02],\n",
      "          [-5.9096e-03,  1.6848e-02,  1.4482e-03]],\n",
      "\n",
      "         [[-1.0037e-02, -1.1217e-02, -1.6118e-02],\n",
      "          [ 8.7654e-03, -6.5322e-03,  1.1853e-02],\n",
      "          [ 1.5349e-02,  1.4639e-02, -9.9066e-03]],\n",
      "\n",
      "         [[ 8.3489e-03, -1.3483e-03, -1.6343e-02],\n",
      "          [ 1.5679e-04,  1.5216e-03, -5.7556e-03],\n",
      "          [ 7.7893e-03,  5.1400e-03,  6.2631e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5403e-02, -3.6285e-03,  7.5862e-04],\n",
      "          [-6.6745e-03, -1.1134e-02, -8.8434e-04],\n",
      "          [-1.5200e-02, -1.6130e-02,  2.7559e-03]],\n",
      "\n",
      "         [[ 1.5681e-02,  1.5156e-02, -1.6184e-02],\n",
      "          [ 1.3360e-02,  1.2910e-02, -9.4986e-03],\n",
      "          [-2.7059e-03,  1.2843e-02, -4.0305e-04]],\n",
      "\n",
      "         [[ 3.1864e-03,  2.7121e-03, -7.7466e-03],\n",
      "          [ 2.6661e-03,  1.2352e-02, -1.6194e-02],\n",
      "          [-5.8906e-03, -1.5385e-02, -1.3917e-02]]]])), ('convolution_block5.0.bias', tensor([-3.8607e-03, -1.4971e-02,  1.5159e-02, -6.8255e-03, -1.0118e-02,\n",
      "         1.3676e-05,  1.0396e-02,  1.3041e-02, -1.4054e-02,  7.9117e-03,\n",
      "         1.5860e-02, -1.4193e-02,  1.3223e-02,  4.5683e-04,  1.3085e-03,\n",
      "         4.7501e-03,  1.0934e-02, -5.5420e-03,  3.4532e-03,  1.0666e-02,\n",
      "         1.1872e-02,  8.3410e-03,  9.3816e-03,  1.9840e-03, -5.5081e-03,\n",
      "        -1.0498e-02,  4.3215e-03, -1.7222e-03, -1.6878e-02, -1.8711e-03,\n",
      "        -4.5604e-03,  1.0553e-02,  1.1367e-02, -1.6463e-02, -1.6073e-02,\n",
      "        -1.8834e-03,  6.3240e-03,  5.6743e-03, -1.0253e-02,  5.9463e-03,\n",
      "        -2.0751e-04,  1.3334e-02,  9.9298e-04, -9.4371e-03, -1.4484e-02,\n",
      "        -1.5342e-02,  6.6030e-03, -1.3092e-02, -5.9982e-03,  9.7541e-03,\n",
      "        -1.2866e-02, -5.0473e-03, -7.9781e-03, -1.1212e-02, -8.0089e-03,\n",
      "         1.1255e-02,  9.2639e-04, -9.0040e-06,  1.5883e-02, -2.8154e-03,\n",
      "        -1.4738e-02,  1.5880e-02,  1.0937e-02,  1.0076e-02,  1.1810e-03,\n",
      "         1.2019e-03,  9.9029e-03,  1.0172e-02, -8.9737e-03, -1.2004e-03,\n",
      "         1.0551e-02, -1.2640e-02, -3.7124e-03, -1.0489e-02,  6.8621e-03,\n",
      "         1.6296e-02, -4.1746e-03,  4.0581e-03, -4.7636e-03,  1.6525e-02,\n",
      "         4.0524e-03, -1.2894e-02, -6.4815e-03, -1.3721e-02, -1.2167e-02,\n",
      "        -3.1810e-03,  1.6894e-03, -1.3561e-02,  4.8616e-03, -4.9936e-03,\n",
      "         1.0221e-02, -1.5830e-02,  1.5264e-02, -3.4895e-05,  1.3807e-03,\n",
      "         4.2964e-04,  8.4338e-03, -3.8073e-04, -1.1038e-02, -1.1577e-02,\n",
      "        -1.4197e-03,  6.2375e-03, -1.2176e-02,  2.3035e-03, -1.2493e-02,\n",
      "         9.7874e-03,  6.8150e-03,  1.0652e-02, -1.3822e-02,  1.1041e-02,\n",
      "         3.0941e-03,  1.4629e-03,  1.3445e-02,  1.5247e-02, -5.2300e-03,\n",
      "         1.2909e-02,  2.3994e-03, -7.6182e-03,  2.2380e-03,  6.4086e-05,\n",
      "        -3.4428e-03,  1.0195e-02, -4.7835e-03,  1.6127e-02, -2.8908e-03,\n",
      "         1.3867e-02, -5.5057e-03,  1.1551e-02,  1.1915e-02, -8.6253e-03,\n",
      "        -5.7673e-03,  2.6214e-03,  1.1803e-02,  4.6386e-03,  3.7203e-03,\n",
      "         4.2981e-03, -8.7689e-03,  1.2150e-02, -7.3311e-03, -6.2039e-03,\n",
      "         9.5913e-03, -8.4342e-03, -5.1365e-04, -1.4979e-02, -1.6042e-03,\n",
      "        -1.5288e-02,  6.7039e-04,  1.5387e-02,  3.9895e-03, -9.3281e-03,\n",
      "         1.0424e-02, -1.1933e-02,  1.6262e-02,  1.6229e-02, -4.3102e-03,\n",
      "        -2.3841e-03,  1.4609e-02,  3.3014e-03, -7.0407e-03, -1.6959e-02,\n",
      "        -5.8573e-03, -6.6643e-03,  2.3751e-03,  3.1926e-03, -5.2673e-03,\n",
      "        -1.2723e-02,  1.2183e-02,  1.2845e-02,  1.6182e-02, -5.8435e-03,\n",
      "         6.4406e-03,  1.4518e-02,  8.7697e-03,  4.8410e-03,  7.8511e-03,\n",
      "        -1.2013e-03, -8.6472e-03, -1.3580e-03, -4.2748e-03,  9.2629e-03,\n",
      "        -3.1314e-03, -6.5849e-03,  1.5628e-02,  1.2189e-02, -1.1032e-03,\n",
      "        -1.4565e-02, -1.7000e-03, -9.4796e-03,  4.6537e-03, -3.7563e-03,\n",
      "         1.1720e-03,  1.2843e-02,  1.1616e-02,  8.8783e-03, -7.4190e-04,\n",
      "         4.7258e-03,  5.2367e-03, -1.1915e-02,  1.5040e-02,  7.7297e-03,\n",
      "        -6.1644e-03,  1.1307e-02,  1.3692e-02, -2.7695e-03,  1.6466e-02,\n",
      "         1.3330e-02, -1.4801e-02, -6.9162e-03,  9.3461e-03,  1.6818e-02,\n",
      "         1.1010e-03, -6.0989e-03, -1.1679e-02,  1.5063e-02,  4.9577e-03,\n",
      "         1.3199e-02, -9.9293e-03,  1.4854e-02, -9.0092e-03, -1.5329e-02,\n",
      "        -1.4290e-02, -8.0650e-03,  1.0366e-02,  1.1154e-02,  9.3567e-03,\n",
      "        -2.7598e-03,  7.1870e-03,  1.2831e-02, -1.1337e-03, -1.0974e-02,\n",
      "        -1.0012e-02, -1.1688e-02, -1.5153e-02,  3.6448e-03, -7.6018e-03,\n",
      "         6.0203e-03, -9.0070e-03, -5.2274e-03,  1.6939e-02,  7.5279e-03,\n",
      "         1.0644e-02, -1.4729e-03,  1.1640e-03,  2.7324e-03, -2.2185e-03,\n",
      "         4.1650e-04,  1.1581e-02, -1.3315e-02,  3.7285e-05,  2.8134e-03,\n",
      "         1.3672e-02,  1.9170e-03, -1.2266e-02, -6.9966e-03, -1.6374e-02,\n",
      "        -3.0552e-03])), ('convolution_block5.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])), ('convolution_block5.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block5.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('convolution_block5.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.])), ('convolution_block5.1.num_batches_tracked', tensor(0)), ('fully_connected.1.weight', tensor([[-0.0034,  0.0450,  0.0204,  ...,  0.0227, -0.0049, -0.0582],\n",
      "        [ 0.0415, -0.0101,  0.0276,  ..., -0.0007, -0.0214,  0.0075],\n",
      "        [ 0.0371, -0.0250, -0.0213,  ..., -0.0445,  0.0288,  0.0209],\n",
      "        ...,\n",
      "        [ 0.0522, -0.0224,  0.0554,  ...,  0.0551, -0.0585, -0.0539],\n",
      "        [ 0.0517, -0.0593, -0.0401,  ..., -0.0310, -0.0158,  0.0389],\n",
      "        [-0.0100,  0.0243,  0.0351,  ..., -0.0490,  0.0228, -0.0338]])), ('fully_connected.1.bias', tensor([ 1.3102e-03, -3.1037e-03,  4.4682e-02,  3.1752e-03,  5.7426e-02,\n",
      "         6.0861e-02,  2.1552e-02,  3.9140e-02, -3.8275e-02, -2.1742e-02,\n",
      "        -2.7299e-02,  2.7213e-02, -2.2513e-02,  1.4053e-04,  2.4712e-02,\n",
      "         4.2968e-02, -1.3669e-03, -4.2923e-02,  1.6952e-02,  5.3972e-02,\n",
      "         4.5032e-02, -2.3596e-02,  4.2317e-02, -1.0835e-02, -4.5843e-04,\n",
      "        -2.3888e-03, -1.6515e-02,  1.7881e-02,  4.0925e-02, -4.8099e-02,\n",
      "         6.2407e-02, -2.7955e-02, -4.8881e-02,  6.1126e-02, -5.8672e-02,\n",
      "        -2.1021e-02, -2.3364e-02,  4.7524e-02,  1.8064e-02, -3.5444e-02,\n",
      "        -6.2439e-02, -3.2158e-02, -3.2290e-02, -2.3459e-02,  3.9338e-03,\n",
      "         3.6337e-02,  5.3323e-02, -1.8630e-02, -5.4358e-02,  2.6107e-02,\n",
      "        -1.3738e-02, -3.0859e-02,  2.5597e-02, -4.5030e-02,  2.5284e-02,\n",
      "        -3.3803e-02,  1.7705e-02,  3.2340e-02, -1.7631e-02,  6.2925e-03,\n",
      "         2.9518e-02,  6.3399e-03, -1.7084e-02,  2.5062e-02,  1.9688e-02,\n",
      "        -3.1388e-02,  1.1586e-03, -3.0744e-02, -5.6504e-02,  5.3376e-05,\n",
      "         4.0030e-02,  1.8700e-02,  8.6400e-03, -2.7645e-02, -5.3869e-02,\n",
      "         3.5201e-02,  2.1174e-03, -2.4047e-02, -5.6201e-02, -4.4475e-02,\n",
      "        -1.2298e-02, -2.4076e-02, -1.7418e-02, -2.8629e-02,  4.2663e-02,\n",
      "         3.6856e-02,  3.8331e-02,  5.1515e-02, -2.2177e-02,  5.4194e-03,\n",
      "        -4.9859e-02,  4.2059e-02,  1.8007e-02,  5.4690e-02,  3.5380e-04,\n",
      "         2.0349e-02,  4.2927e-02, -6.1435e-03, -4.9590e-02,  2.9434e-02,\n",
      "        -4.1719e-02,  5.6390e-02,  1.8832e-02,  1.8798e-02,  4.8150e-03,\n",
      "        -2.0841e-02,  9.8260e-03,  4.7097e-02, -4.3074e-03, -4.6091e-02,\n",
      "        -5.8787e-03,  2.6453e-03,  1.9151e-02, -3.2809e-02,  2.3833e-02,\n",
      "        -1.0258e-02, -5.3671e-02,  5.0666e-02, -2.4213e-02,  4.9509e-02,\n",
      "         3.5655e-02,  5.3085e-03,  2.9282e-02, -1.8963e-02,  4.3855e-02,\n",
      "        -4.4828e-02, -5.8566e-03,  2.1714e-02])), ('fully_connected1.1.weight', tensor([[ 0.0838,  0.0553,  0.0618,  ...,  0.0361,  0.0659, -0.0481],\n",
      "        [ 0.0820, -0.0683, -0.0749,  ...,  0.0760,  0.0736, -0.0164],\n",
      "        [ 0.0398, -0.0874, -0.0675,  ..., -0.0404, -0.0158, -0.0366],\n",
      "        ...,\n",
      "        [-0.0480,  0.0070, -0.0821,  ..., -0.0281, -0.0828, -0.0135],\n",
      "        [ 0.0014, -0.0504, -0.0008,  ..., -0.0712,  0.0213,  0.0476],\n",
      "        [ 0.0368,  0.0678,  0.0857,  ..., -0.0285, -0.0275,  0.0032]])), ('fully_connected1.1.bias', tensor([ 0.0587,  0.0109,  0.0126, -0.0561, -0.0152, -0.0855,  0.0528,  0.0027,\n",
      "        -0.0814,  0.0375,  0.0375,  0.0777, -0.0402,  0.0275, -0.0292,  0.0049,\n",
      "        -0.0191,  0.0784, -0.0358, -0.0638, -0.0171, -0.0164, -0.0004, -0.0563,\n",
      "        -0.0529, -0.0317,  0.0486, -0.0658,  0.0583, -0.0772,  0.0194,  0.0346,\n",
      "        -0.0193, -0.0133,  0.0527, -0.0471,  0.0356, -0.0129, -0.0834,  0.0685,\n",
      "        -0.0192,  0.0245,  0.0665, -0.0494,  0.0140,  0.0050,  0.0160, -0.0358,\n",
      "         0.0782, -0.0249, -0.0826,  0.0725,  0.0654,  0.0519, -0.0661,  0.0125,\n",
      "        -0.0026, -0.0294,  0.0329, -0.0283, -0.0710,  0.0522, -0.0563,  0.0740])), ('fully_connected2.0.weight', tensor([[ 1.5471e-02, -1.6009e-02,  5.9110e-02,  3.2384e-02, -5.3802e-02,\n",
      "         -8.7571e-03,  2.9935e-02, -5.9189e-02, -6.0885e-02,  1.0582e-01,\n",
      "          4.2810e-02, -4.2028e-02,  4.5201e-02, -1.0623e-01,  5.2502e-03,\n",
      "          8.8453e-02,  1.1042e-01,  1.1098e-01, -1.0973e-02, -1.1810e-01,\n",
      "         -3.7927e-02, -2.6717e-02,  8.3944e-02,  9.7866e-02,  2.5154e-02,\n",
      "         -1.0993e-01,  1.9395e-02,  3.1841e-02, -7.2529e-02,  8.6970e-02,\n",
      "         -1.0339e-01,  3.1996e-02, -6.9029e-02,  5.8072e-02,  8.1535e-02,\n",
      "          1.4286e-02, -1.2389e-01, -4.9920e-02, -8.5007e-02, -1.1347e-01,\n",
      "         -5.5864e-02,  1.1782e-01, -2.3485e-02,  3.1050e-02, -1.1119e-01,\n",
      "          6.3866e-02, -1.0705e-01,  1.1064e-01,  6.9714e-02, -5.3907e-02,\n",
      "          8.8639e-02,  6.4273e-02,  3.6543e-02,  1.6797e-02, -6.8058e-02,\n",
      "         -1.1608e-01,  9.0383e-02, -4.8210e-02,  8.8430e-02, -7.6864e-02,\n",
      "         -7.3050e-02,  8.7118e-02, -3.6484e-02,  1.4145e-02],\n",
      "        [-1.2093e-01,  4.1463e-02, -1.6048e-02, -1.4145e-02,  9.3008e-02,\n",
      "         -5.5550e-02, -4.8991e-02,  8.9218e-03, -8.1494e-05,  1.1201e-01,\n",
      "          5.5634e-02,  1.5390e-02, -2.4848e-02,  8.7192e-02,  9.1609e-03,\n",
      "         -6.3481e-02, -5.5853e-02, -8.0707e-02, -5.4779e-03, -8.6504e-02,\n",
      "         -9.5423e-02,  9.8752e-02,  1.1871e-01, -9.3506e-02, -9.9289e-04,\n",
      "         -8.7561e-02, -8.2064e-02,  7.9985e-02,  7.6740e-02, -4.3024e-02,\n",
      "          3.6030e-02, -3.5767e-03,  4.4962e-02,  3.6300e-02,  9.1262e-03,\n",
      "          1.0939e-02, -9.7486e-02,  5.8129e-02, -6.8773e-03,  1.2265e-01,\n",
      "          2.5676e-02,  7.3115e-03,  7.8447e-02,  7.3960e-02,  8.4101e-02,\n",
      "         -3.5155e-02, -2.6418e-02,  1.3049e-02, -3.5847e-02,  1.3084e-02,\n",
      "         -6.7860e-02,  3.9215e-02,  1.1710e-01, -1.0521e-01,  9.1013e-02,\n",
      "         -5.3398e-02,  1.0982e-01,  7.0962e-02, -3.5853e-02, -3.4810e-02,\n",
      "          5.1514e-02,  1.1985e-01,  4.0537e-02,  4.6294e-02],\n",
      "        [ 1.1056e-01, -6.1419e-02, -7.3412e-02,  1.1095e-01, -1.1319e-01,\n",
      "         -2.3706e-02,  3.1748e-02, -5.8209e-03,  3.3391e-03, -6.7056e-02,\n",
      "         -1.1913e-01,  5.9344e-02,  1.0309e-02, -9.5117e-02, -1.0715e-01,\n",
      "         -3.1184e-02, -9.4035e-02, -5.4020e-02, -7.1544e-02, -7.7504e-04,\n",
      "          5.5484e-02, -3.2740e-02, -7.6954e-02,  6.0951e-02, -1.1442e-01,\n",
      "          7.8981e-02,  1.0438e-02, -1.0886e-01, -8.6043e-02,  1.1239e-01,\n",
      "         -9.4496e-02,  5.5710e-03,  3.6534e-02, -9.5009e-02,  5.0823e-02,\n",
      "         -1.1722e-01, -1.2426e-01, -1.0214e-02, -1.1633e-01,  6.7882e-02,\n",
      "         -2.1579e-03, -2.4297e-02,  2.2236e-02,  9.5109e-02, -1.1272e-01,\n",
      "         -5.7797e-02,  5.4366e-02,  9.2321e-02, -8.0602e-02,  1.5820e-02,\n",
      "          3.7743e-02,  2.6678e-03, -1.9563e-02,  1.1385e-01,  1.0886e-01,\n",
      "         -5.1601e-02,  8.6704e-02, -2.4544e-02, -7.5939e-02,  1.1842e-01,\n",
      "          4.5399e-02, -3.4201e-02, -9.2968e-02, -8.6119e-02],\n",
      "        [ 6.3992e-04,  3.4441e-02,  5.9780e-03, -1.0583e-01,  7.2288e-02,\n",
      "         -9.9577e-02, -6.3143e-02,  2.1167e-02, -5.3824e-02, -1.0962e-01,\n",
      "          6.7041e-02,  1.0173e-01, -4.9769e-02, -7.6124e-02,  6.6945e-03,\n",
      "          5.4815e-02,  1.0828e-01, -4.2786e-02,  8.5791e-02, -4.4340e-02,\n",
      "         -2.2763e-03, -1.0232e-01,  5.9858e-02,  8.8795e-03, -9.4403e-03,\n",
      "         -2.3517e-02,  8.4809e-02, -3.6305e-02, -8.9145e-02, -8.1386e-02,\n",
      "         -7.4235e-02, -4.6093e-02,  5.6035e-03, -4.9554e-02,  2.0240e-03,\n",
      "         -2.2314e-02, -1.3907e-02,  3.0813e-02,  4.6013e-02,  8.0221e-02,\n",
      "          1.7509e-02, -7.5668e-02, -3.9110e-02, -3.7596e-02, -8.5435e-02,\n",
      "         -7.3387e-02, -9.6367e-02, -1.0738e-01, -3.7212e-02, -1.2285e-01,\n",
      "         -6.5069e-02, -9.5729e-02, -1.2161e-01, -3.2065e-02, -1.1143e-02,\n",
      "         -3.5396e-02,  6.1056e-02,  5.7193e-02,  7.4460e-02, -2.8476e-02,\n",
      "          1.0488e-01, -1.4807e-02, -2.7719e-02,  7.9820e-02],\n",
      "        [-1.0183e-01,  7.8008e-02,  6.6420e-02,  1.1164e-01, -3.2040e-02,\n",
      "          5.1082e-02,  1.0292e-01,  1.1983e-01, -1.2028e-01, -4.1460e-02,\n",
      "          4.9434e-02,  2.8627e-02,  6.1508e-02, -3.6503e-02,  4.8692e-02,\n",
      "          1.1355e-01, -7.3178e-02,  5.3577e-02,  3.5386e-02,  2.3769e-02,\n",
      "         -2.1963e-02,  5.7544e-03,  9.5669e-02,  5.9487e-03,  6.9141e-02,\n",
      "          8.9536e-02, -7.7358e-02,  8.4916e-02, -1.1970e-01, -5.3926e-02,\n",
      "         -4.8066e-02,  1.6908e-02,  4.4215e-02,  4.1616e-02, -6.5974e-03,\n",
      "          9.6141e-03,  1.0669e-01, -8.7008e-02, -1.2167e-01, -1.9933e-02,\n",
      "         -2.0157e-02,  7.8052e-03,  6.7017e-02,  8.9031e-02,  3.9656e-02,\n",
      "         -2.3375e-03, -1.0094e-01, -6.5524e-02,  8.9127e-02,  6.6177e-02,\n",
      "          1.1595e-01, -1.1586e-01, -7.0076e-02,  1.0601e-01,  7.6007e-02,\n",
      "         -3.1755e-02,  1.1003e-02, -2.9378e-02, -5.5674e-03, -7.7117e-02,\n",
      "         -2.2770e-02,  1.0910e-02, -6.6418e-02,  4.6216e-02],\n",
      "        [-4.7912e-02, -4.6748e-02,  8.8795e-02, -4.1350e-02,  2.7233e-02,\n",
      "          3.9957e-02,  1.0728e-01, -5.4770e-02,  9.8218e-02,  8.5930e-02,\n",
      "         -1.2103e-01, -3.0167e-02, -1.0588e-01, -6.6982e-02,  2.8384e-02,\n",
      "         -1.1497e-01,  7.2052e-02, -4.9513e-02,  7.5669e-02,  2.5316e-03,\n",
      "          2.6240e-02, -5.8766e-02, -5.7806e-02, -7.4705e-02, -1.2198e-01,\n",
      "         -6.1643e-03,  8.1430e-02,  1.0058e-01, -1.2198e-01,  1.2439e-01,\n",
      "         -7.1279e-03,  1.0684e-01, -8.0589e-02, -5.7301e-02,  9.4994e-02,\n",
      "         -8.2760e-02,  2.0119e-02, -9.3794e-02,  6.3299e-02,  3.2122e-02,\n",
      "         -5.1648e-02, -7.1269e-02, -6.4413e-02, -3.9934e-02, -9.5696e-02,\n",
      "         -1.1230e-02,  3.2090e-02,  4.0381e-02,  1.0058e-01, -1.0483e-01,\n",
      "          2.0915e-02,  1.1926e-01,  7.1284e-02, -5.1098e-02, -1.0401e-01,\n",
      "          1.0255e-01, -8.3018e-02, -7.4537e-03,  6.2774e-02, -1.2017e-01,\n",
      "          1.2227e-01,  5.1244e-02, -1.0758e-01,  1.5411e-02],\n",
      "        [-5.8440e-02,  7.9106e-02,  3.7779e-02, -4.7730e-03, -1.7793e-02,\n",
      "         -1.0617e-01, -4.5267e-02,  6.4110e-02,  6.9608e-02,  5.0222e-02,\n",
      "          8.8609e-02, -1.0239e-01,  1.7887e-02,  7.6343e-02,  1.3599e-02,\n",
      "         -4.9948e-02, -5.8543e-02,  1.0069e-01,  1.8264e-02,  2.3289e-02,\n",
      "          1.1115e-01,  2.0452e-02, -5.9688e-02, -7.1606e-04,  2.9843e-02,\n",
      "          7.9471e-02, -1.1277e-01, -9.0649e-02,  5.9304e-02,  4.5778e-02,\n",
      "          9.2851e-02, -3.6915e-02,  1.1366e-01,  5.4974e-02,  9.7031e-02,\n",
      "          5.1577e-02,  3.7999e-02,  9.7685e-03,  9.8034e-02,  8.2755e-02,\n",
      "         -2.0184e-02,  9.8280e-02,  7.3252e-02,  2.7430e-02, -1.0828e-01,\n",
      "         -4.2600e-02, -7.1473e-02, -8.9917e-02,  2.0093e-02, -3.8043e-02,\n",
      "         -1.2353e-01,  1.2246e-01, -4.1015e-02, -1.1269e-01, -2.6233e-02,\n",
      "          4.0894e-02,  5.7487e-02, -7.3043e-02,  3.7144e-02,  1.1584e-01,\n",
      "          6.9641e-03, -1.1029e-01,  5.3652e-02, -6.1454e-03],\n",
      "        [ 9.1963e-02,  6.8956e-02,  5.1308e-02,  6.3662e-02, -8.1425e-02,\n",
      "          1.0886e-01,  1.1225e-01, -2.7192e-02, -7.9307e-02, -9.0110e-02,\n",
      "         -1.1409e-01,  4.3915e-02,  4.5979e-02,  5.6054e-02, -5.8968e-02,\n",
      "         -9.8466e-02,  6.8412e-02, -8.3965e-03,  6.7101e-02,  1.1940e-01,\n",
      "          3.2962e-02,  6.0120e-03, -1.2440e-01, -9.6946e-03, -1.0228e-02,\n",
      "         -7.7849e-02, -4.5465e-02, -1.1732e-01, -4.5602e-02,  8.6589e-02,\n",
      "         -7.0651e-02, -8.2909e-02, -8.3185e-02, -1.0172e-02,  2.4201e-02,\n",
      "          3.8071e-03,  3.9276e-02,  3.8329e-03,  2.4012e-03, -8.9046e-02,\n",
      "         -1.0338e-01, -4.4818e-02,  1.1397e-01, -1.0546e-01, -4.6943e-02,\n",
      "         -9.2125e-02, -1.0553e-01, -1.1155e-02,  3.1096e-02, -1.0843e-02,\n",
      "          7.6255e-02,  1.7556e-02,  1.1302e-01,  1.2694e-02,  8.9302e-02,\n",
      "         -2.8132e-02,  7.6820e-02,  5.5624e-02, -1.1615e-01,  4.8764e-02,\n",
      "         -1.1864e-01,  2.3979e-02,  4.9917e-02,  1.2945e-02],\n",
      "        [ 7.4029e-02, -1.7039e-03, -7.1693e-02,  8.5285e-02,  6.7901e-02,\n",
      "         -1.2423e-01,  5.4136e-02, -6.4680e-02, -3.4579e-02, -1.5884e-02,\n",
      "          4.5659e-02, -8.4078e-02,  3.2010e-02, -1.1047e-01, -3.5494e-02,\n",
      "         -4.3095e-02, -3.0599e-02,  3.1335e-02, -1.5430e-02,  6.0123e-02,\n",
      "          5.6281e-02,  5.4323e-02, -6.5675e-02,  6.3566e-02, -8.3855e-02,\n",
      "          9.5360e-02,  8.8830e-02,  4.1619e-02,  8.4049e-03, -2.8538e-02,\n",
      "          7.9987e-02,  1.1045e-01, -1.0210e-01, -1.1822e-01,  7.1465e-02,\n",
      "         -1.1803e-01,  9.5400e-02, -8.5379e-02, -1.0385e-01, -7.5268e-02,\n",
      "          5.6557e-02,  1.1457e-01,  3.5237e-02, -8.0008e-02,  6.5359e-02,\n",
      "         -9.7407e-02, -4.7697e-04,  2.6432e-02,  7.5711e-02, -1.1201e-01,\n",
      "          9.2445e-02,  1.8254e-02,  5.5683e-02, -8.9711e-02, -1.0344e-01,\n",
      "          7.9464e-02,  7.4798e-02,  9.5429e-02,  6.8104e-02,  9.1084e-02,\n",
      "         -3.9786e-02, -4.8447e-02, -8.9864e-02, -6.4950e-02],\n",
      "        [ 2.9318e-02, -2.9874e-02,  9.6363e-02,  9.1968e-02,  4.2727e-02,\n",
      "          1.1062e-01, -1.0888e-01,  1.8520e-02, -1.0083e-01, -7.7237e-02,\n",
      "          3.7712e-02, -3.3148e-02, -1.0940e-01, -9.0883e-03,  1.2379e-01,\n",
      "          1.9688e-02,  7.9055e-02, -1.0094e-01, -1.2040e-01,  6.5332e-02,\n",
      "         -9.1489e-02,  1.1826e-01,  4.6930e-02, -5.4597e-02, -1.1939e-01,\n",
      "          9.3960e-02,  8.8024e-02, -7.1226e-02, -1.1350e-01,  9.3974e-02,\n",
      "         -9.0809e-02,  3.1813e-02,  3.7467e-03,  4.6490e-03, -5.4133e-02,\n",
      "         -5.7670e-02,  2.4865e-02, -6.3090e-02,  8.3910e-02, -7.0934e-02,\n",
      "         -5.5966e-02,  5.9614e-02,  6.6716e-02, -6.8392e-02, -9.4540e-02,\n",
      "          8.6761e-02, -2.9752e-02,  9.8557e-02, -6.0137e-02, -3.7662e-03,\n",
      "          3.9711e-02, -1.2107e-01,  8.2233e-02,  8.4322e-02, -1.3697e-02,\n",
      "         -3.1959e-02, -5.9743e-02,  7.8417e-02, -9.8139e-02, -1.0754e-02,\n",
      "         -7.8581e-02, -1.4868e-02, -8.9991e-02,  3.7098e-02]])), ('fully_connected2.0.bias', tensor([-2.0966e-05, -9.3608e-02,  1.8824e-02,  1.3449e-02, -3.4012e-03,\n",
      "         3.0084e-02, -3.8601e-03, -4.4895e-02,  3.4976e-02,  5.5342e-02]))])\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(number_classes=10)\n",
    "print(model)\n",
    "#model.convolution_block\n",
    "#model.flatten\n",
    "print(model.state_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, weight_decay = 0.005, momentum = 0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss\n",
    "loss_fn1 = nn.MSELoss()\n",
    "loss_fn2 = nn.CrossEntropyLoss()       # Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "def get_test_loader(data_dir,\n",
    "                    batch_size,\n",
    "                    shuffle=True):\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "\n",
    "    # define transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((227,227)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=False,\n",
    "        download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fns, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader): # y : GT\n",
    "        pred = model(X)\n",
    "        loss_sum = 0.0\n",
    "        for loss_fn in loss_fns:\n",
    "          pred_max, max_indices = torch.max(pred, dim=1)\n",
    "          pred_max = pred_max.to(torch.float)\n",
    "          y = y.to(torch.float)\n",
    "          loss_sum += loss_fn(pred_max, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_sum = loss_sum.to(torch.float)\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss_sum\n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss_sum.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    train_loss /= len(dataloader)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fns):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad(): # To freeze the network\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss_sum = 0.0\n",
    "            for loss_fn in loss_fns: \n",
    "                pred_max, max_indices = torch.max(pred, dim=1)\n",
    "                test_loss_sum += loss_fn(pred_max, y).item()\n",
    "            test_loss += test_loss_sum\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item() # calculating number of batches\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.CIFAR10(root=\"../data/cifar10/\", train=True, download=False, transform=ToTensor())\n",
    "\n",
    "test_data = datasets.CIFAR10(root=\"../data/cifar10/\", train=False, download=False, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "loaded_train = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "loaded_test = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(model, loss_fns, optimizer, num_epochs = 5):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for t in range(num_epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = train(loaded_train, model, loss_fns, optimizer)\n",
    "        train_loss = train_loss.detach().numpy()\n",
    "        test_loss, accuracy = test(loaded_test, model, loss_fns)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        accuracy_scores.append(accuracy)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    fig,axs = plt.subplots(1, 2, figsize=(5,8))\n",
    "    axs = axs.ravel()\n",
    "    axs[0].plot(range(num_epochs), train_losses, \":r\")\n",
    "    axs[0].plot(range(num_epochs), test_losses, \"-b\")\n",
    "\n",
    "    axs[1].plot(range(num_epochs), accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 23.280245  [    0/50000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 8.258591 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 8.720411  [    0/50000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 8.248249 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 8.451678  [    0/50000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 8.243345 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 9.187729  [    0/50000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[242], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m eval_net(model, loss_fns\u001b[39m=\u001b[39;49m[loss_fn1], optimizer\u001b[39m=\u001b[39;49moptimizer, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[241], line 8\u001b[0m, in \u001b[0;36meval_net\u001b[1;34m(model, loss_fns, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m      7\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     train_loss \u001b[39m=\u001b[39m train(loaded_train, model, loss_fns, optimizer)\n\u001b[0;32m      9\u001b[0m     train_loss \u001b[39m=\u001b[39m train_loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     10\u001b[0m     test_loss, accuracy \u001b[39m=\u001b[39m test(loaded_test, model, loss_fns)\n",
      "Cell \u001b[1;32mIn[237], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fns, optimizer)\u001b[0m\n\u001b[0;32m     13\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     14\u001b[0m loss_sum \u001b[39m=\u001b[39m loss_sum\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m---> 15\u001b[0m loss_sum\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     16\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     18\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_sum\n",
      "File \u001b[1;32mc:\\Users\\yusuf\\.conda\\envs\\mldl\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yusuf\\.conda\\envs\\mldl\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_net(model, loss_fns=[loss_fn1], optimizer=optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
