{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\breakkit\\lib\\site-packages\\torchvision\\models\\inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\envs\\breakkit\\lib\\site-packages\\torchvision\\models\\googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "\n",
    "model_dict = {\n",
    "    'resnet18': models.resnet18(weights=None), # ++ \n",
    "    'alexnet' : models.alexnet(weights=None), # Error\n",
    "    'vgg16_bn': models.vgg16_bn(weights=None), # Memory\n",
    "    'vgg16' : models.vgg16(weights=None), # RuntimeError: Detected the following values in `preds`: tensor([111, 530, 626, 644, 818], device='cuda:0') but expected only the following values [0,1] since `preds` is a label tensor.\n",
    "    'vgg19_bn': models.vgg19_bn(weights=None), # Memory\n",
    "    'vgg19': models.vgg19(weights=None), # RuntimeError: Detected the following values in `preds`: tensor([111, 530, 644, 818], device='cuda:0') but expected only the following values [0,1] since `preds` is a label tensor.\n",
    "    'squeezenet' : models.squeezenet1_0(weights=None), # \n",
    "    'densenet' : models.densenet161(weights=None), # \n",
    "    'inception_v3' : models.inception_v3(weights=None), # \n",
    "    'googlenet' : models.googlenet(weights=None), # \n",
    "    'shufflenet' : models.shufflenet_v2_x1_0(weights=None), # \n",
    "    'mobilenet' : models.mobilenet_v2(weights=None), # \n",
    "    'resnext50_32x4d' : models.resnext50_32x4d(weights=None), # \n",
    "    'wide_resnet50_2' : models.wide_resnet50_2(weights=None), # ++ (32bs = memory error)\n",
    "    'mnasnet' : models.mnasnet1_0(weights=None), # ...\n",
    "}\n",
    "\n",
    "model_names = {\n",
    "'resnet18': 'fc',\n",
    "'alexnet': 'classifier',\n",
    "'vgg16_bn': 'classifier',\n",
    "'vgg16': 'classifier',\n",
    "'vgg19_bn': 'classifier',\n",
    "'vgg19': 'classifier',\n",
    "'squeezenet': 'classifier',\n",
    "'densenet': 'classifier',\n",
    "'inception_v3': 'fc',\n",
    "'googlenet': 'fc',\n",
    "'shufflenet': 'fc',\n",
    "'mobilenet': 'classifier',\n",
    "'resnext50_32x4d': 'fc',\n",
    "'wide_resnet50_2': 'fc',\n",
    "'mnasnet': 'classifier'\n",
    "}\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in model_dict.items():\n",
    "    # Get last layer.\n",
    "    last_layer_attr = model_names[model_name]\n",
    "    last_layer = getattr(model, last_layer_attr)\n",
    "\n",
    "    if isinstance(last_layer, torch.nn.Linear):\n",
    "        num_ftrs = last_layer.in_features\n",
    "        setattr(model, last_layer_attr, torch.nn.Linear(num_ftrs, num_classes))\n",
    "    elif isinstance(last_layer, torch.nn.Sequential):\n",
    "        if model_name != 'squeezenet':\n",
    "            last_layer_ = last_layer[-1]\n",
    "            num_ftrs = last_layer_.in_features\n",
    "            model.classifier[-1] = torch.nn.Linear(num_ftrs, num_classes)\n",
    "        else:\n",
    "            last_layer = model.classifier\n",
    "            last_layer_ = last_layer[1]\n",
    "            num_ftrs = last_layer_.in_channels\n",
    "            kernel_size = last_layer_.kernel_size\n",
    "            model.classifier[1] = torch.nn.Conv2d(num_ftrs, num_classes, kernel_size)\n",
    "    # Update the last layer.\n",
    "    model_dict[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 4\n",
    "if num_channels != 3:\n",
    "    for model_name, model in model_dict.items():\n",
    "        if model_name in ['resnet18', 'resnext50_32x4d', 'wide_resnet50_2']:\n",
    "            model.conv1.in_channels = num_channels\n",
    "        elif model_name in ['alexnet', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'vgg16', 'densenet', 'squeezenet']:\n",
    "            model.features[0].in_channels = num_channels\n",
    "        elif model_name in ['mnasnet']:\n",
    "            model.layers[0].in_channels = num_channels\n",
    "        elif model_name == 'shufflenet':\n",
    "            model.conv1[0].in_channels = 4\n",
    "        elif model_name == 'inception_v3':\n",
    "            model.Conv2d_1a_3x3.conv.in_channels = 4\n",
    "        elif model_name == 'googlenet':\n",
    "            model.conv1.conv.in_channels = 4\n",
    "    # Update the dictionary.\n",
    "    model_dict[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights:\n",
      "torch.Size([64, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Define a simple convolutional layer\n",
    "conv = torch.nn.Conv2d(4, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Check the initial weights before applying initialization\n",
    "print(\"Initial weights:\")\n",
    "print(conv.weight.shape)\n",
    "new_weights = conv.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_dict['mobilenet']\n",
    "model.features[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "from tools import BreaKHis\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torchvision import transforms as T\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import WeightedRandomSampler, random_split, RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from models.fpcn import FPCN\n",
    "from models.utilities.losses import FocalLoss\n",
    "import os, sys\n",
    "import warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:03<00:00, 156.42it/s]\n",
      "100%|██████████| 1370/1370 [00:09<00:00, 140.29it/s]\n",
      "h: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[159], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m myDataset \u001b[39m=\u001b[39m BreaKHis(\n\u001b[0;32m      2\u001b[0m     root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mC:/Users/user/Dersler/Machine and Deep Learning/Project/BreaKHis_v1/\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      3\u001b[0m                 transform \u001b[39m=\u001b[39;49m T\u001b[39m.\u001b[39;49mCompose([\n\u001b[0;32m      4\u001b[0m                 T\u001b[39m.\u001b[39;49mToPILImage(),  \u001b[39m# Convert numpy.ndarray to PIL Image\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m                 T\u001b[39m.\u001b[39;49mResize(\u001b[39m256\u001b[39;49m),\n\u001b[0;32m      6\u001b[0m                 T\u001b[39m.\u001b[39;49mCenterCrop(\u001b[39m224\u001b[39;49m),\n\u001b[0;32m      7\u001b[0m                 T\u001b[39m.\u001b[39;49mToTensor(),\n\u001b[0;32m      8\u001b[0m                 T\u001b[39m.\u001b[39;49mNormalize(mean\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m ,\u001b[39m0\u001b[39;49m ,\u001b[39m0\u001b[39;49m], std\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m ,\u001b[39m0\u001b[39;49m ,\u001b[39m0\u001b[39;49m])\n\u001b[0;32m      9\u001b[0m             ]),\n\u001b[0;32m     10\u001b[0m                 mode \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mbinary\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     11\u001b[0m                 imageLikefeatures \u001b[39m=\u001b[39;49m [\u001b[39m'\u001b[39;49m\u001b[39mhog\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     12\u001b[0m                 )\n",
      "File \u001b[1;32mc:\\Users\\user\\Dersler\\Machine and Deep Learning\\Project\\breast_histopathology_clf\\tools.py:182\u001b[0m, in \u001b[0;36mBreaKHis.__init__\u001b[1;34m(self, root, mf, mode, transform, target_transform, shuffle, imageLikefeatures)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mfor\u001b[39;00m i, imageLikefeature \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(imageLikefeatures):\n\u001b[0;32m    181\u001b[0m     features \u001b[39m=\u001b[39m read_imageLikefeature(imageLikefeature[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfnames)\n\u001b[1;32m--> 182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages \u001b[39m=\u001b[39m conc(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimages, features, different_sizes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\Dersler\\Machine and Deep Learning\\Project\\breast_histopathology_clf\\tools.py:119\u001b[0m, in \u001b[0;36mconc\u001b[1;34m(images, imageLikeFeatures, different_sizes)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m??\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    118\u001b[0m \u001b[39m# Find the minimum size.\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m min_height \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(images\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], imageLikeFeatures\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m    120\u001b[0m min_width \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(images\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], imageLikeFeatures\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])\n\u001b[0;32m    121\u001b[0m \u001b[39mprint\u001b[39m(min_width, min_height)\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "myDataset = BreaKHis(\n",
    "    root='C:/Users/user/Dersler/Machine and Deep Learning/Project/BreaKHis_v1/',\n",
    "                transform = T.Compose([\n",
    "                T.ToPILImage(),  # Convert numpy.ndarray to PIL Image\n",
    "                T.Resize(256),\n",
    "                T.CenterCrop(224),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0, 0 ,0 ,0], std=[0, 0 ,0 ,0])\n",
    "            ]),\n",
    "                mode = 'binary',\n",
    "                imageLikefeatures = ['hog']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "breakkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
